const Redis = require('ioredis')
const config = require('../../config/config')
const logger = require('../utils/logger')

// æ—¶åŒºè¾…åŠ©å‡½æ•°
// æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°çš„ç›®çš„æ˜¯è·å–æŸä¸ªæ—¶é—´ç‚¹åœ¨ç›®æ ‡æ—¶åŒºçš„"æœ¬åœ°"è¡¨ç¤º
// ä¾‹å¦‚ï¼šUTCæ—¶é—´ 2025-07-30 01:00:00 åœ¨ UTC+8 æ—¶åŒºè¡¨ç¤ºä¸º 2025-07-30 09:00:00
function getDateInTimezone(date = new Date()) {
  const offset = config.system.timezoneOffset || 8 // é»˜è®¤UTC+8

  // æ–¹æ³•ï¼šåˆ›å»ºä¸€ä¸ªåç§»åçš„Dateå¯¹è±¡ï¼Œä½¿å…¶getUTCXXXæ–¹æ³•è¿”å›ç›®æ ‡æ—¶åŒºçš„å€¼
  // è¿™æ ·æˆ‘ä»¬å¯ä»¥ç”¨getUTCFullYear()ç­‰æ–¹æ³•è·å–ç›®æ ‡æ—¶åŒºçš„å¹´æœˆæ—¥æ—¶åˆ†ç§’
  const offsetMs = offset * 3600000 // æ—¶åŒºåç§»çš„æ¯«ç§’æ•°
  const adjustedTime = new Date(date.getTime() + offsetMs)

  return adjustedTime
}

// è·å–é…ç½®æ—¶åŒºçš„æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
function getDateStringInTimezone(date = new Date()) {
  const tzDate = getDateInTimezone(date)
  // ä½¿ç”¨UTCæ–¹æ³•è·å–åç§»åçš„æ—¥æœŸéƒ¨åˆ†
  return `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}-${String(
    tzDate.getUTCDate()
  ).padStart(2, '0')}`
}

// è·å–é…ç½®æ—¶åŒºçš„å°æ—¶ (0-23)
function getHourInTimezone(date = new Date()) {
  const tzDate = getDateInTimezone(date)
  return tzDate.getUTCHours()
}

// è·å–é…ç½®æ—¶åŒºçš„ ISO å‘¨ï¼ˆYYYY-Wxx æ ¼å¼ï¼Œå‘¨ä¸€åˆ°å‘¨æ—¥ï¼‰
function getWeekStringInTimezone(date = new Date()) {
  const tzDate = getDateInTimezone(date)

  // è·å–å¹´ä»½
  const year = tzDate.getUTCFullYear()

  // è®¡ç®— ISO å‘¨æ•°ï¼ˆå‘¨ä¸€ä¸ºç¬¬ä¸€å¤©ï¼‰
  const dateObj = new Date(tzDate)
  const dayOfWeek = dateObj.getUTCDay() || 7 // å°†å‘¨æ—¥(0)è½¬æ¢ä¸º7
  const firstThursday = new Date(dateObj)
  firstThursday.setUTCDate(dateObj.getUTCDate() + 4 - dayOfWeek) // æ‰¾åˆ°è¿™å‘¨çš„å‘¨å››

  const yearStart = new Date(firstThursday.getUTCFullYear(), 0, 1)
  const weekNumber = Math.ceil(((firstThursday - yearStart) / 86400000 + 1) / 7)

  return `${year}-W${String(weekNumber).padStart(2, '0')}`
}

// å¹¶å‘é˜Ÿåˆ—ç›¸å…³å¸¸é‡
const QUEUE_STATS_TTL_SECONDS = 86400 * 7 // ç»Ÿè®¡è®¡æ•°ä¿ç•™ 7 å¤©
const WAIT_TIME_TTL_SECONDS = 86400 // ç­‰å¾…æ—¶é—´æ ·æœ¬ä¿ç•™ 1 å¤©ï¼ˆæ»šåŠ¨çª—å£ï¼Œæ— éœ€é•¿æœŸä¿ç•™ï¼‰
// ç­‰å¾…æ—¶é—´æ ·æœ¬æ•°é…ç½®ï¼ˆæé«˜ç»Ÿè®¡ç½®ä¿¡åº¦ï¼‰
// - æ¯ API Key ä» 100 æé«˜åˆ° 500ï¼šæä¾›æ›´ç¨³å®šçš„ P99 ä¼°è®¡
// - å…¨å±€ä» 500 æé«˜åˆ° 2000ï¼šæ”¯æŒæ›´é«˜ç²¾åº¦çš„ P99.9 åˆ†æ
// - å†…å­˜å¼€é”€çº¦ 12-20KBï¼ˆRedis quicklist æ¯å…ƒç´  1-10 å­—èŠ‚ï¼‰ï¼Œå¯æ¥å—
// è¯¦è§ design.md Decision 5: ç­‰å¾…æ—¶é—´ç»Ÿè®¡æ ·æœ¬æ•°
const WAIT_TIME_SAMPLES_PER_KEY = 500 // æ¯ä¸ª API Key ä¿ç•™çš„ç­‰å¾…æ—¶é—´æ ·æœ¬æ•°
const WAIT_TIME_SAMPLES_GLOBAL = 2000 // å…¨å±€ä¿ç•™çš„ç­‰å¾…æ—¶é—´æ ·æœ¬æ•°
const QUEUE_TTL_BUFFER_SECONDS = 30 // æ’é˜Ÿè®¡æ•°å™¨TTLç¼“å†²æ—¶é—´

class RedisClient {
  constructor() {
    this.client = null
    this.isConnected = false
  }

  async connect() {
    try {
      this.client = new Redis({
        host: config.redis.host,
        port: config.redis.port,
        password: config.redis.password,
        db: config.redis.db,
        retryDelayOnFailover: config.redis.retryDelayOnFailover,
        maxRetriesPerRequest: config.redis.maxRetriesPerRequest,
        lazyConnect: config.redis.lazyConnect,
        tls: config.redis.enableTLS ? {} : false
      })

      this.client.on('connect', () => {
        this.isConnected = true
        logger.info('ğŸ”— Redis connected successfully')
      })

      this.client.on('error', (err) => {
        this.isConnected = false
        logger.error('âŒ Redis connection error:', err)
      })

      this.client.on('close', () => {
        this.isConnected = false
        logger.warn('âš ï¸  Redis connection closed')
      })

      // åªæœ‰åœ¨ lazyConnect æ¨¡å¼ä¸‹æ‰éœ€è¦æ‰‹åŠ¨è°ƒç”¨ connect()
      // å¦‚æœ Redis å·²ç»è¿æ¥æˆ–æ­£åœ¨è¿æ¥ä¸­ï¼Œåˆ™è·³è¿‡
      if (
        this.client.status !== 'connecting' &&
        this.client.status !== 'connect' &&
        this.client.status !== 'ready'
      ) {
        await this.client.connect()
      } else {
        // ç­‰å¾… ready çŠ¶æ€
        await new Promise((resolve, reject) => {
          if (this.client.status === 'ready') {
            resolve()
          } else {
            this.client.once('ready', resolve)
            this.client.once('error', reject)
          }
        })
      }
      return this.client
    } catch (error) {
      logger.error('ğŸ’¥ Failed to connect to Redis:', error)
      throw error
    }
  }

  // ğŸ”„ è‡ªåŠ¨è¿ç§» usage ç´¢å¼•ï¼ˆå¯åŠ¨æ—¶è°ƒç”¨ï¼‰
  async migrateUsageIndex() {
    const migrationKey = 'system:migration:usage_index_v2' // v2: æ·»åŠ  keymodel è¿ç§»
    const migrated = await this.client.get(migrationKey)
    if (migrated) {
      logger.debug('ğŸ“Š Usage index migration already completed')
      return
    }

    logger.info('ğŸ“Š Starting usage index migration...')
    const stats = { daily: 0, hourly: 0, modelDaily: 0, modelHourly: 0 }

    try {
      // è¿ç§» usage:daily
      let cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:daily:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          const match = key.match(/^usage:daily:([^:]+):(\d{4}-\d{2}-\d{2})$/)
          if (match) {
            pipeline.sadd(`usage:daily:index:${match[2]}`, match[1])
            pipeline.expire(`usage:daily:index:${match[2]}`, 86400 * 32)
            stats.daily++
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // è¿ç§» usage:hourly
      cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:hourly:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          const match = key.match(/^usage:hourly:([^:]+):(\d{4}-\d{2}-\d{2}:\d{2})$/)
          if (match) {
            pipeline.sadd(`usage:hourly:index:${match[2]}`, match[1])
            pipeline.expire(`usage:hourly:index:${match[2]}`, 86400 * 7)
            stats.hourly++
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // è¿ç§» usage:model:daily
      cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:model:daily:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          const match = key.match(/^usage:model:daily:([^:]+):(\d{4}-\d{2}-\d{2})$/)
          if (match) {
            pipeline.sadd(`usage:model:daily:index:${match[2]}`, match[1])
            pipeline.expire(`usage:model:daily:index:${match[2]}`, 86400 * 32)
            stats.modelDaily++
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // è¿ç§» usage:model:hourly
      cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:model:hourly:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          const match = key.match(/^usage:model:hourly:([^:]+):(\d{4}-\d{2}-\d{2}:\d{2})$/)
          if (match) {
            pipeline.sadd(`usage:model:hourly:index:${match[2]}`, match[1])
            pipeline.expire(`usage:model:hourly:index:${match[2]}`, 86400 * 7)
            stats.modelHourly++
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // è¿ç§» usage:keymodel:daily (usage:{keyId}:model:daily:{model}:{date})
      cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:*:model:daily:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          // usage:{keyId}:model:daily:{model}:{date}
          const match = key.match(/^usage:([^:]+):model:daily:(.+):(\d{4}-\d{2}-\d{2})$/)
          if (match) {
            const [, keyId, model, date] = match
            pipeline.sadd(`usage:keymodel:daily:index:${date}`, `${keyId}:${model}`)
            pipeline.expire(`usage:keymodel:daily:index:${date}`, 86400 * 32)
            stats.keymodelDaily = (stats.keymodelDaily || 0) + 1
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // è¿ç§» usage:keymodel:hourly (usage:{keyId}:model:hourly:{model}:{hour})
      cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:*:model:hourly:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          // usage:{keyId}:model:hourly:{model}:{hour}
          const match = key.match(/^usage:([^:]+):model:hourly:(.+):(\d{4}-\d{2}-\d{2}:\d{2})$/)
          if (match) {
            const [, keyId, model, hour] = match
            pipeline.sadd(`usage:keymodel:hourly:index:${hour}`, `${keyId}:${model}`)
            pipeline.expire(`usage:keymodel:hourly:index:${hour}`, 86400 * 7)
            stats.keymodelHourly = (stats.keymodelHourly || 0) + 1
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // æ ‡è®°è¿ç§»å®Œæˆ
      await this.client.set(migrationKey, Date.now().toString())
      logger.info(
        `ğŸ“Š Usage index migration completed: daily=${stats.daily}, hourly=${stats.hourly}, modelDaily=${stats.modelDaily}, modelHourly=${stats.modelHourly}, keymodelDaily=${stats.keymodelDaily || 0}, keymodelHourly=${stats.keymodelHourly || 0}`
      )
    } catch (error) {
      logger.error('ğŸ“Š Usage index migration failed:', error)
    }
  }

  // ğŸ”„ è‡ªåŠ¨è¿ç§» alltime æ¨¡å‹ç»Ÿè®¡ï¼ˆå¯åŠ¨æ—¶è°ƒç”¨ï¼‰
  async migrateAlltimeModelStats() {
    const migrationKey = 'system:migration:alltime_model_stats_v1'
    const migrated = await this.client.get(migrationKey)
    if (migrated) {
      logger.debug('ğŸ“Š Alltime model stats migration already completed')
      return
    }

    logger.info('ğŸ“Š Starting alltime model stats migration...')
    const stats = { keys: 0, models: 0 }

    try {
      // æ‰«ææ‰€æœ‰æœˆåº¦æ¨¡å‹ç»Ÿè®¡æ•°æ®å¹¶èšåˆåˆ° alltime
      // æ ¼å¼: usage:{keyId}:model:monthly:{model}:{month}
      let cursor = '0'
      const aggregatedData = new Map() // keyId:model -> {inputTokens, outputTokens, ...}

      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:*:model:monthly:*:*',
          'COUNT',
          500
        )
        cursor = newCursor

        for (const key of keys) {
          // usage:{keyId}:model:monthly:{model}:{month}
          const match = key.match(/^usage:([^:]+):model:monthly:(.+):(\d{4}-\d{2})$/)
          if (match) {
            const [, keyId, model] = match
            const aggregateKey = `${keyId}:${model}`

            // è·å–è¯¥æœˆçš„æ•°æ®
            const data = await this.client.hgetall(key)
            if (data && Object.keys(data).length > 0) {
              if (!aggregatedData.has(aggregateKey)) {
                aggregatedData.set(aggregateKey, {
                  keyId,
                  model,
                  inputTokens: 0,
                  outputTokens: 0,
                  cacheCreateTokens: 0,
                  cacheReadTokens: 0,
                  requests: 0
                })
              }

              const agg = aggregatedData.get(aggregateKey)
              agg.inputTokens += parseInt(data.inputTokens) || 0
              agg.outputTokens += parseInt(data.outputTokens) || 0
              agg.cacheCreateTokens += parseInt(data.cacheCreateTokens) || 0
              agg.cacheReadTokens += parseInt(data.cacheReadTokens) || 0
              agg.requests += parseInt(data.requests) || 0
              stats.keys++
            }
          }
        }
      } while (cursor !== '0')

      // å†™å…¥èšåˆåçš„ alltime æ•°æ®
      const pipeline = this.client.pipeline()
      for (const [, agg] of aggregatedData) {
        const alltimeKey = `usage:${agg.keyId}:model:alltime:${agg.model}`
        pipeline.hset(alltimeKey, {
          inputTokens: agg.inputTokens.toString(),
          outputTokens: agg.outputTokens.toString(),
          cacheCreateTokens: agg.cacheCreateTokens.toString(),
          cacheReadTokens: agg.cacheReadTokens.toString(),
          requests: agg.requests.toString()
        })
        stats.models++
      }

      if (stats.models > 0) {
        await pipeline.exec()
      }

      // æ ‡è®°è¿ç§»å®Œæˆ
      await this.client.set(migrationKey, Date.now().toString())
      logger.info(
        `ğŸ“Š Alltime model stats migration completed: scanned ${stats.keys} monthly keys, created ${stats.models} alltime keys`
      )
    } catch (error) {
      logger.error('ğŸ“Š Alltime model stats migration failed:', error)
    }
  }

  async disconnect() {
    if (this.client) {
      await this.client.quit()
      this.isConnected = false
      logger.info('ğŸ‘‹ Redis disconnected')
    }
  }

  getClient() {
    if (!this.client || !this.isConnected) {
      logger.warn('âš ï¸ Redis client is not connected')
      return null
    }
    return this.client
  }

  // å®‰å…¨è·å–å®¢æˆ·ç«¯ï¼ˆç”¨äºå…³é”®æ“ä½œï¼‰
  getClientSafe() {
    if (!this.client || !this.isConnected) {
      throw new Error('Redis client is not connected')
    }
    return this.client
  }

  // ğŸ”‘ API Key ç›¸å…³æ“ä½œ
  async setApiKey(keyId, keyData, hashedKey = null) {
    const key = `apikey:${keyId}`
    const client = this.getClientSafe()

    // ç»´æŠ¤å“ˆå¸Œæ˜ å°„è¡¨ï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼‰
    // hashedKeyå‚æ•°æ˜¯å®é™…çš„å“ˆå¸Œå€¼ï¼Œç”¨äºå»ºç«‹æ˜ å°„
    if (hashedKey) {
      await client.hset('apikey:hash_map', hashedKey, keyId)
    }

    await client.hset(key, keyData)
    await client.expire(key, 86400 * 365) // 1å¹´è¿‡æœŸ
  }

  async getApiKey(keyId) {
    const key = `apikey:${keyId}`
    return await this.client.hgetall(key)
  }

  async deleteApiKey(keyId) {
    const key = `apikey:${keyId}`

    // è·å–è¦åˆ é™¤çš„API Keyå“ˆå¸Œå€¼ï¼Œä»¥ä¾¿ä»æ˜ å°„è¡¨ä¸­ç§»é™¤
    const keyData = await this.client.hgetall(key)
    if (keyData && keyData.apiKey) {
      // keyData.apiKeyç°åœ¨å­˜å‚¨çš„æ˜¯å“ˆå¸Œå€¼ï¼Œç›´æ¥ä»æ˜ å°„è¡¨åˆ é™¤
      await this.client.hdel('apikey:hash_map', keyData.apiKey)
    }

    return await this.client.del(key)
  }

  async getAllApiKeys() {
    const keys = await this.scanKeys('apikey:*')
    const apiKeys = []
    const dataList = await this.batchHgetallChunked(keys)

    for (let i = 0; i < keys.length; i++) {
      const key = keys[i]
      // è¿‡æ»¤æ‰hash_mapï¼Œå®ƒä¸æ˜¯çœŸæ­£çš„API Key
      if (key === 'apikey:hash_map') {
        continue
      }

      const keyData = dataList[i]
      if (keyData && Object.keys(keyData).length > 0) {
        apiKeys.push({ id: key.replace('apikey:', ''), ...keyData })
      }
    }
    return apiKeys
  }

  /**
   * ä½¿ç”¨ SCAN è·å–æ‰€æœ‰ API Key IDï¼ˆé¿å… KEYS å‘½ä»¤é˜»å¡ï¼‰
   * @returns {Promise<string[]>} API Key ID åˆ—è¡¨ï¼ˆå·²å»é‡ï¼‰
   */
  async scanApiKeyIds() {
    const keyIds = new Set()
    let cursor = '0'
    // æ’é™¤ç´¢å¼• key çš„å‰ç¼€
    const excludePrefixes = [
      'apikey:hash_map',
      'apikey:idx:',
      'apikey:set:',
      'apikey:tags:',
      'apikey:index:'
    ]

    do {
      const [newCursor, keys] = await this.client.scan(cursor, 'MATCH', 'apikey:*', 'COUNT', 100)
      cursor = newCursor

      for (const key of keys) {
        // åªæ¥å— apikey:<uuid> å½¢æ€ï¼Œæ’é™¤ç´¢å¼• key
        if (excludePrefixes.some((prefix) => key.startsWith(prefix))) {
          continue
        }
        // ç¡®ä¿æ˜¯ apikey:<id> æ ¼å¼ï¼ˆåªæœ‰ä¸€ä¸ªå†’å·ï¼‰
        if (key.split(':').length !== 2) {
          continue
        }
        keyIds.add(key.replace('apikey:', ''))
      }
    } while (cursor !== '0')

    return [...keyIds]
  }

  // æ·»åŠ æ ‡ç­¾åˆ°å…¨å±€æ ‡ç­¾é›†åˆ
  async addTag(tagName) {
    await this.client.sadd('apikey:tags:all', tagName)
  }

  // ä»å…¨å±€æ ‡ç­¾é›†åˆåˆ é™¤æ ‡ç­¾
  async removeTag(tagName) {
    await this.client.srem('apikey:tags:all', tagName)
  }

  // è·å–å…¨å±€æ ‡ç­¾é›†åˆ
  async getGlobalTags() {
    return await this.client.smembers('apikey:tags:all')
  }

  /**
   * ä½¿ç”¨ç´¢å¼•è·å–æ‰€æœ‰ API Key çš„æ ‡ç­¾ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
   * ä¼˜å…ˆçº§ï¼šç´¢å¼•å°±ç»ªæ—¶ç”¨ apikey:tags:all > apikey:idx:all + pipeline > SCAN
   * @returns {Promise<string[]>} å»é‡æ’åºåçš„æ ‡ç­¾åˆ—è¡¨
   */
  async scanAllApiKeyTags() {
    // æ£€æŸ¥ç´¢å¼•æ˜¯å¦å°±ç»ªï¼ˆéé‡å»ºä¸­ä¸”ç‰ˆæœ¬å·æ­£ç¡®ï¼‰
    const isIndexReady = await this._checkIndexReady()

    if (isIndexReady) {
      // æ–¹æ¡ˆ1ï¼šç›´æ¥è¯»å–ç´¢å¼•æœåŠ¡ç»´æŠ¤çš„æ ‡ç­¾é›†åˆ
      const cachedTags = await this.client.smembers('apikey:tags:all')
      if (cachedTags && cachedTags.length > 0) {
        // ä¿æŒ trim ä¸€è‡´æ€§
        return cachedTags
          .map((t) => (t ? t.trim() : ''))
          .filter((t) => t)
          .sort()
      }

      // æ–¹æ¡ˆ2ï¼šä½¿ç”¨ç´¢å¼•çš„ key ID åˆ—è¡¨ + pipeline
      const indexedKeyIds = await this.client.smembers('apikey:idx:all')
      if (indexedKeyIds && indexedKeyIds.length > 0) {
        return this._extractTagsFromKeyIds(indexedKeyIds)
      }
    }

    // æ–¹æ¡ˆ3ï¼šå›é€€åˆ° SCANï¼ˆç´¢å¼•æœªå°±ç»ªæˆ–é‡å»ºä¸­ï¼‰
    return this._scanTagsFallback()
  }

  /**
   * æ£€æŸ¥ç´¢å¼•æ˜¯å¦å°±ç»ª
   */
  async _checkIndexReady() {
    try {
      const version = await this.client.get('apikey:index:version')
      // ç‰ˆæœ¬å· >= 2 è¡¨ç¤ºç´¢å¼•å°±ç»ª
      return parseInt(version) >= 2
    } catch {
      return false
    }
  }

  async _extractTagsFromKeyIds(keyIds) {
    const tagSet = new Set()
    const pipeline = this.client.pipeline()
    for (const keyId of keyIds) {
      pipeline.hmget(`apikey:${keyId}`, 'tags', 'isDeleted')
    }

    const results = await pipeline.exec()
    if (!results) {
      return []
    }

    for (const result of results) {
      if (!result) {
        continue
      }
      const [err, values] = result
      if (err || !values) {
        continue
      }
      const [tags, isDeleted] = values
      if (isDeleted === 'true' || !tags) {
        continue
      }

      try {
        const parsed = JSON.parse(tags)
        if (Array.isArray(parsed)) {
          for (const tag of parsed) {
            if (tag && typeof tag === 'string' && tag.trim()) {
              tagSet.add(tag.trim())
            }
          }
        }
      } catch {
        // å¿½ç•¥è§£æé”™è¯¯
      }
    }
    return Array.from(tagSet).sort()
  }

  async _scanTagsFallback() {
    const tagSet = new Set()
    let cursor = '0'

    do {
      const [newCursor, keys] = await this.client.scan(cursor, 'MATCH', 'apikey:*', 'COUNT', 100)
      cursor = newCursor

      const validKeys = keys.filter((k) => k !== 'apikey:hash_map' && k.split(':').length === 2)
      if (validKeys.length === 0) {
        continue
      }

      const pipeline = this.client.pipeline()
      for (const key of validKeys) {
        pipeline.hmget(key, 'tags', 'isDeleted')
      }

      const results = await pipeline.exec()
      if (!results) {
        continue
      }

      for (const result of results) {
        if (!result) {
          continue
        }
        const [err, values] = result
        if (err || !values) {
          continue
        }
        const [tags, isDeleted] = values
        if (isDeleted === 'true' || !tags) {
          continue
        }

        try {
          const parsed = JSON.parse(tags)
          if (Array.isArray(parsed)) {
            for (const tag of parsed) {
              if (tag && typeof tag === 'string' && tag.trim()) {
                tagSet.add(tag.trim())
              }
            }
          }
        } catch {
          // å¿½ç•¥è§£æé”™è¯¯
        }
      }
    } while (cursor !== '0')

    return Array.from(tagSet).sort()
  }

  /**
   * æ‰¹é‡è·å– API Key æ•°æ®ï¼ˆä½¿ç”¨ Pipeline ä¼˜åŒ–ï¼‰
   * @param {string[]} keyIds - API Key ID åˆ—è¡¨
   * @returns {Promise<Object[]>} API Key æ•°æ®åˆ—è¡¨
   */
  async batchGetApiKeys(keyIds) {
    if (!keyIds || keyIds.length === 0) {
      return []
    }

    const pipeline = this.client.pipeline()
    for (const keyId of keyIds) {
      pipeline.hgetall(`apikey:${keyId}`)
    }

    const results = await pipeline.exec()
    const apiKeys = []

    for (let i = 0; i < results.length; i++) {
      const [err, data] = results[i]
      if (!err && data && Object.keys(data).length > 0) {
        apiKeys.push({ id: keyIds[i], ...this._parseApiKeyData(data) })
      }
    }

    return apiKeys
  }

  /**
   * è§£æ API Key æ•°æ®ï¼Œå°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ­£ç¡®çš„ç±»å‹
   * @param {Object} data - åŸå§‹æ•°æ®
   * @returns {Object} è§£æåçš„æ•°æ®
   */
  _parseApiKeyData(data) {
    if (!data) {
      return data
    }

    const parsed = { ...data }

    // å¸ƒå°”å­—æ®µ
    const boolFields = ['isActive', 'enableModelRestriction', 'isDeleted']
    for (const field of boolFields) {
      if (parsed[field] !== undefined) {
        parsed[field] = parsed[field] === 'true'
      }
    }

    // æ•°å­—å­—æ®µ
    const numFields = [
      'tokenLimit',
      'dailyCostLimit',
      'totalCostLimit',
      'rateLimitRequests',
      'rateLimitTokens',
      'rateLimitWindow',
      'rateLimitCost',
      'maxConcurrency',
      'activationDuration'
    ]
    for (const field of numFields) {
      if (parsed[field] !== undefined && parsed[field] !== '') {
        parsed[field] = parseFloat(parsed[field]) || 0
      }
    }

    // æ•°ç»„å­—æ®µï¼ˆJSON è§£æï¼‰
    const arrayFields = ['tags', 'restrictedModels', 'allowedClients']
    for (const field of arrayFields) {
      if (parsed[field]) {
        try {
          parsed[field] = JSON.parse(parsed[field])
        } catch (e) {
          parsed[field] = []
        }
      }
    }

    // å¯¹è±¡å­—æ®µï¼ˆJSON è§£æï¼‰
    const objectFields = ['serviceRates']
    for (const field of objectFields) {
      if (parsed[field]) {
        try {
          parsed[field] = JSON.parse(parsed[field])
        } catch (e) {
          parsed[field] = {}
        }
      }
    }

    return parsed
  }

  /**
   * è·å– API Keys åˆ†é¡µæ•°æ®ï¼ˆä¸å«è´¹ç”¨ï¼Œç”¨äºä¼˜åŒ–åˆ—è¡¨åŠ è½½ï¼‰
   * @param {Object} options - åˆ†é¡µå’Œç­›é€‰é€‰é¡¹
   * @returns {Promise<{items: Object[], pagination: Object, availableTags: string[]}>}
   */
  async getApiKeysPaginated(options = {}) {
    const {
      page = 1,
      pageSize = 20,
      searchMode = 'apiKey',
      search = '',
      tag = '',
      isActive = '',
      sortBy = 'createdAt',
      sortOrder = 'desc',
      excludeDeleted = true, // é»˜è®¤æ’é™¤å·²åˆ é™¤çš„ API Keys
      modelFilter = []
    } = options

    // å°è¯•ä½¿ç”¨ç´¢å¼•æŸ¥è¯¢ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
    const apiKeyIndexService = require('../services/apiKeyIndexService')
    const indexReady = await apiKeyIndexService.isIndexReady()

    // ç´¢å¼•è·¯å¾„æ”¯æŒçš„æ¡ä»¶ï¼š
    // - æ— æ¨¡å‹ç­›é€‰ï¼ˆéœ€è¦æŸ¥è¯¢ä½¿ç”¨è®°å½•ï¼‰
    // - é bindingAccount æœç´¢æ¨¡å¼ï¼ˆç´¢å¼•ä¸æ”¯æŒï¼‰
    // - é status/expiresAt æ’åºï¼ˆç´¢å¼•ä¸æ”¯æŒï¼‰
    // - æ— æœç´¢å…³é”®è¯ï¼ˆç´¢å¼•åªæœ nameï¼Œæ—§é€»è¾‘æœ name+ownerï¼Œä¸ä¸€è‡´ï¼‰
    const canUseIndex =
      indexReady &&
      modelFilter.length === 0 &&
      searchMode !== 'bindingAccount' &&
      !['status', 'expiresAt'].includes(sortBy) &&
      !search

    if (canUseIndex) {
      // ä½¿ç”¨ç´¢å¼•æŸ¥è¯¢
      try {
        return await apiKeyIndexService.queryWithIndex({
          page,
          pageSize,
          sortBy,
          sortOrder,
          isActive: isActive === '' ? undefined : isActive === 'true' || isActive === true,
          tag,
          excludeDeleted
        })
      } catch (error) {
        logger.warn('âš ï¸ ç´¢å¼•æŸ¥è¯¢å¤±è´¥ï¼Œé™çº§åˆ°å…¨é‡æ‰«æ:', error.message)
      }
    }

    // é™çº§ï¼šä½¿ç”¨ SCAN è·å–æ‰€æœ‰ apikey:* çš„ ID åˆ—è¡¨ï¼ˆé¿å…é˜»å¡ï¼‰
    const keyIds = await this.scanApiKeyIds()

    // 2. ä½¿ç”¨ Pipeline æ‰¹é‡è·å–åŸºç¡€æ•°æ®
    const apiKeys = await this.batchGetApiKeys(keyIds)

    // 3. åº”ç”¨ç­›é€‰æ¡ä»¶
    let filteredKeys = apiKeys

    // æ’é™¤å·²åˆ é™¤çš„ API Keysï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
    if (excludeDeleted) {
      filteredKeys = filteredKeys.filter((k) => !k.isDeleted)
    }

    // çŠ¶æ€ç­›é€‰
    if (isActive !== '' && isActive !== undefined && isActive !== null) {
      const activeValue = isActive === 'true' || isActive === true
      filteredKeys = filteredKeys.filter((k) => k.isActive === activeValue)
    }

    // æ ‡ç­¾ç­›é€‰
    if (tag) {
      filteredKeys = filteredKeys.filter((k) => {
        const tags = Array.isArray(k.tags) ? k.tags : []
        return tags.includes(tag)
      })
    }

    // æœç´¢
    if (search) {
      const lowerSearch = search.toLowerCase().trim()
      if (searchMode === 'apiKey') {
        // apiKey æ¨¡å¼ï¼šæœç´¢åç§°å’Œæ‹¥æœ‰è€…
        filteredKeys = filteredKeys.filter(
          (k) =>
            (k.name && k.name.toLowerCase().includes(lowerSearch)) ||
            (k.ownerDisplayName && k.ownerDisplayName.toLowerCase().includes(lowerSearch))
        )
      } else if (searchMode === 'bindingAccount') {
        // bindingAccount æ¨¡å¼ï¼šç›´æ¥åœ¨Rediså±‚å¤„ç†ï¼Œé¿å…è·¯ç”±å±‚åŠ è½½10000æ¡
        const accountNameCacheService = require('../services/accountNameCacheService')
        filteredKeys = accountNameCacheService.searchByBindingAccount(filteredKeys, lowerSearch)
      }
    }

    // æ¨¡å‹ç­›é€‰
    if (modelFilter.length > 0) {
      const keyIdsWithModels = await this.getKeyIdsWithModels(
        filteredKeys.map((k) => k.id),
        modelFilter
      )
      filteredKeys = filteredKeys.filter((k) => keyIdsWithModels.has(k.id))
    }

    // 4. æ’åº
    filteredKeys.sort((a, b) => {
      // status æ’åºå®é™…ä¸Šä½¿ç”¨ isActive å­—æ®µï¼ˆAPI Key æ²¡æœ‰ status å­—æ®µï¼‰
      const effectiveSortBy = sortBy === 'status' ? 'isActive' : sortBy
      let aVal = a[effectiveSortBy]
      let bVal = b[effectiveSortBy]

      // æ—¥æœŸå­—æ®µè½¬æ—¶é—´æˆ³
      if (['createdAt', 'expiresAt', 'lastUsedAt'].includes(effectiveSortBy)) {
        aVal = aVal ? new Date(aVal).getTime() : 0
        bVal = bVal ? new Date(bVal).getTime() : 0
      }

      // å¸ƒå°”å­—æ®µè½¬æ•°å­—
      if (effectiveSortBy === 'isActive') {
        aVal = aVal ? 1 : 0
        bVal = bVal ? 1 : 0
      }

      // å­—ç¬¦ä¸²å­—æ®µ
      if (sortBy === 'name') {
        aVal = (aVal || '').toLowerCase()
        bVal = (bVal || '').toLowerCase()
      }

      if (aVal < bVal) {
        return sortOrder === 'asc' ? -1 : 1
      }
      if (aVal > bVal) {
        return sortOrder === 'asc' ? 1 : -1
      }
      return 0
    })

    // 5. æ”¶é›†æ‰€æœ‰å¯ç”¨æ ‡ç­¾ï¼ˆåœ¨åˆ†é¡µä¹‹å‰ï¼‰
    const allTags = new Set()
    for (const key of apiKeys) {
      const tags = Array.isArray(key.tags) ? key.tags : []
      tags.forEach((t) => allTags.add(t))
    }
    const availableTags = [...allTags].sort()

    // 6. åˆ†é¡µ
    const total = filteredKeys.length
    const totalPages = Math.ceil(total / pageSize) || 1
    const validPage = Math.min(Math.max(1, page), totalPages)
    const start = (validPage - 1) * pageSize
    const items = filteredKeys.slice(start, start + pageSize)

    return {
      items,
      pagination: {
        page: validPage,
        pageSize,
        total,
        totalPages
      },
      availableTags
    }
  }

  // ğŸ” é€šè¿‡å“ˆå¸Œå€¼æŸ¥æ‰¾API Keyï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
  async findApiKeyByHash(hashedKey) {
    // ä½¿ç”¨åå‘æ˜ å°„è¡¨ï¼šhash -> keyId
    let keyId = await this.client.hget('apikey:hash_map', hashedKey)

    // å›é€€ï¼šæŸ¥æ—§ç»“æ„ apikey_hash:*ï¼ˆå¯åŠ¨å›å¡«æœªå®Œæˆæ—¶å…¼å®¹ï¼‰
    if (!keyId) {
      const oldData = await this.client.hgetall(`apikey_hash:${hashedKey}`)
      if (oldData && oldData.id) {
        keyId = oldData.id
        // å›å¡«åˆ° hash_map
        await this.client.hset('apikey:hash_map', hashedKey, keyId)
      }
    }

    if (!keyId) {
      return null
    }

    const keyData = await this.client.hgetall(`apikey:${keyId}`)
    if (keyData && Object.keys(keyData).length > 0) {
      return { id: keyId, ...keyData }
    }

    // å¦‚æœæ•°æ®ä¸å­˜åœ¨ï¼Œæ¸…ç†æ˜ å°„è¡¨
    await this.client.hdel('apikey:hash_map', hashedKey)
    return null
  }

  // ğŸ“Š ä½¿ç”¨ç»Ÿè®¡ç›¸å…³æ“ä½œï¼ˆæ”¯æŒç¼“å­˜tokenç»Ÿè®¡å’Œæ¨¡å‹ä¿¡æ¯ï¼‰
  // æ ‡å‡†åŒ–æ¨¡å‹åç§°ï¼Œç”¨äºç»Ÿè®¡èšåˆ
  _normalizeModelName(model) {
    if (!model || model === 'unknown') {
      return model
    }

    // å¯¹äºBedrockæ¨¡å‹ï¼Œå»æ‰åŒºåŸŸå‰ç¼€è¿›è¡Œç»Ÿä¸€
    if (model.includes('.anthropic.') || model.includes('.claude')) {
      // åŒ¹é…æ‰€æœ‰AWSåŒºåŸŸæ ¼å¼ï¼šregion.anthropic.model-name-v1:0 -> claude-model-name
      // æ”¯æŒæ‰€æœ‰AWSåŒºåŸŸæ ¼å¼ï¼Œå¦‚ï¼šus-east-1, eu-west-1, ap-southeast-1, ca-central-1ç­‰
      let normalized = model.replace(/^[a-z0-9-]+\./, '') // å»æ‰ä»»ä½•åŒºåŸŸå‰ç¼€ï¼ˆæ›´é€šç”¨ï¼‰
      normalized = normalized.replace('anthropic.', '') // å»æ‰anthropicå‰ç¼€
      normalized = normalized.replace(/-v\d+:\d+$/, '') // å»æ‰ç‰ˆæœ¬åç¼€ï¼ˆå¦‚-v1:0, -v2:1ç­‰ï¼‰
      return normalized
    }

    // å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œå»æ‰å¸¸è§çš„ç‰ˆæœ¬åç¼€
    return model.replace(/-v\d+:\d+$|:latest$/, '')
  }

  async incrementTokenUsage(
    keyId,
    tokens,
    inputTokens = 0,
    outputTokens = 0,
    cacheCreateTokens = 0,
    cacheReadTokens = 0,
    model = 'unknown',
    ephemeral5mTokens = 0, // æ–°å¢ï¼š5åˆ†é’Ÿç¼“å­˜ tokens
    ephemeral1hTokens = 0, // æ–°å¢ï¼š1å°æ—¶ç¼“å­˜ tokens
    isLongContextRequest = false, // æ–°å¢ï¼šæ˜¯å¦ä¸º 1M ä¸Šä¸‹æ–‡è¯·æ±‚ï¼ˆè¶…è¿‡200kï¼‰
    realCost = 0, // çœŸå®è´¹ç”¨ï¼ˆå®˜æ–¹APIè´¹ç”¨ï¼‰
    ratedCost = 0 // è®¡è´¹è´¹ç”¨ï¼ˆåº”ç”¨å€ç‡åï¼‰
  ) {
    const key = `usage:${keyId}`
    const now = new Date()
    const today = getDateStringInTimezone(now)
    const tzDate = getDateInTimezone(now)
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const currentHour = `${today}:${String(getHourInTimezone(now)).padStart(2, '0')}` // æ–°å¢å°æ—¶çº§åˆ«

    const daily = `usage:daily:${keyId}:${today}`
    const monthly = `usage:monthly:${keyId}:${currentMonth}`
    const hourly = `usage:hourly:${keyId}:${currentHour}` // æ–°å¢å°æ—¶çº§åˆ«key

    // æ ‡å‡†åŒ–æ¨¡å‹åç”¨äºç»Ÿè®¡èšåˆ
    const normalizedModel = this._normalizeModelName(model)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡çš„é”®
    const modelDaily = `usage:model:daily:${normalizedModel}:${today}`
    const modelMonthly = `usage:model:monthly:${normalizedModel}:${currentMonth}`
    const modelHourly = `usage:model:hourly:${normalizedModel}:${currentHour}` // æ–°å¢æ¨¡å‹å°æ—¶çº§åˆ«

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡
    const keyModelDaily = `usage:${keyId}:model:daily:${normalizedModel}:${today}`
    const keyModelMonthly = `usage:${keyId}:model:monthly:${normalizedModel}:${currentMonth}`
    const keyModelHourly = `usage:${keyId}:model:hourly:${normalizedModel}:${currentHour}` // æ–°å¢API Keyæ¨¡å‹å°æ—¶çº§åˆ«

    // æ–°å¢ï¼šç³»ç»Ÿçº§åˆ†é’Ÿç»Ÿè®¡
    const minuteTimestamp = Math.floor(now.getTime() / 60000)
    const systemMinuteKey = `system:metrics:minute:${minuteTimestamp}`

    // æ™ºèƒ½å¤„ç†è¾“å…¥è¾“å‡ºtokenåˆ†é…
    const finalInputTokens = inputTokens || 0
    const finalOutputTokens = outputTokens || (finalInputTokens > 0 ? 0 : tokens)
    const finalCacheCreateTokens = cacheCreateTokens || 0
    const finalCacheReadTokens = cacheReadTokens || 0

    // é‡æ–°è®¡ç®—çœŸå®çš„æ€»tokenæ•°ï¼ˆåŒ…æ‹¬ç¼“å­˜tokenï¼‰
    const totalTokens =
      finalInputTokens + finalOutputTokens + finalCacheCreateTokens + finalCacheReadTokens
    // æ ¸å¿ƒtokenï¼ˆä¸åŒ…æ‹¬ç¼“å­˜ï¼‰- ç”¨äºä¸å†å²æ•°æ®å…¼å®¹
    const coreTokens = finalInputTokens + finalOutputTokens

    // ä½¿ç”¨Pipelineä¼˜åŒ–æ€§èƒ½
    const pipeline = this.client.pipeline()

    // ç°æœ‰çš„ç»Ÿè®¡ä¿æŒä¸å˜
    // æ ¸å¿ƒtokenç»Ÿè®¡ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    pipeline.hincrby(key, 'totalTokens', coreTokens)
    pipeline.hincrby(key, 'totalInputTokens', finalInputTokens)
    pipeline.hincrby(key, 'totalOutputTokens', finalOutputTokens)
    // ç¼“å­˜tokenç»Ÿè®¡ï¼ˆæ–°å¢ï¼‰
    pipeline.hincrby(key, 'totalCacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(key, 'totalCacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(key, 'totalAllTokens', totalTokens) // åŒ…å«æ‰€æœ‰ç±»å‹çš„æ€»token
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡ï¼ˆæ–°å¢ï¼‰
    pipeline.hincrby(key, 'totalEphemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(key, 'totalEphemeral1hTokens', ephemeral1hTokens)
    // 1M ä¸Šä¸‹æ–‡è¯·æ±‚ç»Ÿè®¡ï¼ˆæ–°å¢ï¼‰
    if (isLongContextRequest) {
      pipeline.hincrby(key, 'totalLongContextInputTokens', finalInputTokens)
      pipeline.hincrby(key, 'totalLongContextOutputTokens', finalOutputTokens)
      pipeline.hincrby(key, 'totalLongContextRequests', 1)
    }
    // è¯·æ±‚è®¡æ•°
    pipeline.hincrby(key, 'totalRequests', 1)

    // æ¯æ—¥ç»Ÿè®¡
    pipeline.hincrby(daily, 'tokens', coreTokens)
    pipeline.hincrby(daily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(daily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(daily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(daily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(daily, 'allTokens', totalTokens)
    pipeline.hincrby(daily, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(daily, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(daily, 'ephemeral1hTokens', ephemeral1hTokens)
    // 1M ä¸Šä¸‹æ–‡è¯·æ±‚ç»Ÿè®¡
    if (isLongContextRequest) {
      pipeline.hincrby(daily, 'longContextInputTokens', finalInputTokens)
      pipeline.hincrby(daily, 'longContextOutputTokens', finalOutputTokens)
      pipeline.hincrby(daily, 'longContextRequests', 1)
    }

    // æ¯æœˆç»Ÿè®¡
    pipeline.hincrby(monthly, 'tokens', coreTokens)
    pipeline.hincrby(monthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(monthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(monthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(monthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(monthly, 'allTokens', totalTokens)
    pipeline.hincrby(monthly, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(monthly, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(monthly, 'ephemeral1hTokens', ephemeral1hTokens)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æ—¥
    pipeline.hincrby(modelDaily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelDaily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelDaily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelDaily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelDaily, 'allTokens', totalTokens)
    pipeline.hincrby(modelDaily, 'requests', 1)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æœˆ
    pipeline.hincrby(modelMonthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelMonthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelMonthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelMonthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelMonthly, 'allTokens', totalTokens)
    pipeline.hincrby(modelMonthly, 'requests', 1)

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡ - æ¯æ—¥
    pipeline.hincrby(keyModelDaily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelDaily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelDaily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelDaily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelDaily, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelDaily, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(keyModelDaily, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(keyModelDaily, 'ephemeral1hTokens', ephemeral1hTokens)
    // è´¹ç”¨ç»Ÿè®¡ï¼ˆä½¿ç”¨æ•´æ•°å­˜å‚¨ï¼Œå•ä½ï¼šå¾®ç¾å…ƒï¼Œ1ç¾å…ƒ=1000000å¾®ç¾å…ƒï¼‰
    if (realCost > 0) {
      pipeline.hincrby(keyModelDaily, 'realCostMicro', Math.round(realCost * 1000000))
    }
    if (ratedCost > 0) {
      pipeline.hincrby(keyModelDaily, 'ratedCostMicro', Math.round(ratedCost * 1000000))
    }

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡ - æ¯æœˆ
    pipeline.hincrby(keyModelMonthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelMonthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelMonthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelMonthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelMonthly, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelMonthly, 'requests', 1)
    // è¯¦ç»†ç¼“å­˜ç±»å‹ç»Ÿè®¡
    pipeline.hincrby(keyModelMonthly, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(keyModelMonthly, 'ephemeral1hTokens', ephemeral1hTokens)
    // è´¹ç”¨ç»Ÿè®¡
    if (realCost > 0) {
      pipeline.hincrby(keyModelMonthly, 'realCostMicro', Math.round(realCost * 1000000))
    }
    if (ratedCost > 0) {
      pipeline.hincrby(keyModelMonthly, 'ratedCostMicro', Math.round(ratedCost * 1000000))
    }

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡ - æ‰€æœ‰æ—¶é—´ï¼ˆæ—  TTLï¼‰
    const keyModelAlltime = `usage:${keyId}:model:alltime:${normalizedModel}`
    pipeline.hincrby(keyModelAlltime, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelAlltime, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelAlltime, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelAlltime, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelAlltime, 'requests', 1)
    // è´¹ç”¨ç»Ÿè®¡
    if (realCost > 0) {
      pipeline.hincrby(keyModelAlltime, 'realCostMicro', Math.round(realCost * 1000000))
    }
    if (ratedCost > 0) {
      pipeline.hincrby(keyModelAlltime, 'ratedCostMicro', Math.round(ratedCost * 1000000))
    }

    // å°æ—¶çº§åˆ«ç»Ÿè®¡
    pipeline.hincrby(hourly, 'tokens', coreTokens)
    pipeline.hincrby(hourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(hourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(hourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(hourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(hourly, 'allTokens', totalTokens)
    pipeline.hincrby(hourly, 'requests', 1)

    // æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯å°æ—¶
    pipeline.hincrby(modelHourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelHourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelHourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelHourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelHourly, 'allTokens', totalTokens)
    pipeline.hincrby(modelHourly, 'requests', 1)

    // API Keyçº§åˆ«çš„æ¨¡å‹ç»Ÿè®¡ - æ¯å°æ—¶
    pipeline.hincrby(keyModelHourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelHourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelHourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelHourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelHourly, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelHourly, 'requests', 1)
    // è´¹ç”¨ç»Ÿè®¡
    if (realCost > 0) {
      pipeline.hincrby(keyModelHourly, 'realCostMicro', Math.round(realCost * 1000000))
    }
    if (ratedCost > 0) {
      pipeline.hincrby(keyModelHourly, 'ratedCostMicro', Math.round(ratedCost * 1000000))
    }

    // æ–°å¢ï¼šç³»ç»Ÿçº§åˆ†é’Ÿç»Ÿè®¡
    pipeline.hincrby(systemMinuteKey, 'requests', 1)
    pipeline.hincrby(systemMinuteKey, 'totalTokens', totalTokens)
    pipeline.hincrby(systemMinuteKey, 'inputTokens', finalInputTokens)
    pipeline.hincrby(systemMinuteKey, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(systemMinuteKey, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(systemMinuteKey, 'cacheReadTokens', finalCacheReadTokens)

    // è®¾ç½®è¿‡æœŸæ—¶é—´
    pipeline.expire(daily, 86400 * 32) // 32å¤©è¿‡æœŸ
    pipeline.expire(monthly, 86400 * 365) // 1å¹´è¿‡æœŸ
    pipeline.expire(hourly, 86400 * 7) // å°æ—¶ç»Ÿè®¡7å¤©è¿‡æœŸ
    pipeline.expire(modelDaily, 86400 * 32) // æ¨¡å‹æ¯æ—¥ç»Ÿè®¡32å¤©è¿‡æœŸ
    pipeline.expire(modelMonthly, 86400 * 365) // æ¨¡å‹æ¯æœˆç»Ÿè®¡1å¹´è¿‡æœŸ
    pipeline.expire(modelHourly, 86400 * 7) // æ¨¡å‹å°æ—¶ç»Ÿè®¡7å¤©è¿‡æœŸ
    pipeline.expire(keyModelDaily, 86400 * 32) // API Keyæ¨¡å‹æ¯æ—¥ç»Ÿè®¡32å¤©è¿‡æœŸ
    pipeline.expire(keyModelMonthly, 86400 * 365) // API Keyæ¨¡å‹æ¯æœˆç»Ÿè®¡1å¹´è¿‡æœŸ
    pipeline.expire(keyModelHourly, 86400 * 7) // API Keyæ¨¡å‹å°æ—¶ç»Ÿè®¡7å¤©è¿‡æœŸ

    // ç³»ç»Ÿçº§åˆ†é’Ÿç»Ÿè®¡çš„è¿‡æœŸæ—¶é—´ï¼ˆçª—å£æ—¶é—´çš„2å€ï¼Œé»˜è®¤5åˆ†é’Ÿï¼‰
    const configLocal = require('../../config/config')
    const metricsWindow = configLocal.system?.metricsWindow || 5
    pipeline.expire(systemMinuteKey, metricsWindow * 60 * 2)

    // æ·»åŠ ç´¢å¼•ï¼ˆç”¨äºå¿«é€ŸæŸ¥è¯¢ï¼Œé¿å… SCANï¼‰
    pipeline.sadd(`usage:daily:index:${today}`, keyId)
    pipeline.sadd(`usage:hourly:index:${currentHour}`, keyId)
    pipeline.sadd(`usage:model:daily:index:${today}`, normalizedModel)
    pipeline.sadd(`usage:model:hourly:index:${currentHour}`, normalizedModel)
    pipeline.sadd(`usage:model:monthly:index:${currentMonth}`, normalizedModel)
    pipeline.sadd('usage:model:monthly:months', currentMonth) // å…¨å±€æœˆä»½ç´¢å¼•
    pipeline.sadd(`usage:keymodel:daily:index:${today}`, `${keyId}:${normalizedModel}`)
    pipeline.sadd(`usage:keymodel:hourly:index:${currentHour}`, `${keyId}:${normalizedModel}`)
    // æ¸…ç†ç©ºæ ‡è®°ï¼ˆæœ‰æ–°æ•°æ®æ—¶ï¼‰
    pipeline.del(`usage:daily:index:${today}:empty`)
    pipeline.del(`usage:hourly:index:${currentHour}:empty`)
    pipeline.del(`usage:model:daily:index:${today}:empty`)
    pipeline.del(`usage:model:hourly:index:${currentHour}:empty`)
    pipeline.del(`usage:model:monthly:index:${currentMonth}:empty`)
    pipeline.del(`usage:keymodel:daily:index:${today}:empty`)
    pipeline.del(`usage:keymodel:hourly:index:${currentHour}:empty`)
    // ç´¢å¼•è¿‡æœŸæ—¶é—´
    pipeline.expire(`usage:daily:index:${today}`, 86400 * 32)
    pipeline.expire(`usage:hourly:index:${currentHour}`, 86400 * 7)
    pipeline.expire(`usage:model:daily:index:${today}`, 86400 * 32)
    pipeline.expire(`usage:model:hourly:index:${currentHour}`, 86400 * 7)
    pipeline.expire(`usage:model:monthly:index:${currentMonth}`, 86400 * 365)
    pipeline.expire(`usage:keymodel:daily:index:${today}`, 86400 * 32)
    pipeline.expire(`usage:keymodel:hourly:index:${currentHour}`, 86400 * 7)

    // å…¨å±€é¢„èšåˆç»Ÿè®¡
    const globalDaily = `usage:global:daily:${today}`
    const globalMonthly = `usage:global:monthly:${currentMonth}`
    pipeline.hincrby('usage:global:total', 'requests', 1)
    pipeline.hincrby('usage:global:total', 'inputTokens', finalInputTokens)
    pipeline.hincrby('usage:global:total', 'outputTokens', finalOutputTokens)
    pipeline.hincrby('usage:global:total', 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby('usage:global:total', 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby('usage:global:total', 'allTokens', totalTokens)
    pipeline.hincrby(globalDaily, 'requests', 1)
    pipeline.hincrby(globalDaily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(globalDaily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(globalDaily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(globalDaily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(globalDaily, 'allTokens', totalTokens)
    pipeline.hincrby(globalMonthly, 'requests', 1)
    pipeline.hincrby(globalMonthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(globalMonthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(globalMonthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(globalMonthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(globalMonthly, 'allTokens', totalTokens)
    pipeline.expire(globalDaily, 86400 * 32)
    pipeline.expire(globalMonthly, 86400 * 365)

    // æ‰§è¡ŒPipeline
    await pipeline.exec()
  }

  // ğŸ“Š è®°å½•è´¦æˆ·çº§åˆ«çš„ä½¿ç”¨ç»Ÿè®¡
  async incrementAccountUsage(
    accountId,
    totalTokens,
    inputTokens = 0,
    outputTokens = 0,
    cacheCreateTokens = 0,
    cacheReadTokens = 0,
    model = 'unknown',
    isLongContextRequest = false
  ) {
    const now = new Date()
    const today = getDateStringInTimezone(now)
    const tzDate = getDateInTimezone(now)
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const currentHour = `${today}:${String(getHourInTimezone(now)).padStart(2, '0')}`

    // è´¦æˆ·çº§åˆ«ç»Ÿè®¡çš„é”®
    const accountKey = `account_usage:${accountId}`
    const accountDaily = `account_usage:daily:${accountId}:${today}`
    const accountMonthly = `account_usage:monthly:${accountId}:${currentMonth}`
    const accountHourly = `account_usage:hourly:${accountId}:${currentHour}`

    // æ ‡å‡†åŒ–æ¨¡å‹åç”¨äºç»Ÿè®¡èšåˆ
    const normalizedModel = this._normalizeModelName(model)

    // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡çš„é”®
    const accountModelDaily = `account_usage:model:daily:${accountId}:${normalizedModel}:${today}`
    const accountModelMonthly = `account_usage:model:monthly:${accountId}:${normalizedModel}:${currentMonth}`
    const accountModelHourly = `account_usage:model:hourly:${accountId}:${normalizedModel}:${currentHour}`

    // å¤„ç†tokenåˆ†é…
    const finalInputTokens = inputTokens || 0
    const finalOutputTokens = outputTokens || 0
    const finalCacheCreateTokens = cacheCreateTokens || 0
    const finalCacheReadTokens = cacheReadTokens || 0
    const actualTotalTokens =
      finalInputTokens + finalOutputTokens + finalCacheCreateTokens + finalCacheReadTokens
    const coreTokens = finalInputTokens + finalOutputTokens

    // æ„å»ºç»Ÿè®¡æ“ä½œæ•°ç»„
    const operations = [
      // è´¦æˆ·æ€»ä½“ç»Ÿè®¡
      this.client.hincrby(accountKey, 'totalTokens', coreTokens),
      this.client.hincrby(accountKey, 'totalInputTokens', finalInputTokens),
      this.client.hincrby(accountKey, 'totalOutputTokens', finalOutputTokens),
      this.client.hincrby(accountKey, 'totalCacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountKey, 'totalCacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountKey, 'totalAllTokens', actualTotalTokens),
      this.client.hincrby(accountKey, 'totalRequests', 1),

      // è´¦æˆ·æ¯æ—¥ç»Ÿè®¡
      this.client.hincrby(accountDaily, 'tokens', coreTokens),
      this.client.hincrby(accountDaily, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountDaily, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountDaily, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountDaily, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountDaily, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountDaily, 'requests', 1),

      // è´¦æˆ·æ¯æœˆç»Ÿè®¡
      this.client.hincrby(accountMonthly, 'tokens', coreTokens),
      this.client.hincrby(accountMonthly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountMonthly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountMonthly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountMonthly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountMonthly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountMonthly, 'requests', 1),

      // è´¦æˆ·æ¯å°æ—¶ç»Ÿè®¡
      this.client.hincrby(accountHourly, 'tokens', coreTokens),
      this.client.hincrby(accountHourly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountHourly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountHourly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountHourly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountHourly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountHourly, 'requests', 1),

      // æ·»åŠ æ¨¡å‹çº§åˆ«çš„æ•°æ®åˆ°hourlyé”®ä¸­ï¼Œä»¥æ”¯æŒä¼šè¯çª—å£çš„ç»Ÿè®¡
      this.client.hincrby(accountHourly, `model:${normalizedModel}:inputTokens`, finalInputTokens),
      this.client.hincrby(
        accountHourly,
        `model:${normalizedModel}:outputTokens`,
        finalOutputTokens
      ),
      this.client.hincrby(
        accountHourly,
        `model:${normalizedModel}:cacheCreateTokens`,
        finalCacheCreateTokens
      ),
      this.client.hincrby(
        accountHourly,
        `model:${normalizedModel}:cacheReadTokens`,
        finalCacheReadTokens
      ),
      this.client.hincrby(accountHourly, `model:${normalizedModel}:allTokens`, actualTotalTokens),
      this.client.hincrby(accountHourly, `model:${normalizedModel}:requests`, 1),

      // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æ—¥
      this.client.hincrby(accountModelDaily, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelDaily, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelDaily, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelDaily, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelDaily, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelDaily, 'requests', 1),

      // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯æœˆ
      this.client.hincrby(accountModelMonthly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelMonthly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelMonthly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelMonthly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelMonthly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelMonthly, 'requests', 1),

      // è´¦æˆ·æŒ‰æ¨¡å‹ç»Ÿè®¡ - æ¯å°æ—¶
      this.client.hincrby(accountModelHourly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelHourly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelHourly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelHourly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelHourly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelHourly, 'requests', 1),

      // è®¾ç½®è¿‡æœŸæ—¶é—´
      this.client.expire(accountDaily, 86400 * 32), // 32å¤©è¿‡æœŸ
      this.client.expire(accountMonthly, 86400 * 365), // 1å¹´è¿‡æœŸ
      this.client.expire(accountHourly, 86400 * 7), // 7å¤©è¿‡æœŸ
      this.client.expire(accountModelDaily, 86400 * 32), // 32å¤©è¿‡æœŸ
      this.client.expire(accountModelMonthly, 86400 * 365), // 1å¹´è¿‡æœŸ
      this.client.expire(accountModelHourly, 86400 * 7), // 7å¤©è¿‡æœŸ

      // æ·»åŠ ç´¢å¼•
      this.client.sadd(`account_usage:hourly:index:${currentHour}`, accountId),
      this.client.sadd(
        `account_usage:model:hourly:index:${currentHour}`,
        `${accountId}:${normalizedModel}`
      ),
      this.client.expire(`account_usage:hourly:index:${currentHour}`, 86400 * 7),
      this.client.expire(`account_usage:model:hourly:index:${currentHour}`, 86400 * 7),
      // daily ç´¢å¼•
      this.client.sadd(`account_usage:daily:index:${today}`, accountId),
      this.client.sadd(
        `account_usage:model:daily:index:${today}`,
        `${accountId}:${normalizedModel}`
      ),
      this.client.expire(`account_usage:daily:index:${today}`, 86400 * 32),
      this.client.expire(`account_usage:model:daily:index:${today}`, 86400 * 32),
      // æ¸…ç†ç©ºæ ‡è®°
      this.client.del(`account_usage:hourly:index:${currentHour}:empty`),
      this.client.del(`account_usage:model:hourly:index:${currentHour}:empty`),
      this.client.del(`account_usage:daily:index:${today}:empty`),
      this.client.del(`account_usage:model:daily:index:${today}:empty`)
    ]

    // å¦‚æœæ˜¯ 1M ä¸Šä¸‹æ–‡è¯·æ±‚ï¼Œæ·»åŠ é¢å¤–çš„ç»Ÿè®¡
    if (isLongContextRequest) {
      operations.push(
        this.client.hincrby(accountKey, 'totalLongContextInputTokens', finalInputTokens),
        this.client.hincrby(accountKey, 'totalLongContextOutputTokens', finalOutputTokens),
        this.client.hincrby(accountKey, 'totalLongContextRequests', 1),
        this.client.hincrby(accountDaily, 'longContextInputTokens', finalInputTokens),
        this.client.hincrby(accountDaily, 'longContextOutputTokens', finalOutputTokens),
        this.client.hincrby(accountDaily, 'longContextRequests', 1)
      )
    }

    await Promise.all(operations)
  }

  /**
   * è·å–ä½¿ç”¨äº†æŒ‡å®šæ¨¡å‹çš„ Key IDsï¼ˆOR é€»è¾‘ï¼‰
   * ä½¿ç”¨ EXISTS + pipeline æ‰¹é‡æ£€æŸ¥ alltime é”®ï¼Œé¿å… KEYS å…¨é‡æ‰«æ
   * æ”¯æŒåˆ†æ‰¹å¤„ç†å’Œ fallback åˆ° SCAN æ¨¡å¼
   */
  async getKeyIdsWithModels(keyIds, models) {
    if (!keyIds.length || !models.length) {
      return new Set()
    }

    const client = this.getClientSafe()
    const result = new Set()
    const BATCH_SIZE = 1000

    // æ„å»ºæ‰€æœ‰éœ€è¦æ£€æŸ¥çš„ key
    const checkKeys = []
    const keyIdMap = new Map()

    for (const keyId of keyIds) {
      for (const model of models) {
        const key = `usage:${keyId}:model:alltime:${model}`
        checkKeys.push(key)
        keyIdMap.set(key, keyId)
      }
    }

    // åˆ†æ‰¹ EXISTS æ£€æŸ¥ï¼ˆé¿å…å•ä¸ª pipeline è¿‡å¤§ï¼‰
    for (let i = 0; i < checkKeys.length; i += BATCH_SIZE) {
      const batch = checkKeys.slice(i, i + BATCH_SIZE)
      const pipeline = client.pipeline()
      for (const key of batch) {
        pipeline.exists(key)
      }
      const results = await pipeline.exec()

      for (let j = 0; j < batch.length; j++) {
        const [err, exists] = results[j]
        if (!err && exists) {
          result.add(keyIdMap.get(batch[j]))
        }
      }
    }

    // Fallback: å¦‚æœ alltime é”®å…¨éƒ¨ä¸å­˜åœ¨ï¼Œå›é€€åˆ° SCAN æ¨¡å¼
    if (result.size === 0 && keyIds.length > 0) {
      // å¤šæŠ½æ ·æ£€æŸ¥ï¼šæŠ½å–æœ€å¤š 3 ä¸ª keyId æ£€æŸ¥æ˜¯å¦æœ‰ alltime æ•°æ®
      const sampleIndices = new Set()
      sampleIndices.add(0) // å§‹ç»ˆåŒ…å«ç¬¬ä¸€ä¸ª
      if (keyIds.length > 1) {
        sampleIndices.add(keyIds.length - 1)
      } // åŒ…å«æœ€åä¸€ä¸ª
      if (keyIds.length > 2) {
        sampleIndices.add(Math.floor(keyIds.length / 2))
      } // åŒ…å«ä¸­é—´ä¸€ä¸ª

      let hasAnyAlltimeData = false
      for (const idx of sampleIndices) {
        const samplePattern = `usage:${keyIds[idx]}:model:alltime:*`
        const sampleKeys = await this.scanKeys(samplePattern)
        if (sampleKeys.length > 0) {
          hasAnyAlltimeData = true
          break
        }
      }

      if (!hasAnyAlltimeData) {
        // alltime æ•°æ®ä¸å­˜åœ¨ï¼Œå›é€€åˆ°æ—§æ‰«æé€»è¾‘
        logger.warn('âš ï¸ alltime æ¨¡å‹æ•°æ®ä¸å­˜åœ¨ï¼Œå›é€€åˆ° SCAN æ¨¡å¼ï¼ˆå»ºè®®è¿è¡Œè¿ç§»è„šæœ¬ï¼‰')
        for (const keyId of keyIds) {
          for (const model of models) {
            const pattern = `usage:${keyId}:model:*:${model}:*`
            const keys = await this.scanKeys(pattern)
            if (keys.length > 0) {
              result.add(keyId)
              break
            }
          }
        }
      }
    }

    return result
  }

  /**
   * è·å–æ‰€æœ‰è¢«ä½¿ç”¨è¿‡çš„æ¨¡å‹åˆ—è¡¨
   */
  async getAllUsedModels() {
    const client = this.getClientSafe()
    const models = new Set()

    // æ‰«ææ‰€æœ‰æ¨¡å‹ä½¿ç”¨è®°å½•
    const pattern = 'usage:*:model:daily:*'
    let cursor = '0'
    do {
      const [nextCursor, keys] = await client.scan(cursor, 'MATCH', pattern, 'COUNT', 1000)
      cursor = nextCursor
      for (const key of keys) {
        // ä» key ä¸­æå–æ¨¡å‹å: usage:{keyId}:model:daily:{model}:{date}
        const match = key.match(/usage:[^:]+:model:daily:([^:]+):/)
        if (match) {
          models.add(match[1])
        }
      }
    } while (cursor !== '0')

    return [...models].sort()
  }

  async getUsageStats(keyId) {
    const totalKey = `usage:${keyId}`
    const today = getDateStringInTimezone()
    const dailyKey = `usage:daily:${keyId}:${today}`
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const monthlyKey = `usage:monthly:${keyId}:${currentMonth}`

    const [total, daily, monthly] = await Promise.all([
      this.client.hgetall(totalKey),
      this.client.hgetall(dailyKey),
      this.client.hgetall(monthlyKey)
    ])

    // è·å–API Keyçš„åˆ›å»ºæ—¶é—´æ¥è®¡ç®—å¹³å‡å€¼
    const keyData = await this.client.hgetall(`apikey:${keyId}`)
    const createdAt = keyData.createdAt ? new Date(keyData.createdAt) : new Date()
    const now = new Date()
    const daysSinceCreated = Math.max(1, Math.ceil((now - createdAt) / (1000 * 60 * 60 * 24)))

    const totalTokens = parseInt(total.totalTokens) || 0
    const totalRequests = parseInt(total.totalRequests) || 0

    // è®¡ç®—å¹³å‡RPM (requests per minute) å’Œ TPM (tokens per minute)
    const totalMinutes = Math.max(1, daysSinceCreated * 24 * 60)
    const avgRPM = totalRequests / totalMinutes
    const avgTPM = totalTokens / totalMinutes

    // å¤„ç†æ—§æ•°æ®å…¼å®¹æ€§ï¼ˆæ”¯æŒç¼“å­˜tokenï¼‰
    const handleLegacyData = (data) => {
      // ä¼˜å…ˆä½¿ç”¨total*å­—æ®µï¼ˆå­˜å‚¨æ—¶ä½¿ç”¨çš„å­—æ®µï¼‰
      const tokens = parseInt(data.totalTokens) || parseInt(data.tokens) || 0
      const inputTokens = parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
      const outputTokens = parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
      const requests = parseInt(data.totalRequests) || parseInt(data.requests) || 0

      // æ–°å¢ç¼“å­˜tokenå­—æ®µ
      const cacheCreateTokens =
        parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
      const cacheReadTokens =
        parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
      const allTokens = parseInt(data.totalAllTokens) || parseInt(data.allTokens) || 0

      const totalFromSeparate = inputTokens + outputTokens
      // è®¡ç®—å®é™…çš„æ€»tokensï¼ˆåŒ…å«æ‰€æœ‰ç±»å‹ï¼‰
      const actualAllTokens =
        allTokens || inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

      if (totalFromSeparate === 0 && tokens > 0) {
        // æ—§æ•°æ®ï¼šæ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»
        return {
          tokens, // ä¿æŒå…¼å®¹æ€§ï¼Œä½†ç»Ÿä¸€ä½¿ç”¨allTokens
          inputTokens: Math.round(tokens * 0.3), // å‡è®¾30%ä¸ºè¾“å…¥
          outputTokens: Math.round(tokens * 0.7), // å‡è®¾70%ä¸ºè¾“å‡º
          cacheCreateTokens: 0, // æ—§æ•°æ®æ²¡æœ‰ç¼“å­˜token
          cacheReadTokens: 0,
          allTokens: tokens, // å¯¹äºæ—§æ•°æ®ï¼ŒallTokensç­‰äºtokens
          requests
        }
      } else {
        // æ–°æ•°æ®æˆ–æ— æ•°æ® - ç»Ÿä¸€ä½¿ç”¨allTokensä½œä¸ºtokensçš„å€¼
        return {
          tokens: actualAllTokens, // ç»Ÿä¸€ä½¿ç”¨allTokensä½œä¸ºæ€»æ•°
          inputTokens,
          outputTokens,
          cacheCreateTokens,
          cacheReadTokens,
          allTokens: actualAllTokens,
          requests
        }
      }
    }

    const totalData = handleLegacyData(total)
    const dailyData = handleLegacyData(daily)
    const monthlyData = handleLegacyData(monthly)

    return {
      total: totalData,
      daily: dailyData,
      monthly: monthlyData,
      averages: {
        rpm: Math.round(avgRPM * 100) / 100, // ä¿ç•™2ä½å°æ•°
        tpm: Math.round(avgTPM * 100) / 100,
        dailyRequests: Math.round((totalRequests / daysSinceCreated) * 100) / 100,
        dailyTokens: Math.round((totalTokens / daysSinceCreated) * 100) / 100
      }
    }
  }

  async addUsageRecord(keyId, record, maxRecords = 200) {
    const listKey = `usage:records:${keyId}`
    const client = this.getClientSafe()

    try {
      await client
        .multi()
        .lpush(listKey, JSON.stringify(record))
        .ltrim(listKey, 0, Math.max(0, maxRecords - 1))
        .expire(listKey, 86400 * 90) // é»˜è®¤ä¿ç•™90å¤©
        .exec()
    } catch (error) {
      logger.error(`âŒ Failed to append usage record for key ${keyId}:`, error)
    }
  }

  async getUsageRecords(keyId, limit = 50) {
    const listKey = `usage:records:${keyId}`
    const client = this.getClient()

    if (!client) {
      return []
    }

    try {
      const rawRecords = await client.lrange(listKey, 0, Math.max(0, limit - 1))
      return rawRecords
        .map((entry) => {
          try {
            return JSON.parse(entry)
          } catch (error) {
            logger.warn('âš ï¸ Failed to parse usage record entry:', error)
            return null
          }
        })
        .filter(Boolean)
    } catch (error) {
      logger.error(`âŒ Failed to load usage records for key ${keyId}:`, error)
      return []
    }
  }

  // ğŸ’° è·å–å½“æ—¥è´¹ç”¨
  async getDailyCost(keyId) {
    const today = getDateStringInTimezone()
    const costKey = `usage:cost:daily:${keyId}:${today}`
    const cost = await this.client.get(costKey)
    const result = parseFloat(cost || 0)
    logger.debug(
      `ğŸ’° Getting daily cost for ${keyId}, date: ${today}, key: ${costKey}, value: ${cost}, result: ${result}`
    )
    return result
  }

  // ğŸ’° å¢åŠ å½“æ—¥è´¹ç”¨ï¼ˆæ”¯æŒå€ç‡æˆæœ¬å’ŒçœŸå®æˆæœ¬åˆ†å¼€è®°å½•ï¼‰
  // amount: å€ç‡åçš„æˆæœ¬ï¼ˆç”¨äºé™é¢æ ¡éªŒï¼‰
  // realAmount: çœŸå®æˆæœ¬ï¼ˆç”¨äºå¯¹è´¦ï¼‰ï¼Œå¦‚æœä¸ä¼ åˆ™ç­‰äº amount
  async incrementDailyCost(keyId, amount, realAmount = null) {
    const today = getDateStringInTimezone()
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const currentHour = `${today}:${String(getHourInTimezone(new Date())).padStart(2, '0')}`

    const dailyKey = `usage:cost:daily:${keyId}:${today}`
    const monthlyKey = `usage:cost:monthly:${keyId}:${currentMonth}`
    const hourlyKey = `usage:cost:hourly:${keyId}:${currentHour}`
    const totalKey = `usage:cost:total:${keyId}` // æ€»è´¹ç”¨é”® - æ°¸ä¸è¿‡æœŸï¼ŒæŒç»­ç´¯åŠ 

    // çœŸå®æˆæœ¬é”®ï¼ˆç”¨äºå¯¹è´¦ï¼‰
    const realTotalKey = `usage:cost:real:total:${keyId}`
    const realDailyKey = `usage:cost:real:daily:${keyId}:${today}`
    const actualRealAmount = realAmount !== null ? realAmount : amount

    logger.debug(
      `ğŸ’° Incrementing cost for ${keyId}, rated: $${amount}, real: $${actualRealAmount}, date: ${today}`
    )

    const results = await Promise.all([
      this.client.incrbyfloat(dailyKey, amount),
      this.client.incrbyfloat(monthlyKey, amount),
      this.client.incrbyfloat(hourlyKey, amount),
      this.client.incrbyfloat(totalKey, amount), // å€ç‡åæ€»è´¹ç”¨ï¼ˆç”¨äºé™é¢ï¼‰
      this.client.incrbyfloat(realTotalKey, actualRealAmount), // çœŸå®æ€»è´¹ç”¨ï¼ˆç”¨äºå¯¹è´¦ï¼‰
      this.client.incrbyfloat(realDailyKey, actualRealAmount), // çœŸå®æ¯æ—¥è´¹ç”¨
      // è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆæ³¨æ„ï¼štotalKey å’Œ realTotalKey ä¸è®¾ç½®è¿‡æœŸæ—¶é—´ï¼Œä¿æŒæ°¸ä¹…ç´¯è®¡ï¼‰
      this.client.expire(dailyKey, 86400 * 30), // 30å¤©
      this.client.expire(monthlyKey, 86400 * 90), // 90å¤©
      this.client.expire(hourlyKey, 86400 * 7), // 7å¤©
      this.client.expire(realDailyKey, 86400 * 30) // 30å¤©
    ])

    logger.debug(`ğŸ’° Cost incremented successfully, new daily total: $${results[0]}`)
  }

  // ğŸ’° è·å–è´¹ç”¨ç»Ÿè®¡ï¼ˆåŒ…å«å€ç‡æˆæœ¬å’ŒçœŸå®æˆæœ¬ï¼‰
  async getCostStats(keyId) {
    const today = getDateStringInTimezone()
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const currentHour = `${today}:${String(getHourInTimezone(new Date())).padStart(2, '0')}`

    const [daily, monthly, hourly, total, realTotal, realDaily] = await Promise.all([
      this.client.get(`usage:cost:daily:${keyId}:${today}`),
      this.client.get(`usage:cost:monthly:${keyId}:${currentMonth}`),
      this.client.get(`usage:cost:hourly:${keyId}:${currentHour}`),
      this.client.get(`usage:cost:total:${keyId}`),
      this.client.get(`usage:cost:real:total:${keyId}`),
      this.client.get(`usage:cost:real:daily:${keyId}:${today}`)
    ])

    return {
      daily: parseFloat(daily || 0),
      monthly: parseFloat(monthly || 0),
      hourly: parseFloat(hourly || 0),
      total: parseFloat(total || 0),
      realTotal: parseFloat(realTotal || 0),
      realDaily: parseFloat(realDaily || 0)
    }
  }

  // ğŸ’° è·å–æœ¬å‘¨ Opus è´¹ç”¨
  async getWeeklyOpusCost(keyId) {
    const currentWeek = getWeekStringInTimezone()
    const costKey = `usage:opus:weekly:${keyId}:${currentWeek}`
    const cost = await this.client.get(costKey)
    const result = parseFloat(cost || 0)
    logger.debug(
      `ğŸ’° Getting weekly Opus cost for ${keyId}, week: ${currentWeek}, key: ${costKey}, value: ${cost}, result: ${result}`
    )
    return result
  }

  // ğŸ’° å¢åŠ æœ¬å‘¨ Opus è´¹ç”¨ï¼ˆæ”¯æŒå€ç‡æˆæœ¬å’ŒçœŸå®æˆæœ¬ï¼‰
  // amount: å€ç‡åçš„æˆæœ¬ï¼ˆç”¨äºé™é¢æ ¡éªŒï¼‰
  // realAmount: çœŸå®æˆæœ¬ï¼ˆç”¨äºå¯¹è´¦ï¼‰ï¼Œå¦‚æœä¸ä¼ åˆ™ç­‰äº amount
  async incrementWeeklyOpusCost(keyId, amount, realAmount = null) {
    const currentWeek = getWeekStringInTimezone()
    const weeklyKey = `usage:opus:weekly:${keyId}:${currentWeek}`
    const totalKey = `usage:opus:total:${keyId}`
    const realWeeklyKey = `usage:opus:real:weekly:${keyId}:${currentWeek}`
    const realTotalKey = `usage:opus:real:total:${keyId}`
    const actualRealAmount = realAmount !== null ? realAmount : amount

    logger.debug(
      `ğŸ’° Incrementing weekly Opus cost for ${keyId}, week: ${currentWeek}, rated: $${amount}, real: $${actualRealAmount}`
    )

    // ä½¿ç”¨ pipeline æ‰¹é‡æ‰§è¡Œï¼Œæé«˜æ€§èƒ½
    const pipeline = this.client.pipeline()
    pipeline.incrbyfloat(weeklyKey, amount)
    pipeline.incrbyfloat(totalKey, amount)
    pipeline.incrbyfloat(realWeeklyKey, actualRealAmount)
    pipeline.incrbyfloat(realTotalKey, actualRealAmount)
    // è®¾ç½®å‘¨è´¹ç”¨é”®çš„è¿‡æœŸæ—¶é—´ä¸º 2 å‘¨
    pipeline.expire(weeklyKey, 14 * 24 * 3600)
    pipeline.expire(realWeeklyKey, 14 * 24 * 3600)

    const results = await pipeline.exec()
    logger.debug(`ğŸ’° Opus cost incremented successfully, new weekly total: $${results[0][1]}`)
  }

  // ğŸ’° è¦†ç›–è®¾ç½®æœ¬å‘¨ Opus è´¹ç”¨ï¼ˆç”¨äºå¯åŠ¨å›å¡«/è¿ç§»ï¼‰
  async setWeeklyOpusCost(keyId, amount, weekString = null) {
    const currentWeek = weekString || getWeekStringInTimezone()
    const weeklyKey = `usage:opus:weekly:${keyId}:${currentWeek}`

    await this.client.set(weeklyKey, String(amount || 0))
    // ä¿ç•™ 2 å‘¨ï¼Œè¶³å¤Ÿè¦†ç›–"å½“å‰å‘¨ + ä¸Šå‘¨"æŸ¥çœ‹/å›å¡«
    await this.client.expire(weeklyKey, 14 * 24 * 3600)
  }

  // ğŸ’° è®¡ç®—è´¦æˆ·çš„æ¯æ—¥è´¹ç”¨ï¼ˆåŸºäºæ¨¡å‹ä½¿ç”¨ï¼Œä½¿ç”¨ç´¢å¼•é›†åˆæ›¿ä»£ KEYSï¼‰
  async getAccountDailyCost(accountId) {
    const CostCalculator = require('../utils/costCalculator')
    const today = getDateStringInTimezone()

    // ä½¿ç”¨ç´¢å¼•é›†åˆæ›¿ä»£ KEYS å‘½ä»¤
    const indexKey = `account_usage:model:daily:index:${today}`
    const allEntries = await this.client.smembers(indexKey)

    // è¿‡æ»¤å‡ºå½“å‰è´¦æˆ·çš„æ¡ç›®ï¼ˆæ ¼å¼ï¼šaccountId:modelï¼‰
    const accountPrefix = `${accountId}:`
    const accountModels = allEntries
      .filter((entry) => entry.startsWith(accountPrefix))
      .map((entry) => entry.substring(accountPrefix.length))

    if (accountModels.length === 0) {
      return 0
    }

    // Pipeline æ‰¹é‡è·å–æ‰€æœ‰æ¨¡å‹æ•°æ®
    const pipeline = this.client.pipeline()
    for (const model of accountModels) {
      pipeline.hgetall(`account_usage:model:daily:${accountId}:${model}:${today}`)
    }
    const results = await pipeline.exec()

    let totalCost = 0
    for (let i = 0; i < accountModels.length; i++) {
      const model = accountModels[i]
      const [err, modelUsage] = results[i]

      if (!err && modelUsage && (modelUsage.inputTokens || modelUsage.outputTokens)) {
        const usage = {
          input_tokens: parseInt(modelUsage.inputTokens || 0),
          output_tokens: parseInt(modelUsage.outputTokens || 0),
          cache_creation_input_tokens: parseInt(modelUsage.cacheCreateTokens || 0),
          cache_read_input_tokens: parseInt(modelUsage.cacheReadTokens || 0)
        }

        const costResult = CostCalculator.calculateCost(usage, model)
        totalCost += costResult.costs.total

        logger.debug(
          `ğŸ’° Account ${accountId} daily cost for model ${model}: $${costResult.costs.total}`
        )
      }
    }

    logger.debug(`ğŸ’° Account ${accountId} total daily cost: $${totalCost}`)
    return totalCost
  }

  // ğŸ’° æ‰¹é‡è®¡ç®—å¤šä¸ªè´¦æˆ·çš„æ¯æ—¥è´¹ç”¨
  async batchGetAccountDailyCost(accountIds) {
    if (!accountIds || accountIds.length === 0) {
      return new Map()
    }

    const CostCalculator = require('../utils/costCalculator')
    const today = getDateStringInTimezone()

    // ä¸€æ¬¡è·å–ç´¢å¼•
    const indexKey = `account_usage:model:daily:index:${today}`
    const allEntries = await this.client.smembers(indexKey)

    // æŒ‰ accountId åˆ†ç»„
    const accountIdSet = new Set(accountIds)
    const entriesByAccount = new Map()
    for (const entry of allEntries) {
      const colonIndex = entry.indexOf(':')
      if (colonIndex === -1) {
        continue
      }
      const accountId = entry.substring(0, colonIndex)
      const model = entry.substring(colonIndex + 1)
      if (accountIdSet.has(accountId)) {
        if (!entriesByAccount.has(accountId)) {
          entriesByAccount.set(accountId, [])
        }
        entriesByAccount.get(accountId).push(model)
      }
    }

    const costMap = new Map(accountIds.map((id) => [id, 0]))

    // å¦‚æœç´¢å¼•ä¸ºç©ºï¼Œå›é€€åˆ° KEYS å‘½ä»¤ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
    if (allEntries.length === 0) {
      logger.debug('ğŸ’° Daily cost index empty, falling back to KEYS for batch cost calculation')
      for (const accountId of accountIds) {
        try {
          const cost = await this.getAccountDailyCostFallback(accountId, today, CostCalculator)
          costMap.set(accountId, cost)
        } catch {
          // å¿½ç•¥å•ä¸ªè´¦æˆ·çš„é”™è¯¯
        }
      }
      return costMap
    }

    // Pipeline æ‰¹é‡è·å–æ‰€æœ‰æ¨¡å‹æ•°æ®
    const pipeline = this.client.pipeline()
    const queryOrder = []
    for (const [accountId, models] of entriesByAccount) {
      for (const model of models) {
        pipeline.hgetall(`account_usage:model:daily:${accountId}:${model}:${today}`)
        queryOrder.push({ accountId, model })
      }
    }

    if (queryOrder.length === 0) {
      return costMap
    }

    const results = await pipeline.exec()

    for (let i = 0; i < queryOrder.length; i++) {
      const { accountId, model } = queryOrder[i]
      const [err, modelUsage] = results[i]

      if (!err && modelUsage && (modelUsage.inputTokens || modelUsage.outputTokens)) {
        const usage = {
          input_tokens: parseInt(modelUsage.inputTokens || 0),
          output_tokens: parseInt(modelUsage.outputTokens || 0),
          cache_creation_input_tokens: parseInt(modelUsage.cacheCreateTokens || 0),
          cache_read_input_tokens: parseInt(modelUsage.cacheReadTokens || 0)
        }

        const costResult = CostCalculator.calculateCost(usage, model)
        costMap.set(accountId, costMap.get(accountId) + costResult.costs.total)
      }
    }

    return costMap
  }

  // ğŸ’° å›é€€æ–¹æ³•ï¼šè®¡ç®—å•ä¸ªè´¦æˆ·çš„æ¯æ—¥è´¹ç”¨ï¼ˆä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
  async getAccountDailyCostFallback(accountId, today, CostCalculator) {
    const pattern = `account_usage:model:daily:${accountId}:*:${today}`
    const modelKeys = await this.scanKeys(pattern)

    if (!modelKeys || modelKeys.length === 0) {
      return 0
    }

    let totalCost = 0
    const pipeline = this.client.pipeline()
    for (const key of modelKeys) {
      pipeline.hgetall(key)
    }
    const results = await pipeline.exec()

    for (let i = 0; i < modelKeys.length; i++) {
      const key = modelKeys[i]
      const [err, modelUsage] = results[i]
      if (err || !modelUsage) {
        continue
      }

      const parts = key.split(':')
      const model = parts[4]

      if (modelUsage.inputTokens || modelUsage.outputTokens) {
        const usage = {
          input_tokens: parseInt(modelUsage.inputTokens || 0),
          output_tokens: parseInt(modelUsage.outputTokens || 0),
          cache_creation_input_tokens: parseInt(modelUsage.cacheCreateTokens || 0),
          cache_read_input_tokens: parseInt(modelUsage.cacheReadTokens || 0)
        }
        const costResult = CostCalculator.calculateCost(usage, model)
        totalCost += costResult.costs.total
      }
    }

    return totalCost
  }

  // ğŸ“Š è·å–è´¦æˆ·ä½¿ç”¨ç»Ÿè®¡
  async getAccountUsageStats(accountId, accountType = null) {
    const accountKey = `account_usage:${accountId}`
    const today = getDateStringInTimezone()
    const accountDailyKey = `account_usage:daily:${accountId}:${today}`
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const accountMonthlyKey = `account_usage:monthly:${accountId}:${currentMonth}`

    const [total, daily, monthly] = await Promise.all([
      this.client.hgetall(accountKey),
      this.client.hgetall(accountDailyKey),
      this.client.hgetall(accountMonthlyKey)
    ])

    // è·å–è´¦æˆ·åˆ›å»ºæ—¶é—´æ¥è®¡ç®—å¹³å‡å€¼ - æ”¯æŒä¸åŒç±»å‹çš„è´¦å·
    let accountData = {}
    if (accountType === 'droid') {
      accountData = await this.client.hgetall(`droid:account:${accountId}`)
    } else if (accountType === 'openai') {
      accountData = await this.client.hgetall(`openai:account:${accountId}`)
    } else if (accountType === 'openai-responses') {
      accountData = await this.client.hgetall(`openai_responses_account:${accountId}`)
    } else {
      // å°è¯•å¤šä¸ªå‰ç¼€ï¼ˆä¼˜å…ˆ claude:account:ï¼‰
      accountData = await this.client.hgetall(`claude:account:${accountId}`)
      if (!accountData.createdAt) {
        accountData = await this.client.hgetall(`claude_account:${accountId}`)
      }
      if (!accountData.createdAt) {
        accountData = await this.client.hgetall(`openai:account:${accountId}`)
      }
      if (!accountData.createdAt) {
        accountData = await this.client.hgetall(`openai_responses_account:${accountId}`)
      }
      if (!accountData.createdAt) {
        accountData = await this.client.hgetall(`openai_account:${accountId}`)
      }
      if (!accountData.createdAt) {
        accountData = await this.client.hgetall(`droid:account:${accountId}`)
      }
    }
    const createdAt = accountData.createdAt ? new Date(accountData.createdAt) : new Date()
    const now = new Date()
    const daysSinceCreated = Math.max(1, Math.ceil((now - createdAt) / (1000 * 60 * 60 * 24)))

    const totalTokens = parseInt(total.totalTokens) || 0
    const totalRequests = parseInt(total.totalRequests) || 0

    // è®¡ç®—å¹³å‡RPMå’ŒTPM
    const totalMinutes = Math.max(1, daysSinceCreated * 24 * 60)
    const avgRPM = totalRequests / totalMinutes
    const avgTPM = totalTokens / totalMinutes

    // å¤„ç†è´¦æˆ·ç»Ÿè®¡æ•°æ®
    const handleAccountData = (data) => {
      const tokens = parseInt(data.totalTokens) || parseInt(data.tokens) || 0
      const inputTokens = parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
      const outputTokens = parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
      const requests = parseInt(data.totalRequests) || parseInt(data.requests) || 0
      const cacheCreateTokens =
        parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
      const cacheReadTokens =
        parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
      const allTokens = parseInt(data.totalAllTokens) || parseInt(data.allTokens) || 0

      const actualAllTokens =
        allTokens || inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

      return {
        tokens,
        inputTokens,
        outputTokens,
        cacheCreateTokens,
        cacheReadTokens,
        allTokens: actualAllTokens,
        requests
      }
    }

    const totalData = handleAccountData(total)
    const dailyData = handleAccountData(daily)
    const monthlyData = handleAccountData(monthly)

    // è·å–æ¯æ—¥è´¹ç”¨ï¼ˆåŸºäºæ¨¡å‹ä½¿ç”¨ï¼‰
    const dailyCost = await this.getAccountDailyCost(accountId)

    return {
      accountId,
      total: totalData,
      daily: {
        ...dailyData,
        cost: dailyCost
      },
      monthly: monthlyData,
      averages: {
        rpm: Math.round(avgRPM * 100) / 100,
        tpm: Math.round(avgTPM * 100) / 100,
        dailyRequests: Math.round((totalRequests / daysSinceCreated) * 100) / 100,
        dailyTokens: Math.round((totalTokens / daysSinceCreated) * 100) / 100
      }
    }
  }

  // ğŸ“ˆ è·å–æ‰€æœ‰è´¦æˆ·çš„ä½¿ç”¨ç»Ÿè®¡
  async getAllAccountsUsageStats() {
    try {
      // ä½¿ç”¨ getAllIdsByIndex è·å–è´¦æˆ· IDï¼ˆè‡ªåŠ¨å¤„ç†ç´¢å¼•/SCAN å›é€€ï¼‰
      const accountIds = await this.getAllIdsByIndex(
        'claude:account:index',
        'claude:account:*',
        /^claude:account:(.+)$/
      )

      if (accountIds.length === 0) {
        return []
      }

      const accountStats = []

      for (const accountId of accountIds) {
        const accountKey = `claude:account:${accountId}`
        const accountData = await this.client.hgetall(accountKey)

        if (accountData && accountData.name) {
          const stats = await this.getAccountUsageStats(accountId)
          accountStats.push({
            id: accountId,
            name: accountData.name,
            email: accountData.email || '',
            status: accountData.status || 'unknown',
            isActive: accountData.isActive === 'true',
            ...stats
          })
        }
      }

      // æŒ‰å½“æ—¥tokenä½¿ç”¨é‡æ’åº
      accountStats.sort((a, b) => (b.daily.allTokens || 0) - (a.daily.allTokens || 0))

      return accountStats
    } catch (error) {
      logger.error('âŒ Failed to get all accounts usage stats:', error)
      return []
    }
  }

  // ğŸ§¹ æ¸…ç©ºæ‰€æœ‰API Keyçš„ä½¿ç”¨ç»Ÿè®¡æ•°æ®ï¼ˆä½¿ç”¨ scanKeys + batchDelChunked ä¼˜åŒ–ï¼‰
  async resetAllUsageStats() {
    const client = this.getClientSafe()
    const stats = {
      deletedKeys: 0,
      deletedDailyKeys: 0,
      deletedMonthlyKeys: 0,
      resetApiKeys: 0
    }

    try {
      // 1. è·å–æ‰€æœ‰ API Key IDï¼ˆä½¿ç”¨ scanKeysï¼‰
      const apiKeyKeys = await this.scanKeys('apikey:*')
      const apiKeyIds = apiKeyKeys
        .filter((k) => k !== 'apikey:hash_map' && k.split(':').length === 2)
        .map((k) => k.replace('apikey:', ''))

      // 2. æ‰¹é‡åˆ é™¤æ€»ä½“ä½¿ç”¨ç»Ÿè®¡
      const usageKeys = apiKeyIds.map((id) => `usage:${id}`)
      stats.deletedKeys = await this.batchDelChunked(usageKeys)

      // 3. ä½¿ç”¨ scanKeys è·å–å¹¶æ‰¹é‡åˆ é™¤ daily ç»Ÿè®¡
      const dailyKeys = await this.scanKeys('usage:daily:*')
      stats.deletedDailyKeys = await this.batchDelChunked(dailyKeys)

      // 4. ä½¿ç”¨ scanKeys è·å–å¹¶æ‰¹é‡åˆ é™¤ monthly ç»Ÿè®¡
      const monthlyKeys = await this.scanKeys('usage:monthly:*')
      stats.deletedMonthlyKeys = await this.batchDelChunked(monthlyKeys)

      // 5. æ‰¹é‡é‡ç½® lastUsedAtï¼ˆä»…å¯¹å­˜åœ¨çš„ key æ“ä½œï¼Œé¿å…é‡å»ºç©º hashï¼‰
      const BATCH_SIZE = 500
      for (let i = 0; i < apiKeyIds.length; i += BATCH_SIZE) {
        const batch = apiKeyIds.slice(i, i + BATCH_SIZE)
        const existsPipeline = client.pipeline()
        for (const keyId of batch) {
          existsPipeline.exists(`apikey:${keyId}`)
        }
        const existsResults = await existsPipeline.exec()

        const updatePipeline = client.pipeline()
        let updateCount = 0
        for (let j = 0; j < batch.length; j++) {
          const [err, exists] = existsResults[j]
          if (!err && exists) {
            updatePipeline.hset(`apikey:${batch[j]}`, 'lastUsedAt', '')
            updateCount++
          }
        }
        if (updateCount > 0) {
          await updatePipeline.exec()
          stats.resetApiKeys += updateCount
        }
      }

      // 6. æ¸…ç†æ‰€æœ‰ usage ç›¸å…³é”®ï¼ˆä½¿ç”¨ scanKeys + batchDelChunkedï¼‰
      const allUsageKeys = await this.scanKeys('usage:*')
      const additionalDeleted = await this.batchDelChunked(allUsageKeys)
      stats.deletedKeys += additionalDeleted

      return stats
    } catch (error) {
      throw new Error(`Failed to reset usage stats: ${error.message}`)
    }
  }

  // ğŸ¢ Claude è´¦æˆ·ç®¡ç†
  async setClaudeAccount(accountId, accountData) {
    const key = `claude:account:${accountId}`
    await this.client.hset(key, accountData)
    await this.client.sadd('claude:account:index', accountId)
    await this.client.del('claude:account:index:empty')
  }

  async getClaudeAccount(accountId) {
    const key = `claude:account:${accountId}`
    return await this.client.hgetall(key)
  }

  async getAllClaudeAccounts() {
    const accountIds = await this.getAllIdsByIndex(
      'claude:account:index',
      'claude:account:*',
      /^claude:account:(.+)$/
    )
    if (accountIds.length === 0) {
      return []
    }

    const keys = accountIds.map((id) => `claude:account:${id}`)
    const pipeline = this.client.pipeline()
    keys.forEach((key) => pipeline.hgetall(key))
    const results = await pipeline.exec()

    const accounts = []
    results.forEach(([err, accountData], index) => {
      if (!err && accountData && Object.keys(accountData).length > 0) {
        accounts.push({ id: accountIds[index], ...accountData })
      }
    })
    return accounts
  }

  async deleteClaudeAccount(accountId) {
    const key = `claude:account:${accountId}`
    await this.client.srem('claude:account:index', accountId)
    return await this.client.del(key)
  }

  // ğŸ¤– Droid è´¦æˆ·ç›¸å…³æ“ä½œ
  async setDroidAccount(accountId, accountData) {
    const key = `droid:account:${accountId}`
    await this.client.hset(key, accountData)
    await this.client.sadd('droid:account:index', accountId)
    await this.client.del('droid:account:index:empty')
  }

  async getDroidAccount(accountId) {
    const key = `droid:account:${accountId}`
    return await this.client.hgetall(key)
  }

  async getAllDroidAccounts() {
    const accountIds = await this.getAllIdsByIndex(
      'droid:account:index',
      'droid:account:*',
      /^droid:account:(.+)$/
    )
    if (accountIds.length === 0) {
      return []
    }

    const keys = accountIds.map((id) => `droid:account:${id}`)
    const pipeline = this.client.pipeline()
    keys.forEach((key) => pipeline.hgetall(key))
    const results = await pipeline.exec()

    const accounts = []
    results.forEach(([err, accountData], index) => {
      if (!err && accountData && Object.keys(accountData).length > 0) {
        accounts.push({ id: accountIds[index], ...accountData })
      }
    })
    return accounts
  }

  async deleteDroidAccount(accountId) {
    const key = `droid:account:${accountId}`
    // ä»ç´¢å¼•ä¸­ç§»é™¤
    await this.client.srem('droid:account:index', accountId)
    return await this.client.del(key)
  }

  async setOpenAiAccount(accountId, accountData) {
    const key = `openai:account:${accountId}`
    await this.client.hset(key, accountData)
    await this.client.sadd('openai:account:index', accountId)
    await this.client.del('openai:account:index:empty')
  }
  async getOpenAiAccount(accountId) {
    const key = `openai:account:${accountId}`
    return await this.client.hgetall(key)
  }
  async deleteOpenAiAccount(accountId) {
    const key = `openai:account:${accountId}`
    await this.client.srem('openai:account:index', accountId)
    return await this.client.del(key)
  }

  async getAllOpenAIAccounts() {
    const accountIds = await this.getAllIdsByIndex(
      'openai:account:index',
      'openai:account:*',
      /^openai:account:(.+)$/
    )
    if (accountIds.length === 0) {
      return []
    }

    const keys = accountIds.map((id) => `openai:account:${id}`)
    const pipeline = this.client.pipeline()
    keys.forEach((key) => pipeline.hgetall(key))
    const results = await pipeline.exec()

    const accounts = []
    results.forEach(([err, accountData], index) => {
      if (!err && accountData && Object.keys(accountData).length > 0) {
        accounts.push({ id: accountIds[index], ...accountData })
      }
    })
    return accounts
  }

  // ğŸ” ä¼šè¯ç®¡ç†ï¼ˆç”¨äºç®¡ç†å‘˜ç™»å½•ç­‰ï¼‰
  async setSession(sessionId, sessionData, ttl = 86400) {
    const key = `session:${sessionId}`
    await this.client.hset(key, sessionData)
    await this.client.expire(key, ttl)
  }

  async getSession(sessionId) {
    const key = `session:${sessionId}`
    return await this.client.hgetall(key)
  }

  async deleteSession(sessionId) {
    const key = `session:${sessionId}`
    return await this.client.del(key)
  }

  // ğŸ—ï¸ API Keyå“ˆå¸Œç´¢å¼•ç®¡ç†ï¼ˆå…¼å®¹æ—§ç»“æ„ apikey_hash:* å’Œæ–°ç»“æ„ apikey:hash_mapï¼‰
  async setApiKeyHash(hashedKey, keyData, ttl = 0) {
    // å†™å…¥æ—§ç»“æ„ï¼ˆå…¼å®¹ï¼‰
    const key = `apikey_hash:${hashedKey}`
    await this.client.hset(key, keyData)
    if (ttl > 0) {
      await this.client.expire(key, ttl)
    }
    // åŒæ—¶å†™å…¥æ–°ç»“æ„ hash_mapï¼ˆè®¤è¯ä½¿ç”¨æ­¤ç»“æ„ï¼‰
    if (keyData.id) {
      await this.client.hset('apikey:hash_map', hashedKey, keyData.id)
    }
  }

  async getApiKeyHash(hashedKey) {
    const key = `apikey_hash:${hashedKey}`
    return await this.client.hgetall(key)
  }

  async deleteApiKeyHash(hashedKey) {
    // åŒæ—¶æ¸…ç†æ—§ç»“æ„å’Œæ–°ç»“æ„ï¼Œç¡®ä¿ Key è½®æ¢/åˆ é™¤åæ—§ Key å¤±æ•ˆ
    const oldKey = `apikey_hash:${hashedKey}`
    await this.client.del(oldKey)
    // ä»æ–°çš„ hash_map ä¸­ç§»é™¤ï¼ˆè®¤è¯ä½¿ç”¨æ­¤ç»“æ„ï¼‰
    await this.client.hdel('apikey:hash_map', hashedKey)
  }

  // ğŸ”— OAuthä¼šè¯ç®¡ç†
  async setOAuthSession(sessionId, sessionData, ttl = 600) {
    // 10åˆ†é’Ÿè¿‡æœŸ
    const key = `oauth:${sessionId}`

    // åºåˆ—åŒ–å¤æ‚å¯¹è±¡ï¼Œç‰¹åˆ«æ˜¯ proxy é…ç½®
    const serializedData = {}
    for (const [dataKey, value] of Object.entries(sessionData)) {
      if (typeof value === 'object' && value !== null) {
        serializedData[dataKey] = JSON.stringify(value)
      } else {
        serializedData[dataKey] = value
      }
    }

    await this.client.hset(key, serializedData)
    await this.client.expire(key, ttl)
  }

  async getOAuthSession(sessionId) {
    const key = `oauth:${sessionId}`
    const data = await this.client.hgetall(key)

    // ååºåˆ—åŒ– proxy å­—æ®µ
    if (data.proxy) {
      try {
        data.proxy = JSON.parse(data.proxy)
      } catch (error) {
        // å¦‚æœè§£æå¤±è´¥ï¼Œè®¾ç½®ä¸º null
        data.proxy = null
      }
    }

    return data
  }

  async deleteOAuthSession(sessionId) {
    const key = `oauth:${sessionId}`
    return await this.client.del(key)
  }

  // ğŸ’° è´¦æˆ·ä½™é¢ç¼“å­˜ï¼ˆAPI æŸ¥è¯¢ç»“æœï¼‰
  async setAccountBalance(platform, accountId, balanceData, ttl = 3600) {
    const key = `account_balance:${platform}:${accountId}`

    const payload = {
      balance:
        balanceData && balanceData.balance !== null && balanceData.balance !== undefined
          ? String(balanceData.balance)
          : '',
      currency: balanceData?.currency || 'USD',
      lastRefreshAt: balanceData?.lastRefreshAt || new Date().toISOString(),
      queryMethod: balanceData?.queryMethod || 'api',
      status: balanceData?.status || 'success',
      errorMessage: balanceData?.errorMessage || balanceData?.error || '',
      rawData: balanceData?.rawData ? JSON.stringify(balanceData.rawData) : '',
      quota: balanceData?.quota ? JSON.stringify(balanceData.quota) : ''
    }

    await this.client.hset(key, payload)
    await this.client.expire(key, ttl)
  }

  async getAccountBalance(platform, accountId) {
    const key = `account_balance:${platform}:${accountId}`
    const [data, ttlSeconds] = await Promise.all([this.client.hgetall(key), this.client.ttl(key)])

    if (!data || Object.keys(data).length === 0) {
      return null
    }

    let rawData = null
    if (data.rawData) {
      try {
        rawData = JSON.parse(data.rawData)
      } catch (error) {
        rawData = null
      }
    }

    let quota = null
    if (data.quota) {
      try {
        quota = JSON.parse(data.quota)
      } catch (error) {
        quota = null
      }
    }

    return {
      balance: data.balance ? parseFloat(data.balance) : null,
      currency: data.currency || 'USD',
      lastRefreshAt: data.lastRefreshAt || null,
      queryMethod: data.queryMethod || null,
      status: data.status || null,
      errorMessage: data.errorMessage || '',
      rawData,
      quota,
      ttlSeconds: Number.isFinite(ttlSeconds) ? ttlSeconds : null
    }
  }

  // ğŸ“Š è´¦æˆ·ä½™é¢ç¼“å­˜ï¼ˆæœ¬åœ°ç»Ÿè®¡ï¼‰
  async setLocalBalance(platform, accountId, statisticsData, ttl = 300) {
    const key = `account_balance_local:${platform}:${accountId}`

    await this.client.hset(key, {
      estimatedBalance: JSON.stringify(statisticsData || {}),
      lastCalculated: new Date().toISOString()
    })
    await this.client.expire(key, ttl)
  }

  async getLocalBalance(platform, accountId) {
    const key = `account_balance_local:${platform}:${accountId}`
    const data = await this.client.hgetall(key)

    if (!data || !data.estimatedBalance) {
      return null
    }

    try {
      return JSON.parse(data.estimatedBalance)
    } catch (error) {
      return null
    }
  }

  async deleteAccountBalance(platform, accountId) {
    const key = `account_balance:${platform}:${accountId}`
    const localKey = `account_balance_local:${platform}:${accountId}`
    await this.client.del(key, localKey)
  }

  // ğŸ§© è´¦æˆ·ä½™é¢è„šæœ¬é…ç½®
  async setBalanceScriptConfig(platform, accountId, scriptConfig) {
    const key = `account_balance_script:${platform}:${accountId}`
    await this.client.set(key, JSON.stringify(scriptConfig || {}))
  }

  async getBalanceScriptConfig(platform, accountId) {
    const key = `account_balance_script:${platform}:${accountId}`
    const raw = await this.client.get(key)
    if (!raw) {
      return null
    }
    try {
      return JSON.parse(raw)
    } catch (error) {
      return null
    }
  }

  async deleteBalanceScriptConfig(platform, accountId) {
    const key = `account_balance_script:${platform}:${accountId}`
    return await this.client.del(key)
  }

  // ğŸ“ˆ ç³»ç»Ÿç»Ÿè®¡ï¼ˆä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
  async getSystemStats() {
    const keys = await Promise.all([
      this.scanKeys('apikey:*'),
      this.scanKeys('claude:account:*'),
      this.scanKeys('usage:*')
    ])

    // è¿‡æ»¤ apikey ç´¢å¼•é”®ï¼Œåªç»Ÿè®¡å®é™…çš„ apikey
    const apiKeyCount = keys[0].filter(
      (k) => k !== 'apikey:hash_map' && k.split(':').length === 2
    ).length

    return {
      totalApiKeys: apiKeyCount,
      totalClaudeAccounts: keys[1].length,
      totalUsageRecords: keys[2].length
    }
  }

  // ğŸ” é€šè¿‡ç´¢å¼•è·å– key åˆ—è¡¨ï¼ˆæ›¿ä»£ SCANï¼‰
  async getKeysByIndex(indexKey, keyPattern) {
    const members = await this.client.smembers(indexKey)
    if (!members || members.length === 0) {
      return []
    }
    return members.map((id) => keyPattern.replace('{id}', id))
  }

  // ğŸ” æ‰¹é‡é€šè¿‡ç´¢å¼•è·å–æ•°æ®
  async getDataByIndex(indexKey, keyPattern) {
    const keys = await this.getKeysByIndex(indexKey, keyPattern)
    if (keys.length === 0) {
      return []
    }
    return await this.batchHgetallChunked(keys)
  }

  // ğŸ“Š è·å–ä»Šæ—¥ç³»ç»Ÿç»Ÿè®¡
  async getTodayStats() {
    try {
      const today = getDateStringInTimezone()
      // ä¼˜å…ˆä½¿ç”¨ç´¢å¼•æŸ¥è¯¢ï¼Œå›é€€åˆ° SCAN
      let dailyKeys = []
      const indexKey = `usage:daily:index:${today}`
      const indexMembers = await this.client.smembers(indexKey)
      if (indexMembers && indexMembers.length > 0) {
        dailyKeys = indexMembers.map((keyId) => `usage:daily:${keyId}:${today}`)
      } else {
        // å›é€€åˆ° SCANï¼ˆå…¼å®¹å†å²æ•°æ®ï¼‰
        dailyKeys = await this.scanKeys(`usage:daily:*:${today}`)
      }

      let totalRequestsToday = 0
      let totalTokensToday = 0
      let totalInputTokensToday = 0
      let totalOutputTokensToday = 0
      let totalCacheCreateTokensToday = 0
      let totalCacheReadTokensToday = 0

      // æ‰¹é‡è·å–æ‰€æœ‰ä»Šæ—¥æ•°æ®ï¼Œæé«˜æ€§èƒ½
      if (dailyKeys.length > 0) {
        const results = await this.batchHgetallChunked(dailyKeys)

        for (const dailyData of results) {
          if (!dailyData) {
            continue
          }

          totalRequestsToday += parseInt(dailyData.requests) || 0
          const currentDayTokens = parseInt(dailyData.tokens) || 0
          totalTokensToday += currentDayTokens

          // å¤„ç†æ—§æ•°æ®å…¼å®¹æ€§ï¼šå¦‚æœæœ‰æ€»tokenä½†æ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»ï¼Œåˆ™ä½¿ç”¨æ€»tokenä½œä¸ºè¾“å‡ºtoken
          const inputTokens = parseInt(dailyData.inputTokens) || 0
          const outputTokens = parseInt(dailyData.outputTokens) || 0
          const cacheCreateTokens = parseInt(dailyData.cacheCreateTokens) || 0
          const cacheReadTokens = parseInt(dailyData.cacheReadTokens) || 0
          const totalTokensFromSeparate = inputTokens + outputTokens

          if (totalTokensFromSeparate === 0 && currentDayTokens > 0) {
            // æ—§æ•°æ®ï¼šæ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»ï¼Œå‡è®¾70%ä¸ºè¾“å‡ºï¼Œ30%ä¸ºè¾“å…¥ï¼ˆåŸºäºä¸€èˆ¬å¯¹è¯æ¯”ä¾‹ï¼‰
            totalOutputTokensToday += Math.round(currentDayTokens * 0.7)
            totalInputTokensToday += Math.round(currentDayTokens * 0.3)
          } else {
            // æ–°æ•°æ®ï¼šä½¿ç”¨å®é™…çš„è¾“å…¥è¾“å‡ºåˆ†ç¦»
            totalInputTokensToday += inputTokens
            totalOutputTokensToday += outputTokens
          }

          // æ·»åŠ cache tokenç»Ÿè®¡
          totalCacheCreateTokensToday += cacheCreateTokens
          totalCacheReadTokensToday += cacheReadTokens
        }
      }

      // è·å–ä»Šæ—¥åˆ›å»ºçš„API Keyæ•°é‡ï¼ˆæ‰¹é‡ä¼˜åŒ–ï¼‰
      const allApiKeys = await this.scanKeys('apikey:*')
      let apiKeysCreatedToday = 0

      if (allApiKeys.length > 0) {
        const pipeline = this.client.pipeline()
        allApiKeys.forEach((key) => pipeline.hget(key, 'createdAt'))
        const results = await pipeline.exec()

        for (const [error, createdAt] of results) {
          if (!error && createdAt && createdAt.startsWith(today)) {
            apiKeysCreatedToday++
          }
        }
      }

      return {
        requestsToday: totalRequestsToday,
        tokensToday: totalTokensToday,
        inputTokensToday: totalInputTokensToday,
        outputTokensToday: totalOutputTokensToday,
        cacheCreateTokensToday: totalCacheCreateTokensToday,
        cacheReadTokensToday: totalCacheReadTokensToday,
        apiKeysCreatedToday
      }
    } catch (error) {
      console.error('Error getting today stats:', error)
      return {
        requestsToday: 0,
        tokensToday: 0,
        inputTokensToday: 0,
        outputTokensToday: 0,
        cacheCreateTokensToday: 0,
        cacheReadTokensToday: 0,
        apiKeysCreatedToday: 0
      }
    }
  }

  // ğŸ“ˆ è·å–ç³»ç»Ÿæ€»çš„å¹³å‡RPMå’ŒTPM
  async getSystemAverages() {
    try {
      const allApiKeys = await this.scanKeys('apikey:*')
      let totalRequests = 0
      let totalTokens = 0
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let oldestCreatedAt = new Date()

      // æ‰¹é‡è·å–æ‰€æœ‰usageæ•°æ®å’Œkeyæ•°æ®ï¼Œæé«˜æ€§èƒ½
      const usageKeys = allApiKeys.map((key) => `usage:${key.replace('apikey:', '')}`)
      const pipeline = this.client.pipeline()

      // æ·»åŠ æ‰€æœ‰usageæŸ¥è¯¢
      usageKeys.forEach((key) => pipeline.hgetall(key))
      // æ·»åŠ æ‰€æœ‰keyæ•°æ®æŸ¥è¯¢
      allApiKeys.forEach((key) => pipeline.hgetall(key))

      const results = await pipeline.exec()
      const usageResults = results.slice(0, usageKeys.length)
      const keyResults = results.slice(usageKeys.length)

      for (let i = 0; i < allApiKeys.length; i++) {
        const totalData = usageResults[i][1] || {}
        const keyData = keyResults[i][1] || {}

        totalRequests += parseInt(totalData.totalRequests) || 0
        totalTokens += parseInt(totalData.totalTokens) || 0
        totalInputTokens += parseInt(totalData.totalInputTokens) || 0
        totalOutputTokens += parseInt(totalData.totalOutputTokens) || 0

        const createdAt = keyData.createdAt ? new Date(keyData.createdAt) : new Date()
        if (createdAt < oldestCreatedAt) {
          oldestCreatedAt = createdAt
        }
      }

      const now = new Date()
      // ä¿æŒä¸ä¸ªäººAPI Keyè®¡ç®—ä¸€è‡´çš„ç®—æ³•ï¼šæŒ‰å¤©è®¡ç®—ç„¶åè½¬æ¢ä¸ºåˆ†é’Ÿ
      const daysSinceOldest = Math.max(
        1,
        Math.ceil((now - oldestCreatedAt) / (1000 * 60 * 60 * 24))
      )
      const totalMinutes = daysSinceOldest * 24 * 60

      return {
        systemRPM: Math.round((totalRequests / totalMinutes) * 100) / 100,
        systemTPM: Math.round((totalTokens / totalMinutes) * 100) / 100,
        totalInputTokens,
        totalOutputTokens,
        totalTokens
      }
    } catch (error) {
      console.error('Error getting system averages:', error)
      return {
        systemRPM: 0,
        systemTPM: 0,
        totalInputTokens: 0,
        totalOutputTokens: 0,
        totalTokens: 0
      }
    }
  }

  // ğŸ“Š è·å–å®æ—¶ç³»ç»ŸæŒ‡æ ‡ï¼ˆåŸºäºæ»‘åŠ¨çª—å£ï¼‰
  async getRealtimeSystemMetrics() {
    try {
      const configLocal = require('../../config/config')
      const windowMinutes = configLocal.system.metricsWindow || 5

      const now = new Date()
      const currentMinute = Math.floor(now.getTime() / 60000)

      // è°ƒè¯•ï¼šæ‰“å°å½“å‰æ—¶é—´å’Œåˆ†é’Ÿæ—¶é—´æˆ³
      logger.debug(
        `ğŸ” Realtime metrics - Current time: ${now.toISOString()}, Minute timestamp: ${currentMinute}`
      )

      // ä½¿ç”¨Pipelineæ‰¹é‡è·å–çª—å£å†…çš„æ‰€æœ‰åˆ†é’Ÿæ•°æ®
      const pipeline = this.client.pipeline()
      const minuteKeys = []
      for (let i = 0; i < windowMinutes; i++) {
        const minuteKey = `system:metrics:minute:${currentMinute - i}`
        minuteKeys.push(minuteKey)
        pipeline.hgetall(minuteKey)
      }

      logger.debug(`ğŸ” Realtime metrics - Checking keys: ${minuteKeys.join(', ')}`)

      const results = await pipeline.exec()

      // èšåˆè®¡ç®—
      let totalRequests = 0
      let totalTokens = 0
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let totalCacheCreateTokens = 0
      let totalCacheReadTokens = 0
      let validDataCount = 0

      results.forEach(([err, data], index) => {
        if (!err && data && Object.keys(data).length > 0) {
          validDataCount++
          totalRequests += parseInt(data.requests || 0)
          totalTokens += parseInt(data.totalTokens || 0)
          totalInputTokens += parseInt(data.inputTokens || 0)
          totalOutputTokens += parseInt(data.outputTokens || 0)
          totalCacheCreateTokens += parseInt(data.cacheCreateTokens || 0)
          totalCacheReadTokens += parseInt(data.cacheReadTokens || 0)

          logger.debug(`ğŸ” Realtime metrics - Key ${minuteKeys[index]} data:`, {
            requests: data.requests,
            totalTokens: data.totalTokens
          })
        }
      })

      logger.debug(
        `ğŸ” Realtime metrics - Valid data count: ${validDataCount}/${windowMinutes}, Total requests: ${totalRequests}, Total tokens: ${totalTokens}`
      )

      // è®¡ç®—å¹³å‡å€¼ï¼ˆæ¯åˆ†é’Ÿï¼‰
      const realtimeRPM =
        windowMinutes > 0 ? Math.round((totalRequests / windowMinutes) * 100) / 100 : 0
      const realtimeTPM =
        windowMinutes > 0 ? Math.round((totalTokens / windowMinutes) * 100) / 100 : 0

      const result = {
        realtimeRPM,
        realtimeTPM,
        windowMinutes,
        totalRequests,
        totalTokens,
        totalInputTokens,
        totalOutputTokens,
        totalCacheCreateTokens,
        totalCacheReadTokens
      }

      logger.debug('ğŸ” Realtime metrics - Final result:', result)

      return result
    } catch (error) {
      console.error('Error getting realtime system metrics:', error)
      // å¦‚æœå‡ºé”™ï¼Œè¿”å›å†å²å¹³å‡å€¼ä½œä¸ºé™çº§æ–¹æ¡ˆ
      const historicalMetrics = await this.getSystemAverages()
      return {
        realtimeRPM: historicalMetrics.systemRPM,
        realtimeTPM: historicalMetrics.systemTPM,
        windowMinutes: 0, // æ ‡è¯†ä½¿ç”¨äº†å†å²æ•°æ®
        totalRequests: 0,
        totalTokens: historicalMetrics.totalTokens,
        totalInputTokens: historicalMetrics.totalInputTokens,
        totalOutputTokens: historicalMetrics.totalOutputTokens,
        totalCacheCreateTokens: 0,
        totalCacheReadTokens: 0
      }
    }
  }

  // ğŸ”— ä¼šè¯stickyæ˜ å°„ç®¡ç†
  async setSessionAccountMapping(sessionHash, accountId, ttl = null) {
    const appConfig = require('../../config/config')
    // ä»é…ç½®è¯»å–TTLï¼ˆå°æ—¶ï¼‰ï¼Œè½¬æ¢ä¸ºç§’ï¼Œé»˜è®¤1å°æ—¶
    const defaultTTL = ttl !== null ? ttl : (appConfig.session?.stickyTtlHours || 1) * 60 * 60
    const key = `sticky_session:${sessionHash}`
    await this.client.set(key, accountId, 'EX', defaultTTL)
  }

  async getSessionAccountMapping(sessionHash) {
    const key = `sticky_session:${sessionHash}`
    return await this.client.get(key)
  }

  // ğŸš€ æ™ºèƒ½ä¼šè¯TTLç»­æœŸï¼šå‰©ä½™æ—¶é—´å°‘äºé˜ˆå€¼æ—¶è‡ªåŠ¨ç»­æœŸ
  async extendSessionAccountMappingTTL(sessionHash) {
    const appConfig = require('../../config/config')
    const key = `sticky_session:${sessionHash}`

    // ğŸ“Š ä»é…ç½®è·å–å‚æ•°
    const ttlHours = appConfig.session?.stickyTtlHours || 1 // å°æ—¶ï¼Œé»˜è®¤1å°æ—¶
    const thresholdMinutes = appConfig.session?.renewalThresholdMinutes || 0 // åˆ†é’Ÿï¼Œé»˜è®¤0ï¼ˆä¸ç»­æœŸï¼‰

    // å¦‚æœé˜ˆå€¼ä¸º0ï¼Œä¸æ‰§è¡Œç»­æœŸ
    if (thresholdMinutes === 0) {
      return true
    }

    const fullTTL = ttlHours * 60 * 60 // è½¬æ¢ä¸ºç§’
    const renewalThreshold = thresholdMinutes * 60 // è½¬æ¢ä¸ºç§’

    try {
      // è·å–å½“å‰å‰©ä½™TTLï¼ˆç§’ï¼‰
      const remainingTTL = await this.client.ttl(key)

      // é”®ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ
      if (remainingTTL === -2) {
        return false
      }

      // é”®å­˜åœ¨ä½†æ²¡æœ‰TTLï¼ˆæ°¸ä¸è¿‡æœŸï¼Œä¸éœ€è¦å¤„ç†ï¼‰
      if (remainingTTL === -1) {
        return true
      }

      // ğŸ¯ æ™ºèƒ½ç»­æœŸç­–ç•¥ï¼šä»…åœ¨å‰©ä½™æ—¶é—´å°‘äºé˜ˆå€¼æ—¶æ‰ç»­æœŸ
      if (remainingTTL < renewalThreshold) {
        await this.client.expire(key, fullTTL)
        logger.debug(
          `ğŸ”„ Renewed sticky session TTL: ${sessionHash} (was ${Math.round(
            remainingTTL / 60
          )}min, renewed to ${ttlHours}h)`
        )
        return true
      }

      // å‰©ä½™æ—¶é—´å……è¶³ï¼Œæ— éœ€ç»­æœŸ
      logger.debug(
        `âœ… Sticky session TTL sufficient: ${sessionHash} (remaining ${Math.round(
          remainingTTL / 60
        )}min)`
      )
      return true
    } catch (error) {
      logger.error('âŒ Failed to extend session TTL:', error)
      return false
    }
  }

  async deleteSessionAccountMapping(sessionHash) {
    const key = `sticky_session:${sessionHash}`
    return await this.client.del(key)
  }

  // ğŸ§¹ æ¸…ç†è¿‡æœŸæ•°æ®ï¼ˆä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
  async cleanup() {
    try {
      const patterns = ['usage:daily:*', 'ratelimit:*', 'session:*', 'sticky_session:*', 'oauth:*']

      for (const pattern of patterns) {
        const keys = await this.scanKeys(pattern)
        const pipeline = this.client.pipeline()

        for (const key of keys) {
          const ttl = await this.client.ttl(key)
          if (ttl === -1) {
            // æ²¡æœ‰è®¾ç½®è¿‡æœŸæ—¶é—´çš„é”®
            if (key.startsWith('oauth:')) {
              pipeline.expire(key, 600) // OAuthä¼šè¯è®¾ç½®10åˆ†é’Ÿè¿‡æœŸ
            } else {
              pipeline.expire(key, 86400) // å…¶ä»–è®¾ç½®1å¤©è¿‡æœŸ
            }
          }
        }

        await pipeline.exec()
      }

      logger.info('ğŸ§¹ Redis cleanup completed')
    } catch (error) {
      logger.error('âŒ Redis cleanup failed:', error)
    }
  }

  // è·å–å¹¶å‘é…ç½®
  _getConcurrencyConfig() {
    const defaults = {
      leaseSeconds: 300,
      renewIntervalSeconds: 30,
      cleanupGraceSeconds: 30
    }

    const configValues = {
      ...defaults,
      ...(config.concurrency || {})
    }

    const normalizeNumber = (value, fallback, options = {}) => {
      const parsed = Number(value)
      if (!Number.isFinite(parsed)) {
        return fallback
      }

      if (options.allowZero && parsed === 0) {
        return 0
      }

      if (options.min !== undefined && parsed < options.min) {
        return options.min
      }

      return parsed
    }

    return {
      leaseSeconds: normalizeNumber(configValues.leaseSeconds, defaults.leaseSeconds, {
        min: 30
      }),
      renewIntervalSeconds: normalizeNumber(
        configValues.renewIntervalSeconds,
        defaults.renewIntervalSeconds,
        {
          allowZero: true,
          min: 0
        }
      ),
      cleanupGraceSeconds: normalizeNumber(
        configValues.cleanupGraceSeconds,
        defaults.cleanupGraceSeconds,
        {
          min: 0
        }
      )
    }
  }

  // å¢åŠ å¹¶å‘è®¡æ•°ï¼ˆåŸºäºç§Ÿçº¦çš„æœ‰åºé›†åˆï¼‰
  async incrConcurrency(apiKeyId, requestId, leaseSeconds = null) {
    if (!requestId) {
      throw new Error('Request ID is required for concurrency tracking')
    }

    try {
      const { leaseSeconds: defaultLeaseSeconds, cleanupGraceSeconds } =
        this._getConcurrencyConfig()
      const lease = leaseSeconds || defaultLeaseSeconds
      const key = `concurrency:${apiKeyId}`
      const now = Date.now()
      const expireAt = now + lease * 1000
      const ttl = Math.max((lease + cleanupGraceSeconds) * 1000, 60000)

      const luaScript = `
        local key = KEYS[1]
        local member = ARGV[1]
        local expireAt = tonumber(ARGV[2])
        local now = tonumber(ARGV[3])
        local ttl = tonumber(ARGV[4])

        redis.call('ZREMRANGEBYSCORE', key, '-inf', now)
        redis.call('ZADD', key, expireAt, member)

        if ttl > 0 then
          redis.call('PEXPIRE', key, ttl)
        end

        local count = redis.call('ZCARD', key)
        return count
      `

      const count = await this.client.eval(luaScript, 1, key, requestId, expireAt, now, ttl)
      logger.database(
        `ğŸ”¢ Incremented concurrency for key ${apiKeyId}: ${count} (request ${requestId})`
      )
      return count
    } catch (error) {
      logger.error('âŒ Failed to increment concurrency:', error)
      throw error
    }
  }

  // åˆ·æ–°å¹¶å‘ç§Ÿçº¦ï¼Œé˜²æ­¢é•¿è¿æ¥æå‰è¿‡æœŸ
  async refreshConcurrencyLease(apiKeyId, requestId, leaseSeconds = null) {
    if (!requestId) {
      return 0
    }

    try {
      const { leaseSeconds: defaultLeaseSeconds, cleanupGraceSeconds } =
        this._getConcurrencyConfig()
      const lease = leaseSeconds || defaultLeaseSeconds
      const key = `concurrency:${apiKeyId}`
      const now = Date.now()
      const expireAt = now + lease * 1000
      const ttl = Math.max((lease + cleanupGraceSeconds) * 1000, 60000)

      const luaScript = `
        local key = KEYS[1]
        local member = ARGV[1]
        local expireAt = tonumber(ARGV[2])
        local now = tonumber(ARGV[3])
        local ttl = tonumber(ARGV[4])

        redis.call('ZREMRANGEBYSCORE', key, '-inf', now)

        local exists = redis.call('ZSCORE', key, member)

        if exists then
          redis.call('ZADD', key, expireAt, member)
          if ttl > 0 then
            redis.call('PEXPIRE', key, ttl)
          end
          return 1
        end

        return 0
      `

      const refreshed = await this.client.eval(luaScript, 1, key, requestId, expireAt, now, ttl)
      if (refreshed === 1) {
        logger.debug(`ğŸ”„ Refreshed concurrency lease for key ${apiKeyId} (request ${requestId})`)
      }
      return refreshed
    } catch (error) {
      logger.error('âŒ Failed to refresh concurrency lease:', error)
      return 0
    }
  }

  // å‡å°‘å¹¶å‘è®¡æ•°
  async decrConcurrency(apiKeyId, requestId) {
    try {
      const key = `concurrency:${apiKeyId}`
      const now = Date.now()

      const luaScript = `
        local key = KEYS[1]
        local member = ARGV[1]
        local now = tonumber(ARGV[2])

        if member then
          redis.call('ZREM', key, member)
        end

        redis.call('ZREMRANGEBYSCORE', key, '-inf', now)

        local count = redis.call('ZCARD', key)
        if count <= 0 then
          redis.call('DEL', key)
          return 0
        end

        return count
      `

      const count = await this.client.eval(luaScript, 1, key, requestId || '', now)
      logger.database(
        `ğŸ”¢ Decremented concurrency for key ${apiKeyId}: ${count} (request ${requestId || 'n/a'})`
      )
      return count
    } catch (error) {
      logger.error('âŒ Failed to decrement concurrency:', error)
      throw error
    }
  }

  // è·å–å½“å‰å¹¶å‘æ•°
  async getConcurrency(apiKeyId) {
    try {
      const key = `concurrency:${apiKeyId}`
      const now = Date.now()

      const luaScript = `
        local key = KEYS[1]
        local now = tonumber(ARGV[1])

        redis.call('ZREMRANGEBYSCORE', key, '-inf', now)
        return redis.call('ZCARD', key)
      `

      const count = await this.client.eval(luaScript, 1, key, now)
      return parseInt(count || 0)
    } catch (error) {
      logger.error('âŒ Failed to get concurrency:', error)
      return 0
    }
  }

  // ğŸ¢ Claude Console è´¦æˆ·å¹¶å‘æ§åˆ¶ï¼ˆå¤ç”¨ç°æœ‰å¹¶å‘æœºåˆ¶ï¼‰
  // å¢åŠ  Console è´¦æˆ·å¹¶å‘è®¡æ•°
  async incrConsoleAccountConcurrency(accountId, requestId, leaseSeconds = null) {
    if (!requestId) {
      throw new Error('Request ID is required for console account concurrency tracking')
    }
    // ä½¿ç”¨ç‰¹æ®Šçš„ key å‰ç¼€åŒºåˆ† Console è´¦æˆ·å¹¶å‘
    const compositeKey = `console_account:${accountId}`
    return await this.incrConcurrency(compositeKey, requestId, leaseSeconds)
  }

  // åˆ·æ–° Console è´¦æˆ·å¹¶å‘ç§Ÿçº¦
  async refreshConsoleAccountConcurrencyLease(accountId, requestId, leaseSeconds = null) {
    if (!requestId) {
      return 0
    }
    const compositeKey = `console_account:${accountId}`
    return await this.refreshConcurrencyLease(compositeKey, requestId, leaseSeconds)
  }

  // å‡å°‘ Console è´¦æˆ·å¹¶å‘è®¡æ•°
  async decrConsoleAccountConcurrency(accountId, requestId) {
    const compositeKey = `console_account:${accountId}`
    return await this.decrConcurrency(compositeKey, requestId)
  }

  // è·å– Console è´¦æˆ·å½“å‰å¹¶å‘æ•°
  async getConsoleAccountConcurrency(accountId) {
    const compositeKey = `console_account:${accountId}`
    return await this.getConcurrency(compositeKey)
  }

  // ğŸ”§ å¹¶å‘ç®¡ç†æ–¹æ³•ï¼ˆç”¨äºç®¡ç†å‘˜æ‰‹åŠ¨æ¸…ç†ï¼‰

  /**
   * è·å–æ‰€æœ‰å¹¶å‘çŠ¶æ€ï¼ˆä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
   * @returns {Promise<Array>} å¹¶å‘çŠ¶æ€åˆ—è¡¨
   */
  async getAllConcurrencyStatus() {
    try {
      const client = this.getClientSafe()
      const keys = await this.scanKeys('concurrency:*')
      const now = Date.now()
      const results = []

      for (const key of keys) {
        // è·³è¿‡å·²çŸ¥é Sorted Set ç±»å‹çš„é”®
        // - concurrency:queue:stats:* æ˜¯ Hash ç±»å‹
        // - concurrency:queue:wait_times:* æ˜¯ List ç±»å‹
        // - concurrency:queue:* (ä¸å«stats/wait_times) æ˜¯ String ç±»å‹
        if (
          key.startsWith('concurrency:queue:stats:') ||
          key.startsWith('concurrency:queue:wait_times:') ||
          (key.startsWith('concurrency:queue:') &&
            !key.includes(':stats:') &&
            !key.includes(':wait_times:'))
        ) {
          continue
        }

        // æ£€æŸ¥é”®ç±»å‹ï¼Œåªå¤„ç† Sorted Set
        const keyType = await client.type(key)
        if (keyType !== 'zset') {
          logger.debug(`ğŸ”¢ getAllConcurrencyStatus skipped non-zset key: ${key} (type: ${keyType})`)
          continue
        }

        // æå– apiKeyIdï¼ˆå»æ‰ concurrency: å‰ç¼€ï¼‰
        const apiKeyId = key.replace('concurrency:', '')

        // è·å–æ‰€æœ‰æˆå‘˜å’Œåˆ†æ•°ï¼ˆè¿‡æœŸæ—¶é—´ï¼‰
        const members = await client.zrangebyscore(key, now, '+inf', 'WITHSCORES')

        // è§£ææˆå‘˜å’Œè¿‡æœŸæ—¶é—´
        const activeRequests = []
        for (let i = 0; i < members.length; i += 2) {
          const requestId = members[i]
          const expireAt = parseInt(members[i + 1])
          const remainingSeconds = Math.max(0, Math.round((expireAt - now) / 1000))
          activeRequests.push({
            requestId,
            expireAt: new Date(expireAt).toISOString(),
            remainingSeconds
          })
        }

        // è·å–è¿‡æœŸçš„æˆå‘˜æ•°é‡
        const expiredCount = await client.zcount(key, '-inf', now)

        results.push({
          apiKeyId,
          key,
          activeCount: activeRequests.length,
          expiredCount,
          activeRequests
        })
      }

      return results
    } catch (error) {
      logger.error('âŒ Failed to get all concurrency status:', error)
      throw error
    }
  }

  /**
   * è·å–ç‰¹å®š API Key çš„å¹¶å‘çŠ¶æ€è¯¦æƒ…
   * @param {string} apiKeyId - API Key ID
   * @returns {Promise<Object>} å¹¶å‘çŠ¶æ€è¯¦æƒ…
   */
  async getConcurrencyStatus(apiKeyId) {
    try {
      const client = this.getClientSafe()
      const key = `concurrency:${apiKeyId}`
      const now = Date.now()

      // æ£€æŸ¥ key æ˜¯å¦å­˜åœ¨
      const exists = await client.exists(key)
      if (!exists) {
        return {
          apiKeyId,
          key,
          activeCount: 0,
          expiredCount: 0,
          activeRequests: [],
          exists: false
        }
      }

      // æ£€æŸ¥é”®ç±»å‹ï¼Œåªå¤„ç† Sorted Set
      const keyType = await client.type(key)
      if (keyType !== 'zset') {
        logger.warn(
          `âš ï¸ getConcurrencyStatus: key ${key} has unexpected type: ${keyType}, expected zset`
        )
        return {
          apiKeyId,
          key,
          activeCount: 0,
          expiredCount: 0,
          activeRequests: [],
          exists: true,
          invalidType: keyType
        }
      }

      // è·å–æ‰€æœ‰æˆå‘˜å’Œåˆ†æ•°
      const allMembers = await client.zrange(key, 0, -1, 'WITHSCORES')

      const activeRequests = []
      const expiredRequests = []

      for (let i = 0; i < allMembers.length; i += 2) {
        const requestId = allMembers[i]
        const expireAt = parseInt(allMembers[i + 1])
        const remainingSeconds = Math.round((expireAt - now) / 1000)

        const requestInfo = {
          requestId,
          expireAt: new Date(expireAt).toISOString(),
          remainingSeconds
        }

        if (expireAt > now) {
          activeRequests.push(requestInfo)
        } else {
          expiredRequests.push(requestInfo)
        }
      }

      return {
        apiKeyId,
        key,
        activeCount: activeRequests.length,
        expiredCount: expiredRequests.length,
        activeRequests,
        expiredRequests,
        exists: true
      }
    } catch (error) {
      logger.error(`âŒ Failed to get concurrency status for ${apiKeyId}:`, error)
      throw error
    }
  }

  /**
   * å¼ºåˆ¶æ¸…ç†ç‰¹å®š API Key çš„å¹¶å‘è®¡æ•°ï¼ˆå¿½ç•¥ç§Ÿçº¦ï¼‰
   * @param {string} apiKeyId - API Key ID
   * @returns {Promise<Object>} æ¸…ç†ç»“æœ
   */
  async forceClearConcurrency(apiKeyId) {
    try {
      const client = this.getClientSafe()
      const key = `concurrency:${apiKeyId}`

      // æ£€æŸ¥é”®ç±»å‹
      const keyType = await client.type(key)

      let beforeCount = 0
      let isLegacy = false

      if (keyType === 'zset') {
        // æ­£å¸¸çš„ zset é”®ï¼Œè·å–æ¡ç›®æ•°
        beforeCount = await client.zcard(key)
      } else if (keyType !== 'none') {
        // é zset ä¸”éç©ºçš„é—ç•™é”®
        isLegacy = true
        logger.warn(
          `âš ï¸ forceClearConcurrency: key ${key} has unexpected type: ${keyType}, will be deleted`
        )
      }

      // åˆ é™¤é”®ï¼ˆæ— è®ºä»€ä¹ˆç±»å‹ï¼‰
      await client.del(key)

      logger.warn(
        `ğŸ§¹ Force cleared concurrency for key ${apiKeyId}, removed ${beforeCount} entries${isLegacy ? ' (legacy key)' : ''}`
      )

      return {
        apiKeyId,
        key,
        clearedCount: beforeCount,
        type: keyType,
        legacy: isLegacy,
        success: true
      }
    } catch (error) {
      logger.error(`âŒ Failed to force clear concurrency for ${apiKeyId}:`, error)
      throw error
    }
  }

  /**
   * å¼ºåˆ¶æ¸…ç†æ‰€æœ‰å¹¶å‘è®¡æ•°ï¼ˆä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
   * @returns {Promise<Object>} æ¸…ç†ç»“æœ
   */
  async forceClearAllConcurrency() {
    try {
      const client = this.getClientSafe()
      const keys = await this.scanKeys('concurrency:*')

      let totalCleared = 0
      let legacyCleared = 0
      const clearedKeys = []

      for (const key of keys) {
        // è·³è¿‡ queue ç›¸å…³çš„é”®ï¼ˆå®ƒä»¬æœ‰å„è‡ªçš„æ¸…ç†é€»è¾‘ï¼‰
        if (key.startsWith('concurrency:queue:')) {
          continue
        }

        // æ£€æŸ¥é”®ç±»å‹
        const keyType = await client.type(key)
        if (keyType === 'zset') {
          const count = await client.zcard(key)
          await client.del(key)
          totalCleared += count
          clearedKeys.push({
            key,
            clearedCount: count,
            type: 'zset'
          })
        } else {
          // é zset ç±»å‹çš„é—ç•™é”®ï¼Œç›´æ¥åˆ é™¤
          await client.del(key)
          legacyCleared++
          clearedKeys.push({
            key,
            clearedCount: 0,
            type: keyType,
            legacy: true
          })
        }
      }

      logger.warn(
        `ğŸ§¹ Force cleared all concurrency: ${clearedKeys.length} keys, ${totalCleared} entries, ${legacyCleared} legacy keys`
      )

      return {
        keysCleared: clearedKeys.length,
        totalEntriesCleared: totalCleared,
        legacyKeysCleared: legacyCleared,
        clearedKeys,
        success: true
      }
    } catch (error) {
      logger.error('âŒ Failed to force clear all concurrency:', error)
      throw error
    }
  }

  /**
   * æ¸…ç†è¿‡æœŸçš„å¹¶å‘æ¡ç›®ï¼ˆä¸å½±å“æ´»è·ƒè¯·æ±‚ï¼Œä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
   * @param {string} apiKeyId - API Key IDï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™æ¸…ç†æ‰€æœ‰ï¼‰
   * @returns {Promise<Object>} æ¸…ç†ç»“æœ
   */
  async cleanupExpiredConcurrency(apiKeyId = null) {
    try {
      const client = this.getClientSafe()
      const now = Date.now()
      let keys

      if (apiKeyId) {
        keys = [`concurrency:${apiKeyId}`]
      } else {
        keys = await this.scanKeys('concurrency:*')
      }

      let totalCleaned = 0
      let legacyCleaned = 0
      const cleanedKeys = []

      for (const key of keys) {
        // è·³è¿‡ queue ç›¸å…³çš„é”®ï¼ˆå®ƒä»¬æœ‰å„è‡ªçš„æ¸…ç†é€»è¾‘ï¼‰
        if (key.startsWith('concurrency:queue:')) {
          continue
        }

        // æ£€æŸ¥é”®ç±»å‹
        const keyType = await client.type(key)
        if (keyType !== 'zset') {
          // é zset ç±»å‹çš„é—ç•™é”®ï¼Œç›´æ¥åˆ é™¤
          await client.del(key)
          legacyCleaned++
          cleanedKeys.push({
            key,
            cleanedCount: 0,
            type: keyType,
            legacy: true
          })
          continue
        }

        // åªæ¸…ç†è¿‡æœŸçš„æ¡ç›®
        const cleaned = await client.zremrangebyscore(key, '-inf', now)
        if (cleaned > 0) {
          totalCleaned += cleaned
          cleanedKeys.push({
            key,
            cleanedCount: cleaned
          })
        }

        // å¦‚æœ key ä¸ºç©ºï¼Œåˆ é™¤å®ƒ
        const remaining = await client.zcard(key)
        if (remaining === 0) {
          await client.del(key)
        }
      }

      logger.info(
        `ğŸ§¹ Cleaned up expired concurrency: ${totalCleaned} entries from ${cleanedKeys.length} keys, ${legacyCleaned} legacy keys removed`
      )

      return {
        keysProcessed: keys.length,
        keysCleaned: cleanedKeys.length,
        totalEntriesCleaned: totalCleaned,
        legacyKeysRemoved: legacyCleaned,
        cleanedKeys,
        success: true
      }
    } catch (error) {
      logger.error('âŒ Failed to cleanup expired concurrency:', error)
      throw error
    }
  }

  // ğŸ”§ Basic Redis operations wrapper methods for convenience
  async get(key) {
    const client = this.getClientSafe()
    return await client.get(key)
  }

  async set(key, value, ...args) {
    const client = this.getClientSafe()
    return await client.set(key, value, ...args)
  }

  async setex(key, ttl, value) {
    const client = this.getClientSafe()
    return await client.setex(key, ttl, value)
  }

  async del(...keys) {
    const client = this.getClientSafe()
    return await client.del(...keys)
  }

  async keys(pattern) {
    const client = this.getClientSafe()
    return await client.keys(pattern)
  }

  // ğŸ“Š è·å–è´¦æˆ·ä¼šè¯çª—å£å†…çš„ä½¿ç”¨ç»Ÿè®¡ï¼ˆåŒ…å«æ¨¡å‹ç»†åˆ†ï¼‰
  async getAccountSessionWindowUsage(accountId, windowStart, windowEnd) {
    try {
      if (!windowStart || !windowEnd) {
        return {
          totalInputTokens: 0,
          totalOutputTokens: 0,
          totalCacheCreateTokens: 0,
          totalCacheReadTokens: 0,
          totalAllTokens: 0,
          totalRequests: 0,
          modelUsage: {}
        }
      }

      const startDate = new Date(windowStart)
      const endDate = new Date(windowEnd)

      // æ·»åŠ æ—¥å¿—ä»¥è°ƒè¯•æ—¶é—´çª—å£
      logger.debug(`ğŸ“Š Getting session window usage for account ${accountId}`)
      logger.debug(`   Window: ${windowStart} to ${windowEnd}`)
      logger.debug(`   Start UTC: ${startDate.toISOString()}, End UTC: ${endDate.toISOString()}`)

      // è·å–çª—å£å†…æ‰€æœ‰å¯èƒ½çš„å°æ—¶é”®
      // é‡è¦ï¼šéœ€è¦ä½¿ç”¨é…ç½®çš„æ—¶åŒºæ¥æ„å»ºé”®åï¼Œå› ä¸ºæ•°æ®å­˜å‚¨æ—¶ä½¿ç”¨çš„æ˜¯é…ç½®æ—¶åŒº
      const hourlyKeys = []
      const currentHour = new Date(startDate)
      currentHour.setMinutes(0)
      currentHour.setSeconds(0)
      currentHour.setMilliseconds(0)

      while (currentHour <= endDate) {
        // ä½¿ç”¨æ—¶åŒºè½¬æ¢å‡½æ•°æ¥è·å–æ­£ç¡®çš„æ—¥æœŸå’Œå°æ—¶
        const tzDateStr = getDateStringInTimezone(currentHour)
        const tzHour = String(getHourInTimezone(currentHour)).padStart(2, '0')
        const key = `account_usage:hourly:${accountId}:${tzDateStr}:${tzHour}`

        logger.debug(`   Adding hourly key: ${key}`)
        hourlyKeys.push(key)
        currentHour.setHours(currentHour.getHours() + 1)
      }

      // æ‰¹é‡è·å–æ‰€æœ‰å°æ—¶çš„æ•°æ®
      const pipeline = this.client.pipeline()
      for (const key of hourlyKeys) {
        pipeline.hgetall(key)
      }
      const results = await pipeline.exec()

      // èšåˆæ‰€æœ‰æ•°æ®
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let totalCacheCreateTokens = 0
      let totalCacheReadTokens = 0
      let totalAllTokens = 0
      let totalRequests = 0
      const modelUsage = {}

      logger.debug(`   Processing ${results.length} hourly results`)

      for (const [error, data] of results) {
        if (error || !data || Object.keys(data).length === 0) {
          continue
        }

        // å¤„ç†æ€»è®¡æ•°æ®
        const hourInputTokens = parseInt(data.inputTokens || 0)
        const hourOutputTokens = parseInt(data.outputTokens || 0)
        const hourCacheCreateTokens = parseInt(data.cacheCreateTokens || 0)
        const hourCacheReadTokens = parseInt(data.cacheReadTokens || 0)
        const hourAllTokens = parseInt(data.allTokens || 0)
        const hourRequests = parseInt(data.requests || 0)

        totalInputTokens += hourInputTokens
        totalOutputTokens += hourOutputTokens
        totalCacheCreateTokens += hourCacheCreateTokens
        totalCacheReadTokens += hourCacheReadTokens
        totalAllTokens += hourAllTokens
        totalRequests += hourRequests

        if (hourAllTokens > 0) {
          logger.debug(`   Hour data: allTokens=${hourAllTokens}, requests=${hourRequests}`)
        }

        // å¤„ç†æ¯ä¸ªæ¨¡å‹çš„æ•°æ®
        for (const [key, value] of Object.entries(data)) {
          // æŸ¥æ‰¾æ¨¡å‹ç›¸å…³çš„é”®ï¼ˆæ ¼å¼: model:{modelName}:{metric}ï¼‰
          if (key.startsWith('model:')) {
            const parts = key.split(':')
            if (parts.length >= 3) {
              const modelName = parts[1]
              const metric = parts.slice(2).join(':')

              if (!modelUsage[modelName]) {
                modelUsage[modelName] = {
                  inputTokens: 0,
                  outputTokens: 0,
                  cacheCreateTokens: 0,
                  cacheReadTokens: 0,
                  allTokens: 0,
                  requests: 0
                }
              }

              if (metric === 'inputTokens') {
                modelUsage[modelName].inputTokens += parseInt(value || 0)
              } else if (metric === 'outputTokens') {
                modelUsage[modelName].outputTokens += parseInt(value || 0)
              } else if (metric === 'cacheCreateTokens') {
                modelUsage[modelName].cacheCreateTokens += parseInt(value || 0)
              } else if (metric === 'cacheReadTokens') {
                modelUsage[modelName].cacheReadTokens += parseInt(value || 0)
              } else if (metric === 'allTokens') {
                modelUsage[modelName].allTokens += parseInt(value || 0)
              } else if (metric === 'requests') {
                modelUsage[modelName].requests += parseInt(value || 0)
              }
            }
          }
        }
      }

      logger.debug(`ğŸ“Š Session window usage summary:`)
      logger.debug(`   Total allTokens: ${totalAllTokens}`)
      logger.debug(`   Total requests: ${totalRequests}`)
      logger.debug(`   Input: ${totalInputTokens}, Output: ${totalOutputTokens}`)
      logger.debug(
        `   Cache Create: ${totalCacheCreateTokens}, Cache Read: ${totalCacheReadTokens}`
      )

      return {
        totalInputTokens,
        totalOutputTokens,
        totalCacheCreateTokens,
        totalCacheReadTokens,
        totalAllTokens,
        totalRequests,
        modelUsage
      }
    } catch (error) {
      logger.error(`âŒ Failed to get session window usage for account ${accountId}:`, error)
      return {
        totalInputTokens: 0,
        totalOutputTokens: 0,
        totalCacheCreateTokens: 0,
        totalCacheReadTokens: 0,
        totalAllTokens: 0,
        totalRequests: 0,
        modelUsage: {}
      }
    }
  }
}

const redisClient = new RedisClient()

// åˆ†å¸ƒå¼é”ç›¸å…³æ–¹æ³•
redisClient.setAccountLock = async function (lockKey, lockValue, ttlMs) {
  try {
    // ä½¿ç”¨SET NX PXå®ç°åŸå­æ€§çš„é”è·å–
    // ioredisè¯­æ³•: set(key, value, 'PX', milliseconds, 'NX')
    const result = await this.client.set(lockKey, lockValue, 'PX', ttlMs, 'NX')
    return result === 'OK'
  } catch (error) {
    logger.error(`Failed to acquire lock ${lockKey}:`, error)
    return false
  }
}

redisClient.releaseAccountLock = async function (lockKey, lockValue) {
  try {
    // ä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åªæœ‰æŒæœ‰é”çš„è¿›ç¨‹æ‰èƒ½é‡Šæ”¾é”
    const script = `
      if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
      else
        return 0
      end
    `
    // ioredisè¯­æ³•: eval(script, numberOfKeys, key1, key2, ..., arg1, arg2, ...)
    const result = await this.client.eval(script, 1, lockKey, lockValue)
    return result === 1
  } catch (error) {
    logger.error(`Failed to release lock ${lockKey}:`, error)
    return false
  }
}

// å¯¼å‡ºæ—¶åŒºè¾…åŠ©å‡½æ•°
redisClient.getDateInTimezone = getDateInTimezone
redisClient.getDateStringInTimezone = getDateStringInTimezone
redisClient.getHourInTimezone = getHourInTimezone
redisClient.getWeekStringInTimezone = getWeekStringInTimezone

// ============== ç”¨æˆ·æ¶ˆæ¯é˜Ÿåˆ—ç›¸å…³æ–¹æ³• ==============

/**
 * å°è¯•è·å–ç”¨æˆ·æ¶ˆæ¯é˜Ÿåˆ—é”
 * ä½¿ç”¨ Lua è„šæœ¬ä¿è¯åŸå­æ€§
 * @param {string} accountId - è´¦æˆ·ID
 * @param {string} requestId - è¯·æ±‚ID
 * @param {number} lockTtlMs - é” TTLï¼ˆæ¯«ç§’ï¼‰
 * @param {number} delayMs - è¯·æ±‚é—´éš”ï¼ˆæ¯«ç§’ï¼‰
 * @returns {Promise<{acquired: boolean, waitMs: number}>}
 *   - acquired: æ˜¯å¦æˆåŠŸè·å–é”
 *   - waitMs: éœ€è¦ç­‰å¾…çš„æ¯«ç§’æ•°ï¼ˆ-1è¡¨ç¤ºè¢«å ç”¨éœ€ç­‰å¾…ï¼Œ>=0è¡¨ç¤ºéœ€è¦å»¶è¿Ÿçš„æ¯«ç§’æ•°ï¼‰
 */
redisClient.acquireUserMessageLock = async function (accountId, requestId, lockTtlMs, delayMs) {
  const lockKey = `user_msg_queue_lock:${accountId}`
  const lastTimeKey = `user_msg_queue_last:${accountId}`

  const script = `
    local lockKey = KEYS[1]
    local lastTimeKey = KEYS[2]
    local requestId = ARGV[1]
    local lockTtl = tonumber(ARGV[2])
    local delayMs = tonumber(ARGV[3])

    -- æ£€æŸ¥é”æ˜¯å¦ç©ºé—²
    local currentLock = redis.call('GET', lockKey)
    if currentLock == false then
      -- æ£€æŸ¥æ˜¯å¦éœ€è¦å»¶è¿Ÿ
      local lastTime = redis.call('GET', lastTimeKey)
      local now = redis.call('TIME')
      local nowMs = tonumber(now[1]) * 1000 + math.floor(tonumber(now[2]) / 1000)

      if lastTime then
        local elapsed = nowMs - tonumber(lastTime)
        if elapsed < delayMs then
          -- éœ€è¦ç­‰å¾…çš„æ¯«ç§’æ•°
          return {0, delayMs - elapsed}
        end
      end

      -- è·å–é”
      redis.call('SET', lockKey, requestId, 'PX', lockTtl)
      return {1, 0}
    end

    -- é”è¢«å ç”¨ï¼Œè¿”å›ç­‰å¾…
    return {0, -1}
  `

  try {
    const result = await this.client.eval(
      script,
      2,
      lockKey,
      lastTimeKey,
      requestId,
      lockTtlMs,
      delayMs
    )
    return {
      acquired: result[0] === 1,
      waitMs: result[1]
    }
  } catch (error) {
    logger.error(`Failed to acquire user message lock for account ${accountId}:`, error)
    // è¿”å› redisError æ ‡è®°ï¼Œè®©ä¸Šå±‚èƒ½åŒºåˆ† Redis æ•…éšœå’Œæ­£å¸¸é”å ç”¨
    return { acquired: false, waitMs: -1, redisError: true, errorMessage: error.message }
  }
}

/**
 * é‡Šæ”¾ç”¨æˆ·æ¶ˆæ¯é˜Ÿåˆ—é”å¹¶è®°å½•å®Œæˆæ—¶é—´
 * @param {string} accountId - è´¦æˆ·ID
 * @param {string} requestId - è¯·æ±‚ID
 * @returns {Promise<boolean>} æ˜¯å¦æˆåŠŸé‡Šæ”¾
 */
redisClient.releaseUserMessageLock = async function (accountId, requestId) {
  const lockKey = `user_msg_queue_lock:${accountId}`
  const lastTimeKey = `user_msg_queue_last:${accountId}`

  const script = `
    local lockKey = KEYS[1]
    local lastTimeKey = KEYS[2]
    local requestId = ARGV[1]

    -- éªŒè¯é”æŒæœ‰è€…
    local currentLock = redis.call('GET', lockKey)
    if currentLock == requestId then
      -- è®°å½•å®Œæˆæ—¶é—´
      local now = redis.call('TIME')
      local nowMs = tonumber(now[1]) * 1000 + math.floor(tonumber(now[2]) / 1000)
      redis.call('SET', lastTimeKey, nowMs, 'EX', 60)  -- 60ç§’åè¿‡æœŸ

      -- åˆ é™¤é”
      redis.call('DEL', lockKey)
      return 1
    end
    return 0
  `

  try {
    const result = await this.client.eval(script, 2, lockKey, lastTimeKey, requestId)
    return result === 1
  } catch (error) {
    logger.error(`Failed to release user message lock for account ${accountId}:`, error)
    return false
  }
}

/**
 * å¼ºåˆ¶é‡Šæ”¾ç”¨æˆ·æ¶ˆæ¯é˜Ÿåˆ—é”ï¼ˆç”¨äºæ¸…ç†å­¤å„¿é”ï¼‰
 * @param {string} accountId - è´¦æˆ·ID
 * @returns {Promise<boolean>} æ˜¯å¦æˆåŠŸé‡Šæ”¾
 */
redisClient.forceReleaseUserMessageLock = async function (accountId) {
  const lockKey = `user_msg_queue_lock:${accountId}`

  try {
    await this.client.del(lockKey)
    return true
  } catch (error) {
    logger.error(`Failed to force release user message lock for account ${accountId}:`, error)
    return false
  }
}

/**
 * è·å–ç”¨æˆ·æ¶ˆæ¯é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
 * @param {string} accountId - è´¦æˆ·ID
 * @returns {Promise<Object>} é˜Ÿåˆ—ç»Ÿè®¡
 */
redisClient.getUserMessageQueueStats = async function (accountId) {
  const lockKey = `user_msg_queue_lock:${accountId}`
  const lastTimeKey = `user_msg_queue_last:${accountId}`

  try {
    const [lockHolder, lastTime, lockTtl] = await Promise.all([
      this.client.get(lockKey),
      this.client.get(lastTimeKey),
      this.client.pttl(lockKey)
    ])

    return {
      accountId,
      isLocked: !!lockHolder,
      lockHolder,
      lockTtlMs: lockTtl > 0 ? lockTtl : 0,
      lockTtlRaw: lockTtl, // åŸå§‹ PTTL å€¼ï¼š>0 æœ‰TTLï¼Œ-1 æ— è¿‡æœŸæ—¶é—´ï¼Œ-2 é”®ä¸å­˜åœ¨
      lastCompletedAt: lastTime ? new Date(parseInt(lastTime)).toISOString() : null
    }
  } catch (error) {
    logger.error(`Failed to get user message queue stats for account ${accountId}:`, error)
    return {
      accountId,
      isLocked: false,
      lockHolder: null,
      lockTtlMs: 0,
      lockTtlRaw: -2,
      lastCompletedAt: null
    }
  }
}

/**
 * æ‰«ææ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯é˜Ÿåˆ—é”ï¼ˆç”¨äºæ¸…ç†ä»»åŠ¡ï¼‰
 * @returns {Promise<string[]>} è´¦æˆ·IDåˆ—è¡¨
 */
redisClient.scanUserMessageQueueLocks = async function () {
  const accountIds = []
  let cursor = '0'
  let iterations = 0
  const MAX_ITERATIONS = 1000 // é˜²æ­¢æ— é™å¾ªç¯

  try {
    do {
      const [newCursor, keys] = await this.client.scan(
        cursor,
        'MATCH',
        'user_msg_queue_lock:*',
        'COUNT',
        100
      )
      cursor = newCursor
      iterations++

      for (const key of keys) {
        const accountId = key.replace('user_msg_queue_lock:', '')
        accountIds.push(accountId)
      }

      // é˜²æ­¢æ— é™å¾ªç¯
      if (iterations >= MAX_ITERATIONS) {
        logger.warn(
          `ğŸ“¬ User message queue: SCAN reached max iterations (${MAX_ITERATIONS}), stopping early`,
          { foundLocks: accountIds.length }
        )
        break
      }
    } while (cursor !== '0')

    if (accountIds.length > 0) {
      logger.debug(
        `ğŸ“¬ User message queue: scanned ${accountIds.length} lock(s) in ${iterations} iteration(s)`
      )
    }

    return accountIds
  } catch (error) {
    logger.error('Failed to scan user message queue locks:', error)
    return []
  }
}

// ============================================
// ğŸš¦ API Key å¹¶å‘è¯·æ±‚æ’é˜Ÿæ–¹æ³•
// ============================================

/**
 * å¢åŠ æ’é˜Ÿè®¡æ•°ï¼ˆä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§ï¼‰
 * @param {string} apiKeyId - API Key ID
 * @param {number} [timeoutMs=60000] - æ’é˜Ÿè¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ï¼Œç”¨äºè®¡ç®— TTL
 * @returns {Promise<number>} å¢åŠ åçš„æ’é˜Ÿæ•°é‡
 */
redisClient.incrConcurrencyQueue = async function (apiKeyId, timeoutMs = 60000) {
  const key = `concurrency:queue:${apiKeyId}`
  try {
    // ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿ INCR å’Œ EXPIRE åŸå­æ‰§è¡Œï¼Œé˜²æ­¢è¿›ç¨‹å´©æºƒå¯¼è‡´è®¡æ•°å™¨æ³„æ¼
    // TTL = è¶…æ—¶æ—¶é—´ + ç¼“å†²æ—¶é—´ï¼ˆç¡®ä¿é”®ä¸ä¼šåœ¨è¯·æ±‚è¿˜åœ¨ç­‰å¾…æ—¶è¿‡æœŸï¼‰
    const ttlSeconds = Math.ceil(timeoutMs / 1000) + QUEUE_TTL_BUFFER_SECONDS
    const script = `
      local count = redis.call('INCR', KEYS[1])
      redis.call('EXPIRE', KEYS[1], ARGV[1])
      return count
    `
    const count = await this.client.eval(script, 1, key, String(ttlSeconds))
    logger.database(
      `ğŸš¦ Incremented queue count for key ${apiKeyId}: ${count} (TTL: ${ttlSeconds}s)`
    )
    return parseInt(count)
  } catch (error) {
    logger.error(`Failed to increment concurrency queue for ${apiKeyId}:`, error)
    throw error
  }
}

/**
 * å‡å°‘æ’é˜Ÿè®¡æ•°ï¼ˆä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§ï¼‰
 * @param {string} apiKeyId - API Key ID
 * @returns {Promise<number>} å‡å°‘åçš„æ’é˜Ÿæ•°é‡
 */
redisClient.decrConcurrencyQueue = async function (apiKeyId) {
  const key = `concurrency:queue:${apiKeyId}`
  try {
    // ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿ DECR å’Œ DEL åŸå­æ‰§è¡Œï¼Œé˜²æ­¢è¿›ç¨‹å´©æºƒå¯¼è‡´è®¡æ•°å™¨æ®‹ç•™
    const script = `
      local count = redis.call('DECR', KEYS[1])
      if count <= 0 then
        redis.call('DEL', KEYS[1])
        return 0
      end
      return count
    `
    const count = await this.client.eval(script, 1, key)
    const result = parseInt(count)
    if (result === 0) {
      logger.database(`ğŸš¦ Queue count for key ${apiKeyId} is 0, removed key`)
    } else {
      logger.database(`ğŸš¦ Decremented queue count for key ${apiKeyId}: ${result}`)
    }
    return result
  } catch (error) {
    logger.error(`Failed to decrement concurrency queue for ${apiKeyId}:`, error)
    throw error
  }
}

/**
 * è·å–æ’é˜Ÿè®¡æ•°
 * @param {string} apiKeyId - API Key ID
 * @returns {Promise<number>} å½“å‰æ’é˜Ÿæ•°é‡
 */
redisClient.getConcurrencyQueueCount = async function (apiKeyId) {
  const key = `concurrency:queue:${apiKeyId}`
  try {
    const count = await this.client.get(key)
    return parseInt(count || 0)
  } catch (error) {
    logger.error(`Failed to get concurrency queue count for ${apiKeyId}:`, error)
    return 0
  }
}

/**
 * æ¸…ç©ºæ’é˜Ÿè®¡æ•°
 * @param {string} apiKeyId - API Key ID
 * @returns {Promise<boolean>} æ˜¯å¦æˆåŠŸæ¸…ç©º
 */
redisClient.clearConcurrencyQueue = async function (apiKeyId) {
  const key = `concurrency:queue:${apiKeyId}`
  try {
    await this.client.del(key)
    logger.database(`ğŸš¦ Cleared queue count for key ${apiKeyId}`)
    return true
  } catch (error) {
    logger.error(`Failed to clear concurrency queue for ${apiKeyId}:`, error)
    return false
  }
}

/**
 * æ‰«ææ‰€æœ‰æ’é˜Ÿè®¡æ•°å™¨
 * @returns {Promise<string[]>} API Key ID åˆ—è¡¨
 */
redisClient.scanConcurrencyQueueKeys = async function () {
  const apiKeyIds = []
  let cursor = '0'
  let iterations = 0
  const MAX_ITERATIONS = 1000

  try {
    do {
      const [newCursor, keys] = await this.client.scan(
        cursor,
        'MATCH',
        'concurrency:queue:*',
        'COUNT',
        100
      )
      cursor = newCursor
      iterations++

      for (const key of keys) {
        // æ’é™¤ç»Ÿè®¡å’Œç­‰å¾…æ—¶é—´ç›¸å…³çš„é”®
        if (
          key.startsWith('concurrency:queue:stats:') ||
          key.startsWith('concurrency:queue:wait_times:')
        ) {
          continue
        }
        const apiKeyId = key.replace('concurrency:queue:', '')
        apiKeyIds.push(apiKeyId)
      }

      if (iterations >= MAX_ITERATIONS) {
        logger.warn(
          `ğŸš¦ Concurrency queue: SCAN reached max iterations (${MAX_ITERATIONS}), stopping early`,
          { foundQueues: apiKeyIds.length }
        )
        break
      }
    } while (cursor !== '0')

    return apiKeyIds
  } catch (error) {
    logger.error('Failed to scan concurrency queue keys:', error)
    return []
  }
}

/**
 * æ¸…ç†æ‰€æœ‰æ’é˜Ÿè®¡æ•°å™¨ï¼ˆç”¨äºæœåŠ¡é‡å¯ï¼‰
 * @returns {Promise<number>} æ¸…ç†çš„è®¡æ•°å™¨æ•°é‡
 */
redisClient.clearAllConcurrencyQueues = async function () {
  let cleared = 0
  let cursor = '0'
  let iterations = 0
  const MAX_ITERATIONS = 1000

  try {
    do {
      const [newCursor, keys] = await this.client.scan(
        cursor,
        'MATCH',
        'concurrency:queue:*',
        'COUNT',
        100
      )
      cursor = newCursor
      iterations++

      // åªåˆ é™¤æ’é˜Ÿè®¡æ•°å™¨ï¼Œä¿ç•™ç»Ÿè®¡æ•°æ®
      const queueKeys = keys.filter(
        (key) =>
          !key.startsWith('concurrency:queue:stats:') &&
          !key.startsWith('concurrency:queue:wait_times:')
      )

      if (queueKeys.length > 0) {
        await this.client.del(...queueKeys)
        cleared += queueKeys.length
      }

      if (iterations >= MAX_ITERATIONS) {
        break
      }
    } while (cursor !== '0')

    if (cleared > 0) {
      logger.info(`ğŸš¦ Cleared ${cleared} concurrency queue counter(s) on startup`)
    }
    return cleared
  } catch (error) {
    logger.error('Failed to clear all concurrency queues:', error)
    return 0
  }
}

/**
 * å¢åŠ æ’é˜Ÿç»Ÿè®¡è®¡æ•°ï¼ˆä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§ï¼‰
 * @param {string} apiKeyId - API Key ID
 * @param {string} field - ç»Ÿè®¡å­—æ®µ (entered/success/timeout/cancelled)
 * @returns {Promise<number>} å¢åŠ åçš„è®¡æ•°
 */
redisClient.incrConcurrencyQueueStats = async function (apiKeyId, field) {
  const key = `concurrency:queue:stats:${apiKeyId}`
  try {
    // ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿ HINCRBY å’Œ EXPIRE åŸå­æ‰§è¡Œ
    // é˜²æ­¢åœ¨ä¸¤è€…ä¹‹é—´å´©æºƒå¯¼è‡´ç»Ÿè®¡é”®æ²¡æœ‰ TTLï¼ˆå†…å­˜æ³„æ¼ï¼‰
    const script = `
      local count = redis.call('HINCRBY', KEYS[1], ARGV[1], 1)
      redis.call('EXPIRE', KEYS[1], ARGV[2])
      return count
    `
    const count = await this.client.eval(script, 1, key, field, String(QUEUE_STATS_TTL_SECONDS))
    return parseInt(count)
  } catch (error) {
    logger.error(`Failed to increment queue stats ${field} for ${apiKeyId}:`, error)
    return 0
  }
}

/**
 * è·å–æ’é˜Ÿç»Ÿè®¡
 * @param {string} apiKeyId - API Key ID
 * @returns {Promise<Object>} ç»Ÿè®¡æ•°æ®
 */
redisClient.getConcurrencyQueueStats = async function (apiKeyId) {
  const key = `concurrency:queue:stats:${apiKeyId}`
  try {
    const stats = await this.client.hgetall(key)
    return {
      entered: parseInt(stats?.entered || 0),
      success: parseInt(stats?.success || 0),
      timeout: parseInt(stats?.timeout || 0),
      cancelled: parseInt(stats?.cancelled || 0),
      socket_changed: parseInt(stats?.socket_changed || 0),
      rejected_overload: parseInt(stats?.rejected_overload || 0)
    }
  } catch (error) {
    logger.error(`Failed to get queue stats for ${apiKeyId}:`, error)
    return {
      entered: 0,
      success: 0,
      timeout: 0,
      cancelled: 0,
      socket_changed: 0,
      rejected_overload: 0
    }
  }
}

/**
 * è®°å½•æ’é˜Ÿç­‰å¾…æ—¶é—´ï¼ˆæŒ‰ API Key åˆ†å¼€å­˜å‚¨ï¼‰
 * @param {string} apiKeyId - API Key ID
 * @param {number} waitTimeMs - ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
 * @returns {Promise<void>}
 */
redisClient.recordQueueWaitTime = async function (apiKeyId, waitTimeMs) {
  const key = `concurrency:queue:wait_times:${apiKeyId}`
  try {
    // ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§ï¼ŒåŒæ—¶è®¾ç½® TTL é˜²æ­¢å†…å­˜æ³„æ¼
    const script = `
      redis.call('LPUSH', KEYS[1], ARGV[1])
      redis.call('LTRIM', KEYS[1], 0, ARGV[2])
      redis.call('EXPIRE', KEYS[1], ARGV[3])
      return 1
    `
    await this.client.eval(
      script,
      1,
      key,
      waitTimeMs,
      WAIT_TIME_SAMPLES_PER_KEY - 1,
      WAIT_TIME_TTL_SECONDS
    )
  } catch (error) {
    logger.error(`Failed to record queue wait time for ${apiKeyId}:`, error)
  }
}

/**
 * è®°å½•å…¨å±€æ’é˜Ÿç­‰å¾…æ—¶é—´
 * @param {number} waitTimeMs - ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
 * @returns {Promise<void>}
 */
redisClient.recordGlobalQueueWaitTime = async function (waitTimeMs) {
  const key = 'concurrency:queue:wait_times:global'
  try {
    // ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§ï¼ŒåŒæ—¶è®¾ç½® TTL é˜²æ­¢å†…å­˜æ³„æ¼
    const script = `
      redis.call('LPUSH', KEYS[1], ARGV[1])
      redis.call('LTRIM', KEYS[1], 0, ARGV[2])
      redis.call('EXPIRE', KEYS[1], ARGV[3])
      return 1
    `
    await this.client.eval(
      script,
      1,
      key,
      waitTimeMs,
      WAIT_TIME_SAMPLES_GLOBAL - 1,
      WAIT_TIME_TTL_SECONDS
    )
  } catch (error) {
    logger.error('Failed to record global queue wait time:', error)
  }
}

/**
 * è·å–å…¨å±€ç­‰å¾…æ—¶é—´åˆ—è¡¨
 * @returns {Promise<number[]>} ç­‰å¾…æ—¶é—´åˆ—è¡¨
 */
redisClient.getGlobalQueueWaitTimes = async function () {
  const key = 'concurrency:queue:wait_times:global'
  try {
    const samples = await this.client.lrange(key, 0, -1)
    return samples.map(Number)
  } catch (error) {
    logger.error('Failed to get global queue wait times:', error)
    return []
  }
}

/**
 * è·å–æŒ‡å®š API Key çš„ç­‰å¾…æ—¶é—´åˆ—è¡¨
 * @param {string} apiKeyId - API Key ID
 * @returns {Promise<number[]>} ç­‰å¾…æ—¶é—´åˆ—è¡¨
 */
redisClient.getQueueWaitTimes = async function (apiKeyId) {
  const key = `concurrency:queue:wait_times:${apiKeyId}`
  try {
    const samples = await this.client.lrange(key, 0, -1)
    return samples.map(Number)
  } catch (error) {
    logger.error(`Failed to get queue wait times for ${apiKeyId}:`, error)
    return []
  }
}

/**
 * æ‰«ææ‰€æœ‰æ’é˜Ÿç»Ÿè®¡é”®
 * @returns {Promise<string[]>} API Key ID åˆ—è¡¨
 */
redisClient.scanConcurrencyQueueStatsKeys = async function () {
  const apiKeyIds = []
  let cursor = '0'
  let iterations = 0
  const MAX_ITERATIONS = 1000

  try {
    do {
      const [newCursor, keys] = await this.client.scan(
        cursor,
        'MATCH',
        'concurrency:queue:stats:*',
        'COUNT',
        100
      )
      cursor = newCursor
      iterations++

      for (const key of keys) {
        const apiKeyId = key.replace('concurrency:queue:stats:', '')
        apiKeyIds.push(apiKeyId)
      }

      if (iterations >= MAX_ITERATIONS) {
        break
      }
    } while (cursor !== '0')

    return apiKeyIds
  } catch (error) {
    logger.error('Failed to scan concurrency queue stats keys:', error)
    return []
  }
}

// ============================================================================
// è´¦æˆ·æµ‹è¯•å†å²ç›¸å…³æ“ä½œ
// ============================================================================

const ACCOUNT_TEST_HISTORY_MAX = 5 // ä¿ç•™æœ€è¿‘5æ¬¡æµ‹è¯•è®°å½•
const ACCOUNT_TEST_HISTORY_TTL = 86400 * 30 // 30å¤©è¿‡æœŸ
const ACCOUNT_TEST_CONFIG_TTL = 86400 * 365 // æµ‹è¯•é…ç½®ä¿ç•™1å¹´ï¼ˆç”¨æˆ·é€šå¸¸é•¿æœŸä½¿ç”¨ï¼‰

/**
 * ä¿å­˜è´¦æˆ·æµ‹è¯•ç»“æœ
 * @param {string} accountId - è´¦æˆ·ID
 * @param {string} platform - å¹³å°ç±»å‹ (claude/gemini/openaiç­‰)
 * @param {Object} testResult - æµ‹è¯•ç»“æœå¯¹è±¡
 * @param {boolean} testResult.success - æ˜¯å¦æˆåŠŸ
 * @param {string} testResult.message - æµ‹è¯•æ¶ˆæ¯/å“åº”
 * @param {number} testResult.latencyMs - å»¶è¿Ÿæ¯«ç§’æ•°
 * @param {string} testResult.error - é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰
 * @param {string} testResult.timestamp - æµ‹è¯•æ—¶é—´æˆ³
 */
redisClient.saveAccountTestResult = async function (accountId, platform, testResult) {
  const key = `account:test_history:${platform}:${accountId}`
  try {
    const record = JSON.stringify({
      ...testResult,
      timestamp: testResult.timestamp || new Date().toISOString()
    })

    // ä½¿ç”¨ LPUSH + LTRIM ä¿æŒæœ€è¿‘5æ¡è®°å½•
    const client = this.getClientSafe()
    await client.lpush(key, record)
    await client.ltrim(key, 0, ACCOUNT_TEST_HISTORY_MAX - 1)
    await client.expire(key, ACCOUNT_TEST_HISTORY_TTL)

    logger.debug(`ğŸ“ Saved test result for ${platform} account ${accountId}`)
  } catch (error) {
    logger.error(`Failed to save test result for ${accountId}:`, error)
  }
}

/**
 * è·å–è´¦æˆ·æµ‹è¯•å†å²
 * @param {string} accountId - è´¦æˆ·ID
 * @param {string} platform - å¹³å°ç±»å‹
 * @returns {Promise<Array>} æµ‹è¯•å†å²è®°å½•æ•°ç»„ï¼ˆæœ€æ–°åœ¨å‰ï¼‰
 */
redisClient.getAccountTestHistory = async function (accountId, platform) {
  const key = `account:test_history:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    const records = await client.lrange(key, 0, -1)
    return records.map((r) => JSON.parse(r))
  } catch (error) {
    logger.error(`Failed to get test history for ${accountId}:`, error)
    return []
  }
}

/**
 * è·å–è´¦æˆ·æœ€æ–°æµ‹è¯•ç»“æœ
 * @param {string} accountId - è´¦æˆ·ID
 * @param {string} platform - å¹³å°ç±»å‹
 * @returns {Promise<Object|null>} æœ€æ–°æµ‹è¯•ç»“æœ
 */
redisClient.getAccountLatestTestResult = async function (accountId, platform) {
  const key = `account:test_history:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    const record = await client.lindex(key, 0)
    return record ? JSON.parse(record) : null
  } catch (error) {
    logger.error(`Failed to get latest test result for ${accountId}:`, error)
    return null
  }
}

/**
 * æ‰¹é‡è·å–å¤šä¸ªè´¦æˆ·çš„æµ‹è¯•å†å²
 * @param {Array<{accountId: string, platform: string}>} accounts - è´¦æˆ·åˆ—è¡¨
 * @returns {Promise<Object>} ä»¥ accountId ä¸º key çš„æµ‹è¯•å†å²æ˜ å°„
 */
redisClient.getAccountsTestHistory = async function (accounts) {
  const result = {}
  try {
    const client = this.getClientSafe()
    const pipeline = client.pipeline()

    for (const { accountId, platform } of accounts) {
      const key = `account:test_history:${platform}:${accountId}`
      pipeline.lrange(key, 0, -1)
    }

    const responses = await pipeline.exec()

    accounts.forEach(({ accountId }, index) => {
      const [err, records] = responses[index]
      if (!err && records) {
        result[accountId] = records.map((r) => JSON.parse(r))
      } else {
        result[accountId] = []
      }
    })
  } catch (error) {
    logger.error('Failed to get batch test history:', error)
  }
  return result
}

/**
 * ä¿å­˜å®šæ—¶æµ‹è¯•é…ç½®
 * @param {string} accountId - è´¦æˆ·ID
 * @param {string} platform - å¹³å°ç±»å‹
 * @param {Object} config - é…ç½®å¯¹è±¡
 * @param {boolean} config.enabled - æ˜¯å¦å¯ç”¨å®šæ—¶æµ‹è¯•
 * @param {string} config.cronExpression - Cron è¡¨è¾¾å¼ (å¦‚ "0 8 * * *" è¡¨ç¤ºæ¯å¤©8ç‚¹)
 * @param {string} config.model - æµ‹è¯•ä½¿ç”¨çš„æ¨¡å‹
 */
redisClient.saveAccountTestConfig = async function (accountId, platform, testConfig) {
  const key = `account:test_config:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    await client.hset(key, {
      enabled: testConfig.enabled ? 'true' : 'false',
      cronExpression: testConfig.cronExpression || '0 8 * * *', // é»˜è®¤æ¯å¤©æ—©ä¸Š8ç‚¹
      model: testConfig.model || 'claude-sonnet-4-5-20250929', // é»˜è®¤æ¨¡å‹
      updatedAt: new Date().toISOString()
    })
    // è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ1å¹´ï¼‰
    await client.expire(key, ACCOUNT_TEST_CONFIG_TTL)
  } catch (error) {
    logger.error(`Failed to save test config for ${accountId}:`, error)
  }
}

/**
 * è·å–å®šæ—¶æµ‹è¯•é…ç½®
 * @param {string} accountId - è´¦æˆ·ID
 * @param {string} platform - å¹³å°ç±»å‹
 * @returns {Promise<Object|null>} é…ç½®å¯¹è±¡
 */
redisClient.getAccountTestConfig = async function (accountId, platform) {
  const key = `account:test_config:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    const testConfig = await client.hgetall(key)
    if (!testConfig || Object.keys(testConfig).length === 0) {
      return null
    }
    // å‘åå…¼å®¹ï¼šå¦‚æœå­˜åœ¨æ—§çš„ testHour å­—æ®µï¼Œè½¬æ¢ä¸º cron è¡¨è¾¾å¼
    let { cronExpression } = testConfig
    if (!cronExpression && testConfig.testHour) {
      const hour = parseInt(testConfig.testHour, 10)
      cronExpression = `0 ${hour} * * *`
    }
    return {
      enabled: testConfig.enabled === 'true',
      cronExpression: cronExpression || '0 8 * * *',
      model: testConfig.model || 'claude-sonnet-4-5-20250929',
      updatedAt: testConfig.updatedAt
    }
  } catch (error) {
    logger.error(`Failed to get test config for ${accountId}:`, error)
    return null
  }
}

/**
 * è·å–æ‰€æœ‰å¯ç”¨å®šæ—¶æµ‹è¯•çš„è´¦æˆ·
 * @param {string} platform - å¹³å°ç±»å‹
 * @returns {Promise<Array>} è´¦æˆ·IDåˆ—è¡¨åŠ cron é…ç½®
 */
redisClient.getEnabledTestAccounts = async function (platform) {
  const accountIds = []
  let cursor = '0'

  try {
    const client = this.getClientSafe()
    do {
      const [newCursor, keys] = await client.scan(
        cursor,
        'MATCH',
        `account:test_config:${platform}:*`,
        'COUNT',
        100
      )
      cursor = newCursor

      for (const key of keys) {
        const testConfig = await client.hgetall(key)
        if (testConfig && testConfig.enabled === 'true') {
          const accountId = key.replace(`account:test_config:${platform}:`, '')
          // å‘åå…¼å®¹ï¼šå¦‚æœå­˜åœ¨æ—§çš„ testHour å­—æ®µï¼Œè½¬æ¢ä¸º cron è¡¨è¾¾å¼
          let { cronExpression } = testConfig
          if (!cronExpression && testConfig.testHour) {
            const hour = parseInt(testConfig.testHour, 10)
            cronExpression = `0 ${hour} * * *`
          }
          accountIds.push({
            accountId,
            cronExpression: cronExpression || '0 8 * * *',
            model: testConfig.model || 'claude-sonnet-4-5-20250929'
          })
        }
      }
    } while (cursor !== '0')

    return accountIds
  } catch (error) {
    logger.error(`Failed to get enabled test accounts for ${platform}:`, error)
    return []
  }
}

/**
 * ä¿å­˜è´¦æˆ·ä¸Šæ¬¡æµ‹è¯•æ—¶é—´ï¼ˆç”¨äºè°ƒåº¦å™¨åˆ¤æ–­æ˜¯å¦éœ€è¦æµ‹è¯•ï¼‰
 * @param {string} accountId - è´¦æˆ·ID
 * @param {string} platform - å¹³å°ç±»å‹
 */
redisClient.setAccountLastTestTime = async function (accountId, platform) {
  const key = `account:last_test:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    await client.set(key, Date.now().toString(), 'EX', 86400 * 7) // 7å¤©è¿‡æœŸ
  } catch (error) {
    logger.error(`Failed to set last test time for ${accountId}:`, error)
  }
}

/**
 * è·å–è´¦æˆ·ä¸Šæ¬¡æµ‹è¯•æ—¶é—´
 * @param {string} accountId - è´¦æˆ·ID
 * @param {string} platform - å¹³å°ç±»å‹
 * @returns {Promise<number|null>} ä¸Šæ¬¡æµ‹è¯•æ—¶é—´æˆ³
 */
redisClient.getAccountLastTestTime = async function (accountId, platform) {
  const key = `account:last_test:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    const timestamp = await client.get(key)
    return timestamp ? parseInt(timestamp, 10) : null
  } catch (error) {
    logger.error(`Failed to get last test time for ${accountId}:`, error)
    return null
  }
}

/**
 * ä½¿ç”¨ SCAN è·å–åŒ¹é…æ¨¡å¼çš„æ‰€æœ‰ keysï¼ˆé¿å… KEYS å‘½ä»¤é˜»å¡ Redisï¼‰
 * @param {string} pattern - åŒ¹é…æ¨¡å¼ï¼Œå¦‚ 'usage:model:daily:*:2025-01-01'
 * @param {number} batchSize - æ¯æ¬¡ SCAN çš„æ•°é‡ï¼Œé»˜è®¤ 200
 * @returns {Promise<string[]>} åŒ¹é…çš„ key åˆ—è¡¨
 */
redisClient.scanKeys = async function (pattern, batchSize = 200) {
  const keys = []
  let cursor = '0'
  const client = this.getClientSafe()

  do {
    const [newCursor, batch] = await client.scan(cursor, 'MATCH', pattern, 'COUNT', batchSize)
    cursor = newCursor
    keys.push(...batch)
  } while (cursor !== '0')

  // å»é‡ï¼ˆSCAN å¯èƒ½è¿”å›é‡å¤ keyï¼‰
  return [...new Set(keys)]
}

/**
 * æ‰¹é‡ HGETALLï¼ˆä½¿ç”¨ Pipeline å‡å°‘ç½‘ç»œå¾€è¿”ï¼‰
 * @param {string[]} keys - è¦è·å–çš„ key åˆ—è¡¨
 * @returns {Promise<Object[]>} æ¯ä¸ª key å¯¹åº”çš„æ•°æ®ï¼Œå¤±è´¥çš„è¿”å› null
 */
redisClient.batchHgetall = async function (keys) {
  if (!keys || keys.length === 0) {
    return []
  }

  const client = this.getClientSafe()
  const pipeline = client.pipeline()
  keys.forEach((k) => pipeline.hgetall(k))
  const results = await pipeline.exec()

  return results.map(([err, data]) => (err ? null : data))
}

/**
 * ä½¿ç”¨ SCAN + Pipeline è·å–åŒ¹é…æ¨¡å¼çš„æ‰€æœ‰æ•°æ®
 * @param {string} pattern - åŒ¹é…æ¨¡å¼
 * @param {number} batchSize - SCAN æ‰¹æ¬¡å¤§å°
 * @returns {Promise<{key: string, data: Object}[]>} key å’Œæ•°æ®çš„æ•°ç»„
 */
redisClient.scanAndGetAll = async function (pattern, batchSize = 200) {
  const keys = await this.scanKeys(pattern, batchSize)
  if (keys.length === 0) {
    return []
  }

  const dataList = await this.batchHgetall(keys)
  return keys.map((key, i) => ({ key, data: dataList[i] })).filter((item) => item.data !== null)
}

/**
 * æ‰¹é‡è·å–å¤šä¸ª API Key çš„ä½¿ç”¨ç»Ÿè®¡ã€è´¹ç”¨ã€å¹¶å‘ç­‰æ•°æ®
 * @param {string[]} keyIds - API Key ID åˆ—è¡¨
 * @returns {Promise<Map<string, Object>>} keyId -> ç»Ÿè®¡æ•°æ®çš„æ˜ å°„
 */
redisClient.batchGetApiKeyStats = async function (keyIds) {
  if (!keyIds || keyIds.length === 0) {
    return new Map()
  }

  const client = this.getClientSafe()
  const today = getDateStringInTimezone()
  const tzDate = getDateInTimezone()
  const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
  const currentWeek = getWeekStringInTimezone()
  const currentHour = `${today}:${String(getHourInTimezone(new Date())).padStart(2, '0')}`

  const pipeline = client.pipeline()

  // ä¸ºæ¯ä¸ª keyId æ·»åŠ æ‰€æœ‰éœ€è¦çš„æŸ¥è¯¢
  for (const keyId of keyIds) {
    // usage stats (3 hgetall)
    pipeline.hgetall(`usage:${keyId}`)
    pipeline.hgetall(`usage:daily:${keyId}:${today}`)
    pipeline.hgetall(`usage:monthly:${keyId}:${currentMonth}`)
    // cost stats (4 get)
    pipeline.get(`usage:cost:daily:${keyId}:${today}`)
    pipeline.get(`usage:cost:monthly:${keyId}:${currentMonth}`)
    pipeline.get(`usage:cost:hourly:${keyId}:${currentHour}`)
    pipeline.get(`usage:cost:total:${keyId}`)
    // concurrency (1 zcard)
    pipeline.zcard(`concurrency:${keyId}`)
    // weekly opus cost (1 get)
    pipeline.get(`usage:opus:weekly:${keyId}:${currentWeek}`)
    // rate limit (4 get)
    pipeline.get(`rate_limit:requests:${keyId}`)
    pipeline.get(`rate_limit:tokens:${keyId}`)
    pipeline.get(`rate_limit:cost:${keyId}`)
    pipeline.get(`rate_limit:window_start:${keyId}`)
    // apikey data for createdAt (1 hgetall)
    pipeline.hgetall(`apikey:${keyId}`)
  }

  const results = await pipeline.exec()
  const statsMap = new Map()
  const FIELDS_PER_KEY = 14

  for (let i = 0; i < keyIds.length; i++) {
    const keyId = keyIds[i]
    const offset = i * FIELDS_PER_KEY

    const [
      [, usageTotal],
      [, usageDaily],
      [, usageMonthly],
      [, costDaily],
      [, costMonthly],
      [, costHourly],
      [, costTotal],
      [, concurrency],
      [, weeklyOpusCost],
      [, rateLimitRequests],
      [, rateLimitTokens],
      [, rateLimitCost],
      [, rateLimitWindowStart],
      [, keyData]
    ] = results.slice(offset, offset + FIELDS_PER_KEY)

    statsMap.set(keyId, {
      usageTotal: usageTotal || {},
      usageDaily: usageDaily || {},
      usageMonthly: usageMonthly || {},
      costStats: {
        daily: parseFloat(costDaily || 0),
        monthly: parseFloat(costMonthly || 0),
        hourly: parseFloat(costHourly || 0),
        total: parseFloat(costTotal || 0)
      },
      concurrency: concurrency || 0,
      dailyCost: parseFloat(costDaily || 0),
      weeklyOpusCost: parseFloat(weeklyOpusCost || 0),
      rateLimit: {
        requests: parseInt(rateLimitRequests || 0),
        tokens: parseInt(rateLimitTokens || 0),
        cost: parseFloat(rateLimitCost || 0),
        windowStart: rateLimitWindowStart ? parseInt(rateLimitWindowStart) : null
      },
      createdAt: keyData?.createdAt || null
    })
  }

  return statsMap
}

/**
 * åˆ†æ‰¹ HGETALLï¼ˆé¿å…å•æ¬¡ pipeline ä½“ç§¯è¿‡å¤§å¯¼è‡´å†…å­˜å³°å€¼ï¼‰
 * @param {string[]} keys - è¦è·å–çš„ key åˆ—è¡¨
 * @param {number} chunkSize - æ¯æ‰¹å¤§å°ï¼Œé»˜è®¤ 500
 * @returns {Promise<Object[]>} æ¯ä¸ª key å¯¹åº”çš„æ•°æ®ï¼Œå¤±è´¥çš„è¿”å› null
 */
redisClient.batchHgetallChunked = async function (keys, chunkSize = 500) {
  if (!keys || keys.length === 0) {
    return []
  }
  if (keys.length <= chunkSize) {
    return this.batchHgetall(keys)
  }

  const results = []
  for (let i = 0; i < keys.length; i += chunkSize) {
    const chunk = keys.slice(i, i + chunkSize)
    const chunkResults = await this.batchHgetall(chunk)
    results.push(...chunkResults)
  }
  return results
}

/**
 * åˆ†æ‰¹ GETï¼ˆé¿å…å•æ¬¡ pipeline ä½“ç§¯è¿‡å¤§ï¼‰
 * @param {string[]} keys - è¦è·å–çš„ key åˆ—è¡¨
 * @param {number} chunkSize - æ¯æ‰¹å¤§å°ï¼Œé»˜è®¤ 500
 * @returns {Promise<(string|null)[]>} æ¯ä¸ª key å¯¹åº”çš„å€¼
 */
redisClient.batchGetChunked = async function (keys, chunkSize = 500) {
  if (!keys || keys.length === 0) {
    return []
  }

  const client = this.getClientSafe()
  if (keys.length <= chunkSize) {
    const pipeline = client.pipeline()
    keys.forEach((k) => pipeline.get(k))
    const results = await pipeline.exec()
    return results.map(([err, val]) => (err ? null : val))
  }

  const results = []
  for (let i = 0; i < keys.length; i += chunkSize) {
    const chunk = keys.slice(i, i + chunkSize)
    const pipeline = client.pipeline()
    chunk.forEach((k) => pipeline.get(k))
    const chunkResults = await pipeline.exec()
    results.push(...chunkResults.map(([err, val]) => (err ? null : val)))
  }
  return results
}

/**
 * SCAN + åˆ†æ‰¹å¤„ç†ï¼ˆè¾¹æ‰«æè¾¹å¤„ç†ï¼Œé¿å…å…¨é‡ keys å †å†…å­˜ï¼‰
 * @param {string} pattern - åŒ¹é…æ¨¡å¼
 * @param {Function} processor - å¤„ç†å‡½æ•° (keys: string[], dataList: Object[]) => void
 * @param {Object} options - é…ç½®é€‰é¡¹
 * @param {number} options.scanBatchSize - SCAN æ¯æ¬¡è¿”å›æ•°é‡ï¼Œé»˜è®¤ 200
 * @param {number} options.processBatchSize - å¤„ç†æ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤ 500
 * @param {string} options.fetchType - è·å–ç±»å‹ï¼š'hgetall' | 'get' | 'none'ï¼Œé»˜è®¤ 'hgetall'
 */
redisClient.scanAndProcess = async function (pattern, processor, options = {}) {
  const { scanBatchSize = 200, processBatchSize = 500, fetchType = 'hgetall' } = options
  const client = this.getClientSafe()

  let cursor = '0'
  let pendingKeys = []
  const processedKeys = new Set() // å…¨ç¨‹å»é‡

  const processBatch = async (keys) => {
    if (keys.length === 0) {
      return
    }

    // è¿‡æ»¤å·²å¤„ç†çš„ key
    const uniqueKeys = keys.filter((k) => !processedKeys.has(k))
    if (uniqueKeys.length === 0) {
      return
    }

    uniqueKeys.forEach((k) => processedKeys.add(k))

    let dataList = []
    if (fetchType === 'hgetall') {
      dataList = await this.batchHgetall(uniqueKeys)
    } else if (fetchType === 'get') {
      const pipeline = client.pipeline()
      uniqueKeys.forEach((k) => pipeline.get(k))
      const results = await pipeline.exec()
      dataList = results.map(([err, val]) => (err ? null : val))
    } else {
      dataList = uniqueKeys.map(() => null) // fetchType === 'none'
    }

    await processor(uniqueKeys, dataList)
  }

  do {
    const [newCursor, batch] = await client.scan(cursor, 'MATCH', pattern, 'COUNT', scanBatchSize)
    cursor = newCursor
    pendingKeys.push(...batch)

    // è¾¾åˆ°å¤„ç†æ‰¹æ¬¡å¤§å°æ—¶å¤„ç†
    while (pendingKeys.length >= processBatchSize) {
      const toProcess = pendingKeys.slice(0, processBatchSize)
      pendingKeys = pendingKeys.slice(processBatchSize)
      await processBatch(toProcess)
    }
  } while (cursor !== '0')

  // å¤„ç†å‰©ä½™çš„ keys
  if (pendingKeys.length > 0) {
    await processBatch(pendingKeys)
  }
}

/**
 * SCAN + åˆ†æ‰¹è·å–æ‰€æœ‰æ•°æ®ï¼ˆè¿”å›ç»“æœï¼Œé€‚åˆéœ€è¦èšåˆçš„åœºæ™¯ï¼‰
 * @param {string} pattern - åŒ¹é…æ¨¡å¼
 * @param {Object} options - é…ç½®é€‰é¡¹
 * @returns {Promise<{key: string, data: Object}[]>} key å’Œæ•°æ®çš„æ•°ç»„
 */
redisClient.scanAndGetAllChunked = async function (pattern, options = {}) {
  const results = []
  await this.scanAndProcess(
    pattern,
    (keys, dataList) => {
      keys.forEach((key, i) => {
        if (dataList[i] !== null) {
          results.push({ key, data: dataList[i] })
        }
      })
    },
    { ...options, fetchType: 'hgetall' }
  )
  return results
}

/**
 * åˆ†æ‰¹åˆ é™¤ keysï¼ˆé¿å…å¤§é‡ DEL é˜»å¡ï¼‰
 * @param {string[]} keys - è¦åˆ é™¤çš„ key åˆ—è¡¨
 * @param {number} chunkSize - æ¯æ‰¹å¤§å°ï¼Œé»˜è®¤ 500
 * @returns {Promise<number>} åˆ é™¤çš„ key æ•°é‡
 */
redisClient.batchDelChunked = async function (keys, chunkSize = 500) {
  if (!keys || keys.length === 0) {
    return 0
  }

  const client = this.getClientSafe()
  let deleted = 0

  for (let i = 0; i < keys.length; i += chunkSize) {
    const chunk = keys.slice(i, i + chunkSize)
    const pipeline = client.pipeline()
    chunk.forEach((k) => pipeline.del(k))
    const results = await pipeline.exec()
    deleted += results.filter(([err, val]) => !err && val > 0).length
  }

  return deleted
}

/**
 * é€šç”¨ç´¢å¼•è¾…åŠ©å‡½æ•°ï¼šè·å–æ‰€æœ‰ IDï¼ˆä¼˜å…ˆç´¢å¼•ï¼Œå›é€€ SCANï¼‰
 * @param {string} indexKey - ç´¢å¼• Set çš„ key
 * @param {string} scanPattern - SCAN çš„ pattern
 * @param {RegExp} extractRegex - ä» key ä¸­æå– ID çš„æ­£åˆ™
 * @returns {Promise<string[]>} ID åˆ—è¡¨
 */
redisClient.getAllIdsByIndex = async function (indexKey, scanPattern, extractRegex) {
  const client = this.getClientSafe()
  // æ£€æŸ¥æ˜¯å¦å·²æ ‡è®°ä¸ºç©ºï¼ˆé¿å…é‡å¤ SCANï¼‰
  const emptyMarker = await client.get(`${indexKey}:empty`)
  if (emptyMarker === '1') {
    return []
  }
  let ids = await client.smembers(indexKey)
  if (ids && ids.length > 0) {
    return ids
  }
  // å›é€€åˆ° SCANï¼ˆä»…é¦–æ¬¡ï¼‰
  const keys = await this.scanKeys(scanPattern)
  if (keys.length === 0) {
    // æ ‡è®°ä¸ºç©ºï¼Œé¿å…é‡å¤ SCANï¼ˆ1å°æ—¶è¿‡æœŸï¼Œå…è®¸æ–°æ•°æ®å†™å…¥åé‡æ–°æ£€æµ‹ï¼‰
    await client.setex(`${indexKey}:empty`, 3600, '1')
    return []
  }
  ids = keys
    .map((k) => {
      const match = k.match(extractRegex)
      return match ? match[1] : null
    })
    .filter(Boolean)
  // å»ºç«‹ç´¢å¼•
  if (ids.length > 0) {
    await client.sadd(indexKey, ...ids)
  }
  return ids
}

/**
 * æ·»åŠ åˆ°ç´¢å¼•
 */
redisClient.addToIndex = async function (indexKey, id) {
  const client = this.getClientSafe()
  await client.sadd(indexKey, id)
  // æ¸…é™¤ç©ºæ ‡è®°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
  await client.del(`${indexKey}:empty`)
}

/**
 * ä»ç´¢å¼•ç§»é™¤
 */
redisClient.removeFromIndex = async function (indexKey, id) {
  const client = this.getClientSafe()
  await client.srem(indexKey, id)
}

// ============================================
// æ•°æ®è¿ç§»ç›¸å…³
// ============================================

// è¿ç§»å…¨å±€ç»Ÿè®¡æ•°æ®ï¼ˆä» API Key æ•°æ®èšåˆï¼‰
redisClient.migrateGlobalStats = async function () {
  logger.info('ğŸ”„ å¼€å§‹è¿ç§»å…¨å±€ç»Ÿè®¡æ•°æ®...')

  const keyIds = await this.scanApiKeyIds()
  if (!keyIds || keyIds.length === 0) {
    logger.info('ğŸ“Š æ²¡æœ‰ API Key æ•°æ®éœ€è¦è¿ç§»')
    return { success: true, migrated: 0 }
  }

  const total = {
    requests: 0,
    inputTokens: 0,
    outputTokens: 0,
    cacheCreateTokens: 0,
    cacheReadTokens: 0,
    allTokens: 0
  }

  // æ‰¹é‡è·å–æ‰€æœ‰ usage æ•°æ®
  const pipeline = this.client.pipeline()
  keyIds.forEach((id) => pipeline.hgetall(`usage:${id}`))
  const results = await pipeline.exec()

  results.forEach(([err, usage]) => {
    if (err || !usage) {
      return
    }
    // å…¼å®¹æ–°æ—§å­—æ®µæ ¼å¼ï¼ˆå¸¦ total å‰ç¼€å’Œä¸å¸¦çš„ï¼‰
    total.requests += parseInt(usage.totalRequests || usage.requests) || 0
    total.inputTokens += parseInt(usage.totalInputTokens || usage.inputTokens) || 0
    total.outputTokens += parseInt(usage.totalOutputTokens || usage.outputTokens) || 0
    total.cacheCreateTokens +=
      parseInt(usage.totalCacheCreateTokens || usage.cacheCreateTokens) || 0
    total.cacheReadTokens += parseInt(usage.totalCacheReadTokens || usage.cacheReadTokens) || 0
    total.allTokens += parseInt(usage.totalAllTokens || usage.allTokens || usage.totalTokens) || 0
  })

  // å†™å…¥å…¨å±€ç»Ÿè®¡
  await this.client.hset('usage:global:total', total)

  // è¿ç§»æœˆä»½ç´¢å¼•ï¼ˆä»ç°æœ‰çš„ usage:model:monthly:* key ä¸­æå–æœˆä»½ï¼‰
  const monthlyKeys = await this.client.keys('usage:model:monthly:*')
  const months = new Set()
  for (const key of monthlyKeys) {
    const match = key.match(/:(\d{4}-\d{2})$/)
    if (match) {
      months.add(match[1])
    }
  }
  if (months.size > 0) {
    await this.client.sadd('usage:model:monthly:months', ...months)
    logger.info(`ğŸ“… è¿ç§»æœˆä»½ç´¢å¼•: ${months.size} ä¸ªæœˆä»½ (${[...months].sort().join(', ')})`)
  }

  logger.success(
    `âœ… è¿ç§»å®Œæˆ: ${keyIds.length} ä¸ª API Key, ${total.requests} è¯·æ±‚, ${total.allTokens} tokens`
  )
  return { success: true, migrated: keyIds.length, total }
}

// ç¡®ä¿æœˆä»½ç´¢å¼•å®Œæ•´ï¼ˆåå°æ£€æŸ¥ï¼Œè¡¥å……ç¼ºå¤±çš„æœˆä»½ï¼‰
redisClient.ensureMonthlyMonthsIndex = async function () {
  // æ‰«ææ‰€æœ‰æœˆä»½ key
  const monthlyKeys = await this.client.keys('usage:model:monthly:*')
  const allMonths = new Set()
  for (const key of monthlyKeys) {
    const match = key.match(/:(\d{4}-\d{2})$/)
    if (match) {
      allMonths.add(match[1])
    }
  }

  if (allMonths.size === 0) {
    return // æ²¡æœ‰æœˆä»½æ•°æ®
  }

  // è·å–ç´¢å¼•ä¸­å·²æœ‰çš„æœˆä»½
  const existingMonths = await this.client.smembers('usage:model:monthly:months')
  const existingSet = new Set(existingMonths)

  // æ‰¾å‡ºç¼ºå¤±çš„æœˆä»½
  const missingMonths = [...allMonths].filter((m) => !existingSet.has(m))

  if (missingMonths.length > 0) {
    await this.client.sadd('usage:model:monthly:months', ...missingMonths)
    logger.info(
      `ğŸ“… è¡¥å……æœˆä»½ç´¢å¼•: ${missingMonths.length} ä¸ªæœˆä»½ (${missingMonths.sort().join(', ')})`
    )
  }
}

// æ£€æŸ¥æ˜¯å¦éœ€è¦è¿ç§»
redisClient.needsGlobalStatsMigration = async function () {
  const exists = await this.client.exists('usage:global:total')
  return exists === 0
}

// è·å–å·²è¿ç§»ç‰ˆæœ¬
redisClient.getMigratedVersion = async function () {
  return (await this.client.get('system:migrated:version')) || '0.0.0'
}

// è®¾ç½®å·²è¿ç§»ç‰ˆæœ¬
redisClient.setMigratedVersion = async function (version) {
  await this.client.set('system:migrated:version', version)
}

// è·å–å…¨å±€ç»Ÿè®¡ï¼ˆç”¨äº dashboard å¿«é€ŸæŸ¥è¯¢ï¼‰
redisClient.getGlobalStats = async function () {
  const stats = await this.client.hgetall('usage:global:total')
  if (!stats || !stats.requests) {
    return null
  }
  return {
    requests: parseInt(stats.requests) || 0,
    inputTokens: parseInt(stats.inputTokens) || 0,
    outputTokens: parseInt(stats.outputTokens) || 0,
    cacheCreateTokens: parseInt(stats.cacheCreateTokens) || 0,
    cacheReadTokens: parseInt(stats.cacheReadTokens) || 0,
    allTokens: parseInt(stats.allTokens) || 0
  }
}

// å¿«é€Ÿè·å– API Key è®¡æ•°ï¼ˆä¸æ‹‰å…¨é‡æ•°æ®ï¼‰
redisClient.getApiKeyCount = async function () {
  const keyIds = await this.scanApiKeyIds()
  if (!keyIds || keyIds.length === 0) {
    return { total: 0, active: 0 }
  }

  // æ‰¹é‡è·å– isActive å­—æ®µ
  const pipeline = this.client.pipeline()
  keyIds.forEach((id) => pipeline.hget(`apikey:${id}`, 'isActive'))
  const results = await pipeline.exec()

  let active = 0
  results.forEach(([err, val]) => {
    if (!err && (val === 'true' || val === true)) {
      active++
    }
  })
  return { total: keyIds.length, active }
}

// æ¸…ç†è¿‡æœŸçš„ç³»ç»Ÿåˆ†é’Ÿç»Ÿè®¡æ•°æ®ï¼ˆå¯åŠ¨æ—¶è°ƒç”¨ï¼‰
redisClient.cleanupSystemMetrics = async function () {
  logger.info('ğŸ§¹ æ¸…ç†è¿‡æœŸçš„ç³»ç»Ÿåˆ†é’Ÿç»Ÿè®¡æ•°æ®...')

  const keys = await this.scanKeys('system:metrics:minute:*')
  if (!keys || keys.length === 0) {
    logger.info('ğŸ“Š æ²¡æœ‰éœ€è¦æ¸…ç†çš„ç³»ç»Ÿåˆ†é’Ÿç»Ÿè®¡æ•°æ®')
    return { cleaned: 0 }
  }

  // è®¡ç®—å½“å‰åˆ†é’Ÿæ—¶é—´æˆ³å’Œä¿ç•™çª—å£
  const metricsWindow = config.system?.metricsWindow || 5
  const currentMinute = Math.floor(Date.now() / 60000)
  const keepAfter = currentMinute - metricsWindow * 2 // ä¿ç•™çª—å£çš„2å€

  // ç­›é€‰éœ€è¦åˆ é™¤çš„ key
  const toDelete = keys.filter((key) => {
    const match = key.match(/system:metrics:minute:(\d+)/)
    if (!match) {
      return false
    }
    const minute = parseInt(match[1])
    return minute < keepAfter
  })

  if (toDelete.length === 0) {
    logger.info('ğŸ“Š æ²¡æœ‰è¿‡æœŸçš„ç³»ç»Ÿåˆ†é’Ÿç»Ÿè®¡æ•°æ®')
    return { cleaned: 0 }
  }

  // åˆ†æ‰¹åˆ é™¤
  const batchSize = 1000
  for (let i = 0; i < toDelete.length; i += batchSize) {
    const batch = toDelete.slice(i, i + batchSize)
    await this.client.del(...batch)
  }

  logger.success(`âœ… æ¸…ç†å®Œæˆ: åˆ é™¤ ${toDelete.length} ä¸ªè¿‡æœŸçš„ç³»ç»Ÿåˆ†é’Ÿç»Ÿè®¡ key`)
  return { cleaned: toDelete.length }
}

module.exports = redisClient
